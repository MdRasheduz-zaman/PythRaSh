<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-08-03">

<title>pythrash - Artificial Inteligence</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../_include/styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">PythRaSh</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-r" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">R</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-r">    
        <li>
    <a class="dropdown-item" href="../../ch/rbasics/git.html" rel="" target="">
 <span class="dropdown-text">git</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../ch/rbasics/firststeps.html" rel="" target="">
 <span class="dropdown-text">Basic R</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../ch/rbasics/tidyverse.html" rel="" target="">
 <span class="dropdown-text">The tidyverse</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../ch/rbasics/correlation_regression.html" rel="" target="">
 <span class="dropdown-text">Advanced R</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../ch/rbasics/baddata.html" rel="" target="">
 <span class="dropdown-text">Data Wrangling</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../ch/rbasics/solutions.html" rel="" target="">
 <span class="dropdown-text">Problem Solutions</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-python" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Python</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-python">    
        <li>
    <a class="dropdown-item" href="../../ch/python/basics.html" rel="" target="">
 <span class="dropdown-text">Basics</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../ch/python/panda.html" rel="" target="">
 <span class="dropdown-text">Advanced Python</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../ch/python/MLA.html" rel="" target="">
 <span class="dropdown-text">Machine Learning Algorithms</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../ch/python/AI.html" rel="" target="">
 <span class="dropdown-text">AI</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-linux-and-clt" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Linux and CLT</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-linux-and-clt">    
        <li>
    <a class="dropdown-item" href="../../ch/linux-and-ctl/basics.html" rel="" target="">
 <span class="dropdown-text">Linux Basics</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../ch/linux-and-ctl/advanced.html" rel="" target="">
 <span class="dropdown-text">Advanced Command Line</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-probability-and-statistics" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Probability and Statistics</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-probability-and-statistics">    
        <li>
    <a class="dropdown-item" href="../../ch/prob_stat/prob_basic.html" rel="" target="">
 <span class="dropdown-text">Probability Basics</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../ch/prob_stat/stat.html" rel="" target="">
 <span class="dropdown-text">Statistics</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-genomics" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Genomics</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-genomics">    
        <li>
    <a class="dropdown-item" href="../../ch/genomics/basics.html" rel="" target="">
 <span class="dropdown-text">Genomics Basics</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../ch/genomics/advanced.html" rel="" target="">
 <span class="dropdown-text">Advanced Genomics</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../ch/genomics/pipeline.html" rel="" target="">
 <span class="dropdown-text">Pipelines</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-blogs" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Blogs</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-blogs">    
        <li>
    <a class="dropdown-item" href="../../ch/blogs/en/index.html" rel="" target="">
 <span class="dropdown-text">English</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../ch/blogs/bn/index.html" rel="" target="">
 <span class="dropdown-text">Bangla</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/MdRasheduz-zaman" rel="" target="">
 <span class="menu-text">Contact</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/MdRasheduz-zaman/PythRaSh" rel="" target=""><i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#tensor-and-pytorch" id="toc-tensor-and-pytorch" class="nav-link active" data-scroll-target="#tensor-and-pytorch">Tensor and PyTorch</a>
  <ul class="collapse">
  <li><a href="#tensor-creation" id="toc-tensor-creation" class="nav-link" data-scroll-target="#tensor-creation">Tensor Creation</a></li>
  <li><a href="#tensor-shape" id="toc-tensor-shape" class="nav-link" data-scroll-target="#tensor-shape">Tensor shape</a></li>
  <li><a href="#tensor-data-types" id="toc-tensor-data-types" class="nav-link" data-scroll-target="#tensor-data-types">Tensor Data Types</a></li>
  <li><a href="#mathematical-operations" id="toc-mathematical-operations" class="nav-link" data-scroll-target="#mathematical-operations">Mathematical Operations</a>
  <ul class="collapse">
  <li><a href="#scalar-operation" id="toc-scalar-operation" class="nav-link" data-scroll-target="#scalar-operation">Scalar operation</a></li>
  <li><a href="#element-wise-operation" id="toc-element-wise-operation" class="nav-link" data-scroll-target="#element-wise-operation">Element-wise operation</a></li>
  <li><a href="#reduction-operation" id="toc-reduction-operation" class="nav-link" data-scroll-target="#reduction-operation">Reduction operation</a></li>
  <li><a href="#matrix-operations" id="toc-matrix-operations" class="nav-link" data-scroll-target="#matrix-operations">Matrix operations</a></li>
  <li><a href="#dot-products" id="toc-dot-products" class="nav-link" data-scroll-target="#dot-products">Dot products:</a></li>
  <li><a href="#comparison-operations" id="toc-comparison-operations" class="nav-link" data-scroll-target="#comparison-operations">Comparison operations</a></li>
  <li><a href="#special-functions" id="toc-special-functions" class="nav-link" data-scroll-target="#special-functions">Special functions</a></li>
  <li><a href="#inplace-operations" id="toc-inplace-operations" class="nav-link" data-scroll-target="#inplace-operations">Inplace Operations</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#autograd" id="toc-autograd" class="nav-link" data-scroll-target="#autograd">Autograd</a>
  <ul class="collapse">
  <li><a href="#real-world-example" id="toc-real-world-example" class="nav-link" data-scroll-target="#real-world-example">Real-world example:</a></li>
  </ul></li>
  <li><a href="#pytorch-trining-pipeline" id="toc-pytorch-trining-pipeline" class="nav-link" data-scroll-target="#pytorch-trining-pipeline">PyTorch Trining Pipeline</a>
  <ul class="collapse">
  <li><a href="#train-test-split" id="toc-train-test-split" class="nav-link" data-scroll-target="#train-test-split">Train test split</a></li>
  <li><a href="#scaling" id="toc-scaling" class="nav-link" data-scroll-target="#scaling">Scaling</a></li>
  <li><a href="#label-encoding" id="toc-label-encoding" class="nav-link" data-scroll-target="#label-encoding">Label Encoding</a></li>
  <li><a href="#numpy-arrays-to-pytorch-tensors" id="toc-numpy-arrays-to-pytorch-tensors" class="nav-link" data-scroll-target="#numpy-arrays-to-pytorch-tensors">Numpy arrays to PyTorch tensors</a></li>
  <li><a href="#defining-the-model" id="toc-defining-the-model" class="nav-link" data-scroll-target="#defining-the-model">Defining the model</a></li>
  <li><a href="#important-parameters" id="toc-important-parameters" class="nav-link" data-scroll-target="#important-parameters">Important Parameters</a></li>
  <li><a href="#training-pipeline" id="toc-training-pipeline" class="nav-link" data-scroll-target="#training-pipeline">Training Pipeline</a></li>
  <li><a href="#evaluation" id="toc-evaluation" class="nav-link" data-scroll-target="#evaluation">Evaluation</a></li>
  </ul></li>
  <li><a href="#nn-module" id="toc-nn-module" class="nav-link" data-scroll-target="#nn-module">NN module</a></li>
  <li><a href="#dataset-and-dataloader" id="toc-dataset-and-dataloader" class="nav-link" data-scroll-target="#dataset-and-dataloader">Dataset and DataLoader</a></li>
  <li><a href="#annmlp-in-pytorch" id="toc-annmlp-in-pytorch" class="nav-link" data-scroll-target="#annmlp-in-pytorch">ANN/MLP in PyTorch</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="AI.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Artificial Inteligence</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliations</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Md Rasheduzzaman </p>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            <a href="https://www.fli.de/de/institute/institut-fuer-infektionsmedizin-imed/">
            FLI Insel Riems
            </a>
          </p>
        <p class="affiliation">
            <a href="https://github.com/MdRasheduz-zaman">
            &amp; Freelancer
            </a>
          </p>
      </div>
    </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Last updated</div>
    <div class="quarto-title-meta-contents">
      <p class="date">August 3, 2025</p>
    </div>
  </div>
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="abstract-title">Content summary</div>
    Tensor, etc.
  </div>
</div>

</header>

<section id="tensor-and-pytorch" class="level1">
<h1>Tensor and PyTorch</h1>
<p>Let’s load <code>pytorch</code> library and see the version of it.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(torch.__version__)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2.7.0</code></pre>
</div>
</div>
<p>Use CPU if GPU (CUDA) is not available.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"GPU is available!"</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Using GPU: </span><span class="sc">{</span>torch<span class="sc">.</span>cuda<span class="sc">.</span>get_device_name(<span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"GPU not available. Using CPU."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>GPU not available. Using CPU.</code></pre>
</div>
</div>
<p>So, I am using CPU. Let’s start making tensors and build from very basics.</p>
<section id="tensor-creation" class="level2">
<h2 class="anchored" data-anchor-id="tensor-creation">Tensor Creation</h2>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># using empty</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.empty(<span class="dv">2</span>,<span class="dv">3</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>a</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>tensor([[0., 0., 0.],
        [0., 0., 0.]])</code></pre>
</div>
</div>
<p>Let’s check type of pur tensor.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># check type</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="bu">type</span>(a)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>torch.Tensor</code></pre>
</div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># using ones</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>torch.ones(<span class="dv">3</span>,<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>tensor([[1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># using zeros</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>torch.zeros(<span class="dv">3</span>,<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># using rand</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">40</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>torch.rand(<span class="dv">2</span>,<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>tensor([[0.3679, 0.8661, 0.1737],
        [0.7157, 0.8649, 0.4878]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">40</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>torch.rand(<span class="dv">2</span>,<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>tensor([[0.3679, 0.8661, 0.1737],
        [0.7157, 0.8649, 0.4878]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>torch.randint(size<span class="op">=</span>(<span class="dv">2</span>,<span class="dv">3</span>), low<span class="op">=</span><span class="dv">0</span>, high<span class="op">=</span><span class="dv">10</span>, dtype<span class="op">=</span>torch.float32)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>tensor([[6., 3., 6.],
        [7., 6., 5.]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># using tensor</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>torch.tensor([[<span class="dv">3</span>,<span class="dv">2</span>,<span class="dv">1</span>],[<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>tensor([[3, 2, 1],
        [4, 5, 6]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># other ways</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co"># arange</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.arange(<span class="dv">0</span>,<span class="dv">15</span>,<span class="dv">3</span>)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"using arange -&gt;"</span>, a)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="co"># using linspace</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.linspace(<span class="dv">0</span>,<span class="dv">15</span>,<span class="dv">10</span>)</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"using linspace -&gt;"</span>, b)</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="co"># using eye</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> torch.eye(<span class="dv">4</span>)</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"using eye -&gt;"</span>, c)</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a><span class="co"># using full</span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> torch.full((<span class="dv">3</span>, <span class="dv">3</span>), <span class="dv">5</span>)</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"using full -&gt;"</span>, d)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>using arange -&gt; tensor([ 0,  3,  6,  9, 12])
using linspace -&gt; tensor([ 0.0000,  1.6667,  3.3333,  5.0000,  6.6667,  8.3333, 10.0000, 11.6667,
        13.3333, 15.0000])
using eye -&gt; tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]])
using full -&gt; tensor([[5, 5, 5],
        [5, 5, 5],
        [5, 5, 5]])</code></pre>
</div>
</div>
</section>
<section id="tensor-shape" class="level2">
<h2 class="anchored" data-anchor-id="tensor-shape">Tensor shape</h2>
<p>We are making a new tensor (<code>x</code>) and checking shape of it. We can use the shape of <code>x</code> or any other already created tensor to make new tensors of that shape.</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>],[<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>]])</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>tensor([[1, 2, 3],
        [5, 6, 7]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>x.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>torch.Size([2, 3])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>torch.empty_like(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>tensor([[0, 0, 0],
        [0, 0, 0]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>torch.zeros_like(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>tensor([[0, 0, 0],
        [0, 0, 0]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>torch.rand_like(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>RuntimeError: "check_uniform_bounds" not implemented for 'Long'</code></pre>
</div>
</div>
<p>It’s not working, since <code>rand</code> makes float values in the tensor. So, we need to specify data type as float.</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>torch.rand_like(x, dtype<span class="op">=</span>torch.float32)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>tensor([[0.7583, 0.8896, 0.6959],
        [0.4810, 0.8545, 0.1130]])</code></pre>
</div>
</div>
</section>
<section id="tensor-data-types" class="level2">
<h2 class="anchored" data-anchor-id="tensor-data-types">Tensor Data Types</h2>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># find data type</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>x.dtype</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>torch.int64</code></pre>
</div>
</div>
<p>We are changing data type from float to int using <code>dtype</code> here.</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># assign data type</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>torch.tensor([<span class="fl">1.0</span>,<span class="fl">2.0</span>,<span class="fl">3.0</span>], dtype<span class="op">=</span>torch.int32)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>tensor([1, 2, 3], dtype=torch.int32)</code></pre>
</div>
</div>
<p>Similarly, from int to float using <code>dtype</code> here.</p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>torch.tensor([<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>], dtype<span class="op">=</span>torch.float64)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>tensor([1., 2., 3.], dtype=torch.float64)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co">#using to()</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>x.to(torch.float32)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>tensor([[1., 2., 3.],
        [5., 6., 7.]])</code></pre>
</div>
</div>
<p>Some common data types in torch. | <strong>Data Type</strong> | <strong>Dtype</strong> | <strong>Description</strong> | |—————————|——————-|——————————————————————————————————————————————————————————–| | <strong>32-bit Floating Point</strong> | <code>torch.float32</code> | Standard floating-point type used for most deep learning tasks. Provides a balance between precision and memory usage. | | <strong>64-bit Floating Point</strong> | <code>torch.float64</code> | Double-precision floating point. Useful for high-precision numerical tasks but uses more memory. | | <strong>16-bit Floating Point</strong> | <code>torch.float16</code> | Half-precision floating point. Commonly used in mixed-precision training to reduce memory and computational overhead on modern GPUs. | | <strong>BFloat16</strong> | <code>torch.bfloat16</code> | Brain floating-point format with reduced precision compared to <code>float16</code>. Used in mixed-precision training, especially on TPUs. | | <strong>8-bit Floating Point</strong> | <code>torch.float8</code> | Ultra-low-precision floating point. Used for experimental applications and extreme memory-constrained environments (less common). | | <strong>8-bit Integer</strong> | <code>torch.int8</code> | 8-bit signed integer. Used for quantized models to save memory and computation in inference. | | <strong>16-bit Integer</strong> | <code>torch.int16</code> | 16-bit signed integer. Useful for special numerical tasks requiring intermediate precision. | | <strong>32-bit Integer</strong> | <code>torch.int32</code> | Standard signed integer type. Commonly used for indexing and general-purpose numerical tasks. | | <strong>64-bit Integer</strong> | <code>torch.int64</code> | Long integer type. Often used for large indexing arrays or for tasks involving large numbers. | | <strong>8-bit Unsigned Integer</strong>| <code>torch.uint8</code> | 8-bit unsigned integer. Commonly used for image data (e.g., pixel values between 0 and 255). | | <strong>Boolean</strong> | <code>torch.bool</code> | Boolean type, stores <code>True</code> or <code>False</code> values. Often used for masks in logical operations. | | <strong>Complex 64</strong> | <code>torch.complex64</code> | Complex number type with 32-bit real and 32-bit imaginary parts. Used for scientific and signal processing tasks. | | <strong>Complex 128</strong> | <code>torch.complex128</code>| Complex number type with 64-bit real and 64-bit imaginary parts. Offers higher precision but uses more memory. | | <strong>Quantized Integer</strong> | <code>torch.qint8</code> | Quantized signed 8-bit integer. Used in quantized models for efficient inference. | | <strong>Quantized Unsigned Integer</strong> | <code>torch.quint8</code> | Quantized unsigned 8-bit integer. Often used for quantized tensors in image-related tasks. |</p>
</section>
<section id="mathematical-operations" class="level2">
<h2 class="anchored" data-anchor-id="mathematical-operations">Mathematical Operations</h2>
<section id="scalar-operation" class="level3">
<h3 class="anchored" data-anchor-id="scalar-operation">Scalar operation</h3>
<p>Let’s define a tensor x first.</p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.rand(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>tensor([[0.6779, 0.0173, 0.1203],
        [0.1363, 0.8089, 0.8229]])</code></pre>
</div>
</div>
<p>Now, let’s see some scalar operation on this tensor.</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co">#addition</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">+</span> <span class="dv">2</span></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="co">#subtraction</span></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>x <span class="op">-</span> <span class="dv">3</span></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a><span class="co">#multiplication</span></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>x<span class="op">*</span><span class="dv">4</span></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a><span class="co">#division</span></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>x<span class="op">/</span><span class="dv">2</span></span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a><span class="co">#integer division</span></span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>(x<span class="op">*</span><span class="dv">40</span>)<span class="op">//</span><span class="dv">3</span></span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a><span class="co">#modulus division</span></span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a>((x<span class="op">*</span><span class="dv">40</span>)<span class="op">//</span><span class="dv">3</span>)<span class="op">%</span><span class="dv">2</span></span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a><span class="co">#power</span></span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a>x<span class="op">**</span><span class="dv">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>tensor([[4.5950e-01, 2.9987e-04, 1.4484e-02],
        [1.8587e-02, 6.5435e-01, 6.7723e-01]])</code></pre>
</div>
</div>
</section>
<section id="element-wise-operation" class="level3">
<h3 class="anchored" data-anchor-id="element-wise-operation">Element-wise operation</h3>
<p>Let’s make 2 new tensors first. To do anything element-wise, the shape of the tensors should be the same.</p>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.rand(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.rand(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a)</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(b)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0.3759, 0.0295, 0.4132],
        [0.0791, 0.0489, 0.9287]])
tensor([[0.4924, 0.8416, 0.1756],
        [0.5687, 0.4447, 0.0310]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co">#add</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>a <span class="op">+</span> b</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="co">#subtract</span></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>a <span class="op">-</span> b</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a><span class="co">#multiply</span></span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>a<span class="op">*</span>b</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a><span class="co">#division</span></span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>a<span class="op">/</span>b</span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a><span class="co">#power</span></span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>a<span class="op">**</span>b</span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a><span class="co">#mod</span></span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>a<span class="op">%</span>b</span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a><span class="co">#int division</span></span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a>a<span class="op">//</span>b</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>tensor([[ 0.,  0.,  2.],
        [ 0.,  0., 29.]])</code></pre>
</div>
</div>
<p>Let’s apply absolute function on a custom tensor.</p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co">#abs</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> torch.tensor([<span class="op">-</span><span class="dv">1</span>, <span class="dv">2</span>, <span class="op">-</span><span class="dv">3</span>, <span class="dv">4</span>, <span class="op">-</span><span class="dv">5</span>, <span class="op">-</span><span class="dv">6</span>, <span class="dv">7</span>, <span class="op">-</span><span class="dv">8</span>])</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">abs</span>(c)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>tensor([1, 2, 3, 4, 5, 6, 7, 8])</code></pre>
</div>
</div>
<p>We only have positive values, right? As expected.</p>
<p>Let’s apply negative on the tensor.</p>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>torch.neg(c)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>tensor([ 1, -2,  3, -4,  5,  6, -7,  8])</code></pre>
</div>
</div>
<p>We have negative signs on the previously positives, and positive signs on the previously negatives, right?</p>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co">#round</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> torch.tensor([<span class="fl">1.4</span>, <span class="fl">4.4</span>, <span class="fl">3.6</span>, <span class="fl">3.01</span>, <span class="fl">4.55</span>, <span class="fl">4.9</span>])</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">round</span>(d)</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a><span class="co"># ceil</span></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>torch.ceil(d)</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a><span class="co"># floor</span></span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>torch.floor(d)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>tensor([1., 4., 3., 3., 4., 4.])</code></pre>
</div>
</div>
<p>Do you see what <code>round</code>, <code>ciel</code>, <code>floor</code> are doing here? It is not that difficult, try to see.</p>
<p>Let’s do some <code>clamp</code>ing. So, if a value is smaller than the <code>min</code> value provided, that value will be equal to the <code>min</code> value and values bigger than the <code>max</code> value will be made equal to the <code>max</code> value. All other values in between the range will be kept as they are.</p>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># clamp</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>d</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>torch.clamp(d, <span class="bu">min</span><span class="op">=</span><span class="dv">2</span>, <span class="bu">max</span><span class="op">=</span><span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>tensor([2.0000, 4.0000, 3.6000, 3.0100, 4.0000, 4.0000])</code></pre>
</div>
</div>
</section>
<section id="reduction-operation" class="level3">
<h3 class="anchored" data-anchor-id="reduction-operation">Reduction operation</h3>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>e <span class="op">=</span> torch.randint(size<span class="op">=</span>(<span class="dv">2</span>,<span class="dv">3</span>), low<span class="op">=</span><span class="dv">0</span>, high<span class="op">=</span><span class="dv">10</span>, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>e</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>tensor([[5., 1., 7.],
        [7., 1., 5.]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co"># sum</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">sum</span>(e)</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a><span class="co"># sum along columns</span></span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">sum</span>(e, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a><span class="co"># sum along rows</span></span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">sum</span>(e, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a><span class="co"># mean</span></span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a>torch.mean(e)</span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a><span class="co"># mean along col</span></span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a>torch.mean(e, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a><span class="co"># mean along row</span></span>
<span id="cb61-12"><a href="#cb61-12" aria-hidden="true" tabindex="-1"></a>torch.mean(e, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb61-13"><a href="#cb61-13" aria-hidden="true" tabindex="-1"></a><span class="co"># median</span></span>
<span id="cb61-14"><a href="#cb61-14" aria-hidden="true" tabindex="-1"></a>torch.median(e)</span>
<span id="cb61-15"><a href="#cb61-15" aria-hidden="true" tabindex="-1"></a>torch.median(e, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb61-16"><a href="#cb61-16" aria-hidden="true" tabindex="-1"></a>torch.median(e, dim<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>torch.return_types.median(
values=tensor([5., 5.]),
indices=tensor([0, 2]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># max and min</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">max</span>(e)</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">max</span>(e, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">max</span>(e, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">min</span>(e)</span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">min</span>(e, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">min</span>(e, dim<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>torch.return_types.min(
values=tensor([1., 1.]),
indices=tensor([1, 1]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co"># product</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>torch.prod(e)</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a><span class="co">#do yourself dimension-wise</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>tensor(1225.)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co"># standard deviation</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>torch.std(e)</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a><span class="co">#do yourself dimension-wise</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>tensor(2.7325)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="co"># variance</span></span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>torch.var(e)</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a><span class="co">#do yourself dimension-wise</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>tensor(7.4667)</code></pre>
</div>
</div>
<p>Which value is the biggest here? How to get its position/index? Use <code>argmax</code>.</p>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="co"># argmax</span></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>torch.argmax(e)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>tensor(2)</code></pre>
</div>
</div>
<p>Which value is the smallest here? How to get its position/index? Use <code>argmin</code>.</p>
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="co"># argmin</span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>torch.argmin(e)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>tensor(1)</code></pre>
</div>
</div>
</section>
<section id="matrix-operations" class="level3">
<h3 class="anchored" data-anchor-id="matrix-operations">Matrix operations</h3>
<div class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>m1 <span class="op">=</span> torch.randint(size<span class="op">=</span>(<span class="dv">2</span>,<span class="dv">3</span>), low<span class="op">=</span><span class="dv">0</span>, high<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>m2 <span class="op">=</span> torch.randint(size<span class="op">=</span>(<span class="dv">3</span>,<span class="dv">2</span>), low<span class="op">=</span><span class="dv">0</span>, high<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(m1)</span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(m2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[8, 9, 1],
        [2, 4, 5]])
tensor([[6, 5],
        [6, 2],
        [0, 6]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co"># matrix multiplcation</span></span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>torch.matmul(m1, m2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>tensor([[102,  64],
        [ 36,  48]])</code></pre>
</div>
</div>
</section>
<section id="dot-products" class="level3">
<h3 class="anchored" data-anchor-id="dot-products">Dot products:</h3>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>vector1 <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">2</span>])</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>vector2 <span class="op">=</span> torch.tensor([<span class="dv">3</span>, <span class="dv">4</span>])</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a><span class="co"># dot product</span></span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a>torch.dot(vector1, vector2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="40">
<pre><code>tensor(11)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co"># transpose</span></span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a>torch.transpose(m2, <span class="dv">0</span>, <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>tensor([[6, 6, 0],
        [5, 2, 6]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> torch.randint(size<span class="op">=</span>(<span class="dv">3</span>,<span class="dv">3</span>), low<span class="op">=</span><span class="dv">0</span>, high<span class="op">=</span><span class="dv">8</span>, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>h</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>tensor([[7., 1., 3.],
        [3., 2., 2.],
        [7., 2., 4.]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="co"># determinant</span></span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>torch.det(h)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>tensor(6.0000)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="co"># inverse</span></span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>torch.inverse(h)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="44">
<pre><code>tensor([[ 0.6667,  0.3333, -0.6667],
        [ 0.3333,  1.1667, -0.8333],
        [-1.3333, -1.1667,  1.8333]])</code></pre>
</div>
</div>
</section>
<section id="comparison-operations" class="level3">
<h3 class="anchored" data-anchor-id="comparison-operations">Comparison operations</h3>
<div class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>i <span class="op">=</span> torch.randint(size<span class="op">=</span>(<span class="dv">2</span>,<span class="dv">3</span>), low<span class="op">=</span><span class="dv">0</span>, high<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>j <span class="op">=</span> torch.randint(size<span class="op">=</span>(<span class="dv">2</span>,<span class="dv">3</span>), low<span class="op">=</span><span class="dv">0</span>, high<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(i)</span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(j)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[1, 0, 1],
        [7, 8, 9]])
tensor([[1, 9, 7],
        [4, 5, 9]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co"># greater than</span></span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>i <span class="op">&gt;</span> j</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a><span class="co"># less than</span></span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a>i <span class="op">&lt;</span> j</span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a><span class="co"># equal to</span></span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a>i <span class="op">==</span> j</span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a><span class="co"># not equal to</span></span>
<span id="cb91-8"><a href="#cb91-8" aria-hidden="true" tabindex="-1"></a>i <span class="op">!=</span> j</span>
<span id="cb91-9"><a href="#cb91-9" aria-hidden="true" tabindex="-1"></a><span class="co"># greater than equal to</span></span>
<span id="cb91-10"><a href="#cb91-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-11"><a href="#cb91-11" aria-hidden="true" tabindex="-1"></a><span class="co"># less than equal to</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="46">
<pre><code>tensor([[False,  True,  True],
        [ True,  True, False]])</code></pre>
</div>
</div>
</section>
<section id="special-functions" class="level3">
<h3 class="anchored" data-anchor-id="special-functions">Special functions</h3>
<div class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> torch.randint(size<span class="op">=</span>(<span class="dv">2</span>,<span class="dv">3</span>), low<span class="op">=</span><span class="dv">0</span>, high<span class="op">=</span><span class="dv">10</span>, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a>k</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="47">
<pre><code>tensor([[5., 8., 1.],
        [3., 4., 4.]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="co"># log</span></span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>torch.log(k)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="48">
<pre><code>tensor([[1.6094, 2.0794, 0.0000],
        [1.0986, 1.3863, 1.3863]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="co"># exp</span></span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a>torch.exp(k)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<pre><code>tensor([[1.4841e+02, 2.9810e+03, 2.7183e+00],
        [2.0086e+01, 5.4598e+01, 5.4598e+01]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="co"># sqrt</span></span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a>torch.sqrt(k)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="50">
<pre><code>tensor([[2.2361, 2.8284, 1.0000],
        [1.7321, 2.0000, 2.0000]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>k</span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a><span class="co"># sigmoid</span></span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a>torch.sigmoid(k)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="51">
<pre><code>tensor([[0.9933, 0.9997, 0.7311],
        [0.9526, 0.9820, 0.9820]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>k</span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a><span class="co"># softmax</span></span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a>torch.softmax(k, dim<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<pre><code>tensor([[0.8808, 0.9820, 0.0474],
        [0.1192, 0.0180, 0.9526]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="co"># relu</span></span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a>torch.relu(k)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="53">
<pre><code>tensor([[5., 8., 1.],
        [3., 4., 4.]])</code></pre>
</div>
</div>
</section>
<section id="inplace-operations" class="level3">
<h3 class="anchored" data-anchor-id="inplace-operations">Inplace Operations</h3>
<div class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> torch.rand(<span class="dv">2</span>,<span class="dv">3</span>)</span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> torch.rand(<span class="dv">2</span>,<span class="dv">3</span>)</span>
<span id="cb107-3"><a href="#cb107-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-4"><a href="#cb107-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(m)</span>
<span id="cb107-5"><a href="#cb107-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(n)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0.2179, 0.5475, 0.4801],
        [0.2278, 0.7175, 0.8381]])
tensor([[0.2569, 0.9879, 0.0779],
        [0.3233, 0.7714, 0.9524]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a>m.add_(n)</span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a>m</span>
<span id="cb109-3"><a href="#cb109-3" aria-hidden="true" tabindex="-1"></a>n</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="55">
<pre><code>tensor([[0.2569, 0.9879, 0.0779],
        [0.3233, 0.7714, 0.9524]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a>torch.relu(m)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="56">
<pre><code>tensor([[0.4748, 1.5353, 0.5580],
        [0.5511, 1.4889, 1.7905]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a>m.relu_()</span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a>m</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="57">
<pre><code>tensor([[0.4748, 1.5353, 0.5580],
        [0.5511, 1.4889, 1.7905]])</code></pre>
</div>
</div>
<p>Copying a Tensor</p>
<div class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.rand(<span class="dv">2</span>,<span class="dv">3</span>)</span>
<span id="cb115-2"><a href="#cb115-2" aria-hidden="true" tabindex="-1"></a>a</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="58">
<pre><code>tensor([[0.1013, 0.2033, 0.2292],
        [0.6055, 0.3249, 0.9225]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> a</span>
<span id="cb117-2"><a href="#cb117-2" aria-hidden="true" tabindex="-1"></a>a</span>
<span id="cb117-3"><a href="#cb117-3" aria-hidden="true" tabindex="-1"></a>b</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="59">
<pre><code>tensor([[0.1013, 0.2033, 0.2292],
        [0.6055, 0.3249, 0.9225]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a>a[<span class="dv">0</span>][<span class="dv">0</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb119-2"><a href="#cb119-2" aria-hidden="true" tabindex="-1"></a>a</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="60">
<pre><code>tensor([[0.0000, 0.2033, 0.2292],
        [0.6055, 0.3249, 0.9225]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a>b</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="61">
<pre><code>tensor([[0.0000, 0.2033, 0.2292],
        [0.6055, 0.3249, 0.9225]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="62">
<div class="sourceCode cell-code" id="cb123"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a><span class="bu">id</span>(a)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="62">
<pre><code>4843282960</code></pre>
</div>
</div>
<div class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="bu">id</span>(b)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="63">
<pre><code>4843282960</code></pre>
</div>
</div>
<p>Better way of making a copy</p>
<div class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> a.clone()</span>
<span id="cb127-2"><a href="#cb127-2" aria-hidden="true" tabindex="-1"></a>a</span>
<span id="cb127-3"><a href="#cb127-3" aria-hidden="true" tabindex="-1"></a>b</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="64">
<pre><code>tensor([[0.0000, 0.2033, 0.2292],
        [0.6055, 0.3249, 0.9225]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a>a[<span class="dv">0</span>][<span class="dv">0</span>] <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb129-2"><a href="#cb129-2" aria-hidden="true" tabindex="-1"></a>a</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="65">
<pre><code>tensor([[10.0000,  0.2033,  0.2292],
        [ 0.6055,  0.3249,  0.9225]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb131"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a>b</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="66">
<pre><code>tensor([[0.0000, 0.2033, 0.2292],
        [0.6055, 0.3249, 0.9225]])</code></pre>
</div>
</div>
<p>Now, let’s check their memory locations. They are at different locations.</p>
<div class="cell" data-execution_count="67">
<div class="sourceCode cell-code" id="cb133"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a><span class="bu">id</span>(a)</span>
<span id="cb133-2"><a href="#cb133-2" aria-hidden="true" tabindex="-1"></a><span class="bu">id</span>(b)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="67">
<pre><code>4843283344</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="autograd" class="level1">
<h1>Autograd</h1>
<p>Let’s go hard way. Let’s define our own differentiation formula. Our equation was <span class="math inline">\(y = x^2\)</span>. So, the derivative <span class="math inline">\(\frac{dy}{dx}\)</span> will be <span class="math inline">\(2x\)</span>.</p>
<div class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb135"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> dy_dx(x):</span>
<span id="cb135-2"><a href="#cb135-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> <span class="dv">2</span><span class="op">*</span>x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s check for <span class="math inline">\(x = 3\)</span> now.</p>
<div class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb136"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a>dy_dx(<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="69">
<pre><code>6</code></pre>
</div>
</div>
<p>But using <code>PyTorch</code>, it will be easy.</p>
<div class="cell" data-execution_count="70">
<div class="sourceCode cell-code" id="cb138"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a><span class="co">#import torch</span></span>
<span id="cb138-2"><a href="#cb138-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor(<span class="fl">3.0</span>, requires_grad<span class="op">=</span><span class="va">True</span>) <span class="co">#gradient calculation requirement is set as True</span></span>
<span id="cb138-3"><a href="#cb138-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x<span class="op">**</span><span class="dv">2</span></span>
<span id="cb138-4"><a href="#cb138-4" aria-hidden="true" tabindex="-1"></a>x</span>
<span id="cb138-5"><a href="#cb138-5" aria-hidden="true" tabindex="-1"></a>y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="70">
<pre><code>tensor(9., grad_fn=&lt;PowBackward0&gt;)</code></pre>
</div>
</div>
<p>We need to use <code>backward</code> on the last calculation (or variable) though, to calculate the gradient.</p>
<div class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb140"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a>y.backward()</span>
<span id="cb140-2"><a href="#cb140-2" aria-hidden="true" tabindex="-1"></a>x.grad</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="71">
<pre><code>tensor(6.)</code></pre>
</div>
</div>
<p>Now, let’s make the situation a bit complex. Let’s say we have another equation <span class="math inline">\(z = sin(y)\)</span>. So, if we want to calculate <span class="math inline">\(\frac{dz}{dx}\)</span>, it requires a chain formula to calculate the derivative. And it will be: <span class="math display">\[\frac{dz}{dx} = \frac{dz}{dy}*\frac{dy}{dx}\]</span>. If we solve the formula, the derivative will be: <span class="math inline">\(2*x*cos(x^2)\)</span>. And yes, since we have a trigonometric formula, we need to load the math library.</p>
<div class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb142"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb142-2"><a href="#cb142-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-3"><a href="#cb142-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> dz_dx(x):</span>
<span id="cb142-4"><a href="#cb142-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">2</span> <span class="op">*</span> x <span class="op">*</span> math.cos(x<span class="op">**</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="73">
<div class="sourceCode cell-code" id="cb143"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a>dz_dx(<span class="dv">2</span>) <span class="co">#you can decide the value of your x here</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="73">
<pre><code>-2.6145744834544478</code></pre>
</div>
</div>
<p>But let’s use our friend <code>PyTorch</code> to make our life easier.</p>
<div class="cell" data-execution_count="74">
<div class="sourceCode cell-code" id="cb145"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb145-1"><a href="#cb145-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor(<span class="fl">2.0</span>, requires_grad<span class="op">=</span><span class="va">True</span>) <span class="co">#you can decide the value of your x here</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="75">
<div class="sourceCode cell-code" id="cb146"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x<span class="op">**</span><span class="dv">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="76">
<div class="sourceCode cell-code" id="cb147"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb147-1"><a href="#cb147-1" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> torch.sin(y)</span>
<span id="cb147-2"><a href="#cb147-2" aria-hidden="true" tabindex="-1"></a>x</span>
<span id="cb147-3"><a href="#cb147-3" aria-hidden="true" tabindex="-1"></a>y</span>
<span id="cb147-4"><a href="#cb147-4" aria-hidden="true" tabindex="-1"></a>z</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="76">
<pre><code>tensor(-0.7568, grad_fn=&lt;SinBackward0&gt;)</code></pre>
</div>
</div>
<p>So, let’s use <code>backward</code> on our <code>z</code>.</p>
<div class="cell" data-execution_count="77">
<div class="sourceCode cell-code" id="cb149"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb149-1"><a href="#cb149-1" aria-hidden="true" tabindex="-1"></a>z.backward()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="78">
<div class="sourceCode cell-code" id="cb150"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a>x.grad</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="78">
<pre><code>tensor(-2.6146)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="79">
<div class="sourceCode cell-code" id="cb152"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a>y.grad</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><code>y.grad</code> is not possible, since it is an intermediate leaf.</p>
<section id="real-world-example" class="level2">
<h2 class="anchored" data-anchor-id="real-world-example">Real-world example:</h2>
<p>Let’s say a student got CGPA 3.10 and did not get a placement in an institute. So, we can try to make a prediction.</p>
<div class="cell" data-execution_count="80">
<div class="sourceCode cell-code" id="cb153"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb153-1"><a href="#cb153-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb153-2"><a href="#cb153-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb153-3"><a href="#cb153-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Inputs</span></span>
<span id="cb153-4"><a href="#cb153-4" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor(<span class="fl">6.70</span>)  <span class="co"># Input feature</span></span>
<span id="cb153-5"><a href="#cb153-5" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.tensor(<span class="fl">0.0</span>)  <span class="co"># True label (binary)</span></span>
<span id="cb153-6"><a href="#cb153-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb153-7"><a href="#cb153-7" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> torch.tensor(<span class="fl">1.0</span>)  <span class="co"># Weight</span></span>
<span id="cb153-8"><a href="#cb153-8" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.tensor(<span class="fl">0.0</span>)  <span class="co"># Bias</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="81">
<div class="sourceCode cell-code" id="cb154"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Binary Cross-Entropy Loss for scalar</span></span>
<span id="cb154-2"><a href="#cb154-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> binary_cross_entropy_loss(prediction, target):</span>
<span id="cb154-3"><a href="#cb154-3" aria-hidden="true" tabindex="-1"></a>    epsilon <span class="op">=</span> <span class="fl">1e-8</span>  <span class="co"># To prevent log(0)</span></span>
<span id="cb154-4"><a href="#cb154-4" aria-hidden="true" tabindex="-1"></a>    prediction <span class="op">=</span> torch.clamp(prediction, epsilon, <span class="dv">1</span> <span class="op">-</span> epsilon)</span>
<span id="cb154-5"><a href="#cb154-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span>(target <span class="op">*</span> torch.log(prediction) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> target) <span class="op">*</span> torch.log(<span class="dv">1</span> <span class="op">-</span> prediction))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="82">
<div class="sourceCode cell-code" id="cb155"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Forward pass</span></span>
<span id="cb155-2"><a href="#cb155-2" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> w <span class="op">*</span> x <span class="op">+</span> b  <span class="co"># Weighted sum (linear part)</span></span>
<span id="cb155-3"><a href="#cb155-3" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> torch.sigmoid(z)  <span class="co"># Predicted probability</span></span>
<span id="cb155-4"><a href="#cb155-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-5"><a href="#cb155-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute binary cross-entropy loss</span></span>
<span id="cb155-6"><a href="#cb155-6" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> binary_cross_entropy_loss(y_pred, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="83">
<div class="sourceCode cell-code" id="cb156"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb156-1"><a href="#cb156-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Derivatives:</span></span>
<span id="cb156-2"><a href="#cb156-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. dL/d(y_pred): Loss with respect to the prediction (y_pred)</span></span>
<span id="cb156-3"><a href="#cb156-3" aria-hidden="true" tabindex="-1"></a>dloss_dy_pred <span class="op">=</span> (y_pred <span class="op">-</span> y)<span class="op">/</span>(y_pred<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>y_pred))</span>
<span id="cb156-4"><a href="#cb156-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb156-5"><a href="#cb156-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. dy_pred/dz: Prediction (y_pred) with respect to z (sigmoid derivative)</span></span>
<span id="cb156-6"><a href="#cb156-6" aria-hidden="true" tabindex="-1"></a>dy_pred_dz <span class="op">=</span> y_pred <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> y_pred)</span>
<span id="cb156-7"><a href="#cb156-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb156-8"><a href="#cb156-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. dz/dw and dz/db: z with respect to w and b</span></span>
<span id="cb156-9"><a href="#cb156-9" aria-hidden="true" tabindex="-1"></a>dz_dw <span class="op">=</span> x  <span class="co"># dz/dw = x</span></span>
<span id="cb156-10"><a href="#cb156-10" aria-hidden="true" tabindex="-1"></a>dz_db <span class="op">=</span> <span class="dv">1</span>  <span class="co"># dz/db = 1 (bias contributes directly to z)</span></span>
<span id="cb156-11"><a href="#cb156-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb156-12"><a href="#cb156-12" aria-hidden="true" tabindex="-1"></a>dL_dw <span class="op">=</span> dloss_dy_pred <span class="op">*</span> dy_pred_dz <span class="op">*</span> dz_dw</span>
<span id="cb156-13"><a href="#cb156-13" aria-hidden="true" tabindex="-1"></a>dL_db <span class="op">=</span> dloss_dy_pred <span class="op">*</span> dy_pred_dz <span class="op">*</span> dz_db</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="84">
<div class="sourceCode cell-code" id="cb157"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb157-1"><a href="#cb157-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Manual Gradient of loss w.r.t weight (dw): </span><span class="sc">{</span>dL_dw<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb157-2"><a href="#cb157-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Manual Gradient of loss w.r.t bias (db): </span><span class="sc">{</span>dL_db<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Manual Gradient of loss w.r.t weight (dw): 6.691762447357178
Manual Gradient of loss w.r.t bias (db): 0.998770534992218</code></pre>
</div>
</div>
<p>But let’s use our friend again.</p>
<div class="cell" data-execution_count="85">
<div class="sourceCode cell-code" id="cb159"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb159-1"><a href="#cb159-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor(<span class="fl">6.7</span>)</span>
<span id="cb159-2"><a href="#cb159-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.tensor(<span class="fl">0.0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="86">
<div class="sourceCode cell-code" id="cb160"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb160-1"><a href="#cb160-1" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> torch.tensor(<span class="fl">1.0</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb160-2"><a href="#cb160-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.tensor(<span class="fl">0.0</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb160-3"><a href="#cb160-3" aria-hidden="true" tabindex="-1"></a>w</span>
<span id="cb160-4"><a href="#cb160-4" aria-hidden="true" tabindex="-1"></a>b</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="86">
<pre><code>tensor(0., requires_grad=True)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="87">
<div class="sourceCode cell-code" id="cb162"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb162-1"><a href="#cb162-1" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> w<span class="op">*</span>x <span class="op">+</span> b</span>
<span id="cb162-2"><a href="#cb162-2" aria-hidden="true" tabindex="-1"></a>z</span>
<span id="cb162-3"><a href="#cb162-3" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> torch.sigmoid(z)</span>
<span id="cb162-4"><a href="#cb162-4" aria-hidden="true" tabindex="-1"></a>y_pred</span>
<span id="cb162-5"><a href="#cb162-5" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> binary_cross_entropy_loss(y_pred, y)</span>
<span id="cb162-6"><a href="#cb162-6" aria-hidden="true" tabindex="-1"></a>loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="87">
<pre><code>tensor(6.7012, grad_fn=&lt;NegBackward0&gt;)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="88">
<div class="sourceCode cell-code" id="cb164"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb164-1"><a href="#cb164-1" aria-hidden="true" tabindex="-1"></a>loss.backward()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="89">
<div class="sourceCode cell-code" id="cb165"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb165-1"><a href="#cb165-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(w.grad)</span>
<span id="cb165-2"><a href="#cb165-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(b.grad)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor(6.6918)
tensor(0.9988)</code></pre>
</div>
</div>
<p>Let’s insert multiple values (or a vector).</p>
<div class="cell" data-execution_count="90">
<div class="sourceCode cell-code" id="cb167"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb167-1"><a href="#cb167-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="fl">1.0</span>, <span class="fl">2.0</span>, <span class="fl">3.0</span>], requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb167-2"><a href="#cb167-2" aria-hidden="true" tabindex="-1"></a>x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="90">
<pre><code>tensor([1., 2., 3.], requires_grad=True)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="91">
<div class="sourceCode cell-code" id="cb169"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb169-1"><a href="#cb169-1" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> (x<span class="op">**</span><span class="dv">2</span>).mean()</span>
<span id="cb169-2"><a href="#cb169-2" aria-hidden="true" tabindex="-1"></a>y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="91">
<pre><code>tensor(4.6667, grad_fn=&lt;MeanBackward0&gt;)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="92">
<div class="sourceCode cell-code" id="cb171"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb171-1"><a href="#cb171-1" aria-hidden="true" tabindex="-1"></a>y.backward()</span>
<span id="cb171-2"><a href="#cb171-2" aria-hidden="true" tabindex="-1"></a>x.grad</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="92">
<pre><code>tensor([0.6667, 1.3333, 2.0000])</code></pre>
</div>
</div>
<p>If we rerun all these things, the values get updtaed. So, we need to stop this behavior. How to do it?</p>
<div class="cell" data-execution_count="93">
<div class="sourceCode cell-code" id="cb173"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb173-1"><a href="#cb173-1" aria-hidden="true" tabindex="-1"></a><span class="co"># clearing grad</span></span>
<span id="cb173-2"><a href="#cb173-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor(<span class="fl">2.0</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb173-3"><a href="#cb173-3" aria-hidden="true" tabindex="-1"></a>x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="93">
<pre><code>tensor(2., requires_grad=True)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="94">
<div class="sourceCode cell-code" id="cb175"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb175-1"><a href="#cb175-1" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb175-2"><a href="#cb175-2" aria-hidden="true" tabindex="-1"></a>y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="94">
<pre><code>tensor(4., grad_fn=&lt;PowBackward0&gt;)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="95">
<div class="sourceCode cell-code" id="cb177"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb177-1"><a href="#cb177-1" aria-hidden="true" tabindex="-1"></a>y.backward()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="96">
<div class="sourceCode cell-code" id="cb178"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb178-1"><a href="#cb178-1" aria-hidden="true" tabindex="-1"></a>x.grad</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="96">
<pre><code>tensor(4.)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="97">
<div class="sourceCode cell-code" id="cb180"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb180-1"><a href="#cb180-1" aria-hidden="true" tabindex="-1"></a>x.grad.zero_()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="97">
<pre><code>tensor(0.)</code></pre>
</div>
</div>
<p>Now, we don’t see <code>requires_grad=True</code> part here. So, it is off. Another way:</p>
<div class="cell" data-execution_count="98">
<div class="sourceCode cell-code" id="cb182"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb182-1"><a href="#cb182-1" aria-hidden="true" tabindex="-1"></a><span class="co"># option 1 - requires_grad_(False)</span></span>
<span id="cb182-2"><a href="#cb182-2" aria-hidden="true" tabindex="-1"></a><span class="co"># option 2 - detach()</span></span>
<span id="cb182-3"><a href="#cb182-3" aria-hidden="true" tabindex="-1"></a><span class="co"># option 3 - torch.no_grad()</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="99">
<div class="sourceCode cell-code" id="cb183"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb183-1"><a href="#cb183-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor(<span class="fl">2.0</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb183-2"><a href="#cb183-2" aria-hidden="true" tabindex="-1"></a>x</span>
<span id="cb183-3"><a href="#cb183-3" aria-hidden="true" tabindex="-1"></a>x.requires_grad_(<span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="99">
<pre><code>tensor(2.)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="100">
<div class="sourceCode cell-code" id="cb185"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb185-1"><a href="#cb185-1" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb185-2"><a href="#cb185-2" aria-hidden="true" tabindex="-1"></a>y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="100">
<pre><code>tensor(4.)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="101">
<div class="sourceCode cell-code" id="cb187"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb187-1"><a href="#cb187-1" aria-hidden="true" tabindex="-1"></a><span class="co">#not possible now</span></span>
<span id="cb187-2"><a href="#cb187-2" aria-hidden="true" tabindex="-1"></a>y.backward()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn</code></pre>
</div>
</div>
<div class="cell" data-execution_count="102">
<div class="sourceCode cell-code" id="cb189"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb189-1"><a href="#cb189-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor(<span class="fl">2.0</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb189-2"><a href="#cb189-2" aria-hidden="true" tabindex="-1"></a>x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="102">
<pre><code>tensor(2., requires_grad=True)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="103">
<div class="sourceCode cell-code" id="cb191"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb191-1"><a href="#cb191-1" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> x.detach()</span>
<span id="cb191-2"><a href="#cb191-2" aria-hidden="true" tabindex="-1"></a>z</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="103">
<pre><code>tensor(2.)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="104">
<div class="sourceCode cell-code" id="cb193"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb193-1"><a href="#cb193-1" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb193-2"><a href="#cb193-2" aria-hidden="true" tabindex="-1"></a>y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="104">
<pre><code>tensor(4., grad_fn=&lt;PowBackward0&gt;)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="105">
<div class="sourceCode cell-code" id="cb195"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb195-1"><a href="#cb195-1" aria-hidden="true" tabindex="-1"></a>y1 <span class="op">=</span> z <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb195-2"><a href="#cb195-2" aria-hidden="true" tabindex="-1"></a>y1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="105">
<pre><code>tensor(4.)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="106">
<div class="sourceCode cell-code" id="cb197"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb197-1"><a href="#cb197-1" aria-hidden="true" tabindex="-1"></a>y.backward() <span class="co">#possible</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="107">
<div class="sourceCode cell-code" id="cb198"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb198-1"><a href="#cb198-1" aria-hidden="true" tabindex="-1"></a>y1.backward() <span class="co">#not possible</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn</code></pre>
</div>
</div>
</section>
</section>
<section id="pytorch-trining-pipeline" class="level1">
<h1>PyTorch Trining Pipeline</h1>
<div class="cell" data-execution_count="108">
<div class="sourceCode cell-code" id="cb200"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb200-1"><a href="#cb200-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb200-2"><a href="#cb200-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb200-3"><a href="#cb200-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb200-4"><a href="#cb200-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb200-5"><a href="#cb200-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb200-6"><a href="#cb200-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Load an example dataset</p>
<div class="cell" data-execution_count="109">
<div class="sourceCode cell-code" id="cb201"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb201-1"><a href="#cb201-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv'</span>)</span>
<span id="cb201-2"><a href="#cb201-2" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="109">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">diagnosis</th>
<th data-quarto-table-cell-role="th">radius_mean</th>
<th data-quarto-table-cell-role="th">texture_mean</th>
<th data-quarto-table-cell-role="th">perimeter_mean</th>
<th data-quarto-table-cell-role="th">area_mean</th>
<th data-quarto-table-cell-role="th">smoothness_mean</th>
<th data-quarto-table-cell-role="th">compactness_mean</th>
<th data-quarto-table-cell-role="th">concavity_mean</th>
<th data-quarto-table-cell-role="th">concave points_mean</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">texture_worst</th>
<th data-quarto-table-cell-role="th">perimeter_worst</th>
<th data-quarto-table-cell-role="th">area_worst</th>
<th data-quarto-table-cell-role="th">smoothness_worst</th>
<th data-quarto-table-cell-role="th">compactness_worst</th>
<th data-quarto-table-cell-role="th">concavity_worst</th>
<th data-quarto-table-cell-role="th">concave points_worst</th>
<th data-quarto-table-cell-role="th">symmetry_worst</th>
<th data-quarto-table-cell-role="th">fractal_dimension_worst</th>
<th data-quarto-table-cell-role="th">Unnamed: 32</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>842302</td>
<td>M</td>
<td>17.99</td>
<td>10.38</td>
<td>122.80</td>
<td>1001.0</td>
<td>0.11840</td>
<td>0.27760</td>
<td>0.3001</td>
<td>0.14710</td>
<td>...</td>
<td>17.33</td>
<td>184.60</td>
<td>2019.0</td>
<td>0.1622</td>
<td>0.6656</td>
<td>0.7119</td>
<td>0.2654</td>
<td>0.4601</td>
<td>0.11890</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>842517</td>
<td>M</td>
<td>20.57</td>
<td>17.77</td>
<td>132.90</td>
<td>1326.0</td>
<td>0.08474</td>
<td>0.07864</td>
<td>0.0869</td>
<td>0.07017</td>
<td>...</td>
<td>23.41</td>
<td>158.80</td>
<td>1956.0</td>
<td>0.1238</td>
<td>0.1866</td>
<td>0.2416</td>
<td>0.1860</td>
<td>0.2750</td>
<td>0.08902</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>84300903</td>
<td>M</td>
<td>19.69</td>
<td>21.25</td>
<td>130.00</td>
<td>1203.0</td>
<td>0.10960</td>
<td>0.15990</td>
<td>0.1974</td>
<td>0.12790</td>
<td>...</td>
<td>25.53</td>
<td>152.50</td>
<td>1709.0</td>
<td>0.1444</td>
<td>0.4245</td>
<td>0.4504</td>
<td>0.2430</td>
<td>0.3613</td>
<td>0.08758</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>84348301</td>
<td>M</td>
<td>11.42</td>
<td>20.38</td>
<td>77.58</td>
<td>386.1</td>
<td>0.14250</td>
<td>0.28390</td>
<td>0.2414</td>
<td>0.10520</td>
<td>...</td>
<td>26.50</td>
<td>98.87</td>
<td>567.7</td>
<td>0.2098</td>
<td>0.8663</td>
<td>0.6869</td>
<td>0.2575</td>
<td>0.6638</td>
<td>0.17300</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>84358402</td>
<td>M</td>
<td>20.29</td>
<td>14.34</td>
<td>135.10</td>
<td>1297.0</td>
<td>0.10030</td>
<td>0.13280</td>
<td>0.1980</td>
<td>0.10430</td>
<td>...</td>
<td>16.67</td>
<td>152.20</td>
<td>1575.0</td>
<td>0.1374</td>
<td>0.2050</td>
<td>0.4000</td>
<td>0.1625</td>
<td>0.2364</td>
<td>0.07678</td>
<td>NaN</td>
</tr>
</tbody>
</table>

<p>5 rows × 33 columns</p>
</div>
</div>
</div>
<div class="cell" data-execution_count="110">
<div class="sourceCode cell-code" id="cb202"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb202-1"><a href="#cb202-1" aria-hidden="true" tabindex="-1"></a>df.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="110">
<pre><code>(569, 33)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="111">
<div class="sourceCode cell-code" id="cb204"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb204-1"><a href="#cb204-1" aria-hidden="true" tabindex="-1"></a>df.drop(columns<span class="op">=</span>[<span class="st">'id'</span>, <span class="st">'Unnamed: 32'</span>], inplace<span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb204-2"><a href="#cb204-2" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="111">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">diagnosis</th>
<th data-quarto-table-cell-role="th">radius_mean</th>
<th data-quarto-table-cell-role="th">texture_mean</th>
<th data-quarto-table-cell-role="th">perimeter_mean</th>
<th data-quarto-table-cell-role="th">area_mean</th>
<th data-quarto-table-cell-role="th">smoothness_mean</th>
<th data-quarto-table-cell-role="th">compactness_mean</th>
<th data-quarto-table-cell-role="th">concavity_mean</th>
<th data-quarto-table-cell-role="th">concave points_mean</th>
<th data-quarto-table-cell-role="th">symmetry_mean</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">radius_worst</th>
<th data-quarto-table-cell-role="th">texture_worst</th>
<th data-quarto-table-cell-role="th">perimeter_worst</th>
<th data-quarto-table-cell-role="th">area_worst</th>
<th data-quarto-table-cell-role="th">smoothness_worst</th>
<th data-quarto-table-cell-role="th">compactness_worst</th>
<th data-quarto-table-cell-role="th">concavity_worst</th>
<th data-quarto-table-cell-role="th">concave points_worst</th>
<th data-quarto-table-cell-role="th">symmetry_worst</th>
<th data-quarto-table-cell-role="th">fractal_dimension_worst</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>M</td>
<td>17.99</td>
<td>10.38</td>
<td>122.80</td>
<td>1001.0</td>
<td>0.11840</td>
<td>0.27760</td>
<td>0.3001</td>
<td>0.14710</td>
<td>0.2419</td>
<td>...</td>
<td>25.38</td>
<td>17.33</td>
<td>184.60</td>
<td>2019.0</td>
<td>0.1622</td>
<td>0.6656</td>
<td>0.7119</td>
<td>0.2654</td>
<td>0.4601</td>
<td>0.11890</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>M</td>
<td>20.57</td>
<td>17.77</td>
<td>132.90</td>
<td>1326.0</td>
<td>0.08474</td>
<td>0.07864</td>
<td>0.0869</td>
<td>0.07017</td>
<td>0.1812</td>
<td>...</td>
<td>24.99</td>
<td>23.41</td>
<td>158.80</td>
<td>1956.0</td>
<td>0.1238</td>
<td>0.1866</td>
<td>0.2416</td>
<td>0.1860</td>
<td>0.2750</td>
<td>0.08902</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>M</td>
<td>19.69</td>
<td>21.25</td>
<td>130.00</td>
<td>1203.0</td>
<td>0.10960</td>
<td>0.15990</td>
<td>0.1974</td>
<td>0.12790</td>
<td>0.2069</td>
<td>...</td>
<td>23.57</td>
<td>25.53</td>
<td>152.50</td>
<td>1709.0</td>
<td>0.1444</td>
<td>0.4245</td>
<td>0.4504</td>
<td>0.2430</td>
<td>0.3613</td>
<td>0.08758</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>M</td>
<td>11.42</td>
<td>20.38</td>
<td>77.58</td>
<td>386.1</td>
<td>0.14250</td>
<td>0.28390</td>
<td>0.2414</td>
<td>0.10520</td>
<td>0.2597</td>
<td>...</td>
<td>14.91</td>
<td>26.50</td>
<td>98.87</td>
<td>567.7</td>
<td>0.2098</td>
<td>0.8663</td>
<td>0.6869</td>
<td>0.2575</td>
<td>0.6638</td>
<td>0.17300</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>M</td>
<td>20.29</td>
<td>14.34</td>
<td>135.10</td>
<td>1297.0</td>
<td>0.10030</td>
<td>0.13280</td>
<td>0.1980</td>
<td>0.10430</td>
<td>0.1809</td>
<td>...</td>
<td>22.54</td>
<td>16.67</td>
<td>152.20</td>
<td>1575.0</td>
<td>0.1374</td>
<td>0.2050</td>
<td>0.4000</td>
<td>0.1625</td>
<td>0.2364</td>
<td>0.07678</td>
</tr>
</tbody>
</table>

<p>5 rows × 31 columns</p>
</div>
</div>
</div>
<section id="train-test-split" class="level2">
<h2 class="anchored" data-anchor-id="train-test-split">Train test split</h2>
<div class="cell" data-execution_count="112">
<div class="sourceCode cell-code" id="cb205"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb205-1"><a href="#cb205-1" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(df.iloc[:, <span class="dv">1</span>:], df.iloc[:, <span class="dv">0</span>], test_size<span class="op">=</span><span class="fl">0.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="scaling" class="level2">
<h2 class="anchored" data-anchor-id="scaling">Scaling</h2>
<div class="cell" data-execution_count="113">
<div class="sourceCode cell-code" id="cb206"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb206-1"><a href="#cb206-1" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb206-2"><a href="#cb206-2" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb206-3"><a href="#cb206-3" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> scaler.transform(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="114">
<div class="sourceCode cell-code" id="cb207"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb207-1"><a href="#cb207-1" aria-hidden="true" tabindex="-1"></a>X_train</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="114">
<pre><code>array([[-0.30279106, -0.87388841, -0.21264979, ...,  1.24614994,
         0.37827849,  3.01811359],
       [ 1.13805311,  0.18496661,  1.10187355, ...,  1.1649544 ,
         0.24425606, -0.02325634],
       [ 1.80801761, -0.44507608,  1.71875391, ...,  1.43560621,
        -0.35246286, -0.72605794],
       ...,
       [-0.8774468 , -1.04876718, -0.89852335, ..., -0.90462979,
        -0.51041787,  0.39960221],
       [-0.4233286 ,  1.10966806, -0.39609053, ...,  0.84017222,
         0.7548177 ,  1.01622631],
       [-0.08133835, -0.61995485, -0.14122154, ..., -0.80448862,
        -0.36841791, -0.3818832 ]], shape=(455, 30))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="115">
<div class="sourceCode cell-code" id="cb209"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb209-1"><a href="#cb209-1" aria-hidden="true" tabindex="-1"></a>y_train</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="115">
<pre><code>105    M
6      M
373    M
295    B
157    B
      ..
276    B
113    B
398    B
64     M
477    B
Name: diagnosis, Length: 455, dtype: object</code></pre>
</div>
</div>
</section>
<section id="label-encoding" class="level2">
<h2 class="anchored" data-anchor-id="label-encoding">Label Encoding</h2>
<div class="cell" data-execution_count="116">
<div class="sourceCode cell-code" id="cb211"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb211-1"><a href="#cb211-1" aria-hidden="true" tabindex="-1"></a>encoder <span class="op">=</span> LabelEncoder()</span>
<span id="cb211-2"><a href="#cb211-2" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> encoder.fit_transform(y_train)</span>
<span id="cb211-3"><a href="#cb211-3" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> encoder.transform(y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="117">
<div class="sourceCode cell-code" id="cb212"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb212-1"><a href="#cb212-1" aria-hidden="true" tabindex="-1"></a>y_train</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="117">
<pre><code>array([1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0,
       1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1,
       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,
       1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1,
       1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0,
       0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,
       0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,
       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1,
       0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1,
       0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,
       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,
       1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,
       0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1,
       1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0])</code></pre>
</div>
</div>
</section>
<section id="numpy-arrays-to-pytorch-tensors" class="level2">
<h2 class="anchored" data-anchor-id="numpy-arrays-to-pytorch-tensors">Numpy arrays to PyTorch tensors</h2>
<div class="cell" data-execution_count="118">
<div class="sourceCode cell-code" id="cb214"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb214-1"><a href="#cb214-1" aria-hidden="true" tabindex="-1"></a>X_train_tensor <span class="op">=</span> torch.from_numpy(X_train)</span>
<span id="cb214-2"><a href="#cb214-2" aria-hidden="true" tabindex="-1"></a>X_test_tensor <span class="op">=</span> torch.from_numpy(X_test)</span>
<span id="cb214-3"><a href="#cb214-3" aria-hidden="true" tabindex="-1"></a>y_train_tensor <span class="op">=</span> torch.from_numpy(y_train)</span>
<span id="cb214-4"><a href="#cb214-4" aria-hidden="true" tabindex="-1"></a>y_test_tensor <span class="op">=</span> torch.from_numpy(y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="119">
<div class="sourceCode cell-code" id="cb215"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb215-1"><a href="#cb215-1" aria-hidden="true" tabindex="-1"></a>X_train_tensor.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="119">
<pre><code>torch.Size([455, 30])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="120">
<div class="sourceCode cell-code" id="cb217"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb217-1"><a href="#cb217-1" aria-hidden="true" tabindex="-1"></a>y_train_tensor.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="120">
<pre><code>torch.Size([455])</code></pre>
</div>
</div>
</section>
<section id="defining-the-model" class="level2">
<h2 class="anchored" data-anchor-id="defining-the-model">Defining the model</h2>
<div class="cell" data-execution_count="121">
<div class="sourceCode cell-code" id="cb219"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb219-1"><a href="#cb219-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MySimpleNN():</span>
<span id="cb219-2"><a href="#cb219-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb219-3"><a href="#cb219-3" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, X):</span>
<span id="cb219-4"><a href="#cb219-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb219-5"><a href="#cb219-5" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.weights <span class="op">=</span> torch.rand(X.shape[<span class="dv">1</span>], <span class="dv">1</span>, dtype<span class="op">=</span>torch.float64, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb219-6"><a href="#cb219-6" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.bias <span class="op">=</span> torch.zeros(<span class="dv">1</span>, dtype<span class="op">=</span>torch.float64, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb219-7"><a href="#cb219-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb219-8"><a href="#cb219-8" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> forward(<span class="va">self</span>, X):</span>
<span id="cb219-9"><a href="#cb219-9" aria-hidden="true" tabindex="-1"></a>    z <span class="op">=</span> torch.matmul(X, <span class="va">self</span>.weights) <span class="op">+</span> <span class="va">self</span>.bias</span>
<span id="cb219-10"><a href="#cb219-10" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> torch.sigmoid(z)</span>
<span id="cb219-11"><a href="#cb219-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> y_pred</span>
<span id="cb219-12"><a href="#cb219-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb219-13"><a href="#cb219-13" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> loss_function(<span class="va">self</span>, y_pred, y):</span>
<span id="cb219-14"><a href="#cb219-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Clamp predictions to avoid log(0)</span></span>
<span id="cb219-15"><a href="#cb219-15" aria-hidden="true" tabindex="-1"></a>    epsilon <span class="op">=</span> <span class="fl">1e-7</span></span>
<span id="cb219-16"><a href="#cb219-16" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> torch.clamp(y_pred, epsilon, <span class="dv">1</span> <span class="op">-</span> epsilon)</span>
<span id="cb219-17"><a href="#cb219-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb219-18"><a href="#cb219-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate loss</span></span>
<span id="cb219-19"><a href="#cb219-19" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> <span class="op">-</span>(y_train_tensor <span class="op">*</span> torch.log(y_pred) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> y_train_tensor) <span class="op">*</span> torch.log(<span class="dv">1</span> <span class="op">-</span> y_pred)).mean()</span>
<span id="cb219-20"><a href="#cb219-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="important-parameters" class="level2">
<h2 class="anchored" data-anchor-id="important-parameters">Important Parameters</h2>
<div class="cell" data-execution_count="122">
<div class="sourceCode cell-code" id="cb220"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb220-1"><a href="#cb220-1" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb220-2"><a href="#cb220-2" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">25</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="training-pipeline" class="level2">
<h2 class="anchored" data-anchor-id="training-pipeline">Training Pipeline</h2>
<div class="cell" data-execution_count="123">
<div class="sourceCode cell-code" id="cb221"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb221-1"><a href="#cb221-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create model</span></span>
<span id="cb221-2"><a href="#cb221-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> MySimpleNN(X_train_tensor)</span>
<span id="cb221-3"><a href="#cb221-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb221-4"><a href="#cb221-4" aria-hidden="true" tabindex="-1"></a><span class="co"># define loop</span></span>
<span id="cb221-5"><a href="#cb221-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb221-6"><a href="#cb221-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb221-7"><a href="#cb221-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># forward pass</span></span>
<span id="cb221-8"><a href="#cb221-8" aria-hidden="true" tabindex="-1"></a>  y_pred <span class="op">=</span> model.forward(X_train_tensor)</span>
<span id="cb221-9"><a href="#cb221-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb221-10"><a href="#cb221-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># loss calculate</span></span>
<span id="cb221-11"><a href="#cb221-11" aria-hidden="true" tabindex="-1"></a>  loss <span class="op">=</span> model.loss_function(y_pred, y_train_tensor)</span>
<span id="cb221-12"><a href="#cb221-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb221-13"><a href="#cb221-13" aria-hidden="true" tabindex="-1"></a>  <span class="co"># backward pass</span></span>
<span id="cb221-14"><a href="#cb221-14" aria-hidden="true" tabindex="-1"></a>  loss.backward()</span>
<span id="cb221-15"><a href="#cb221-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb221-16"><a href="#cb221-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># parameters update</span></span>
<span id="cb221-17"><a href="#cb221-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">with</span> torch.no_grad():</span>
<span id="cb221-18"><a href="#cb221-18" aria-hidden="true" tabindex="-1"></a>    model.weights <span class="op">-=</span> learning_rate <span class="op">*</span> model.weights.grad</span>
<span id="cb221-19"><a href="#cb221-19" aria-hidden="true" tabindex="-1"></a>    model.bias <span class="op">-=</span> learning_rate <span class="op">*</span> model.bias.grad</span>
<span id="cb221-20"><a href="#cb221-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb221-21"><a href="#cb221-21" aria-hidden="true" tabindex="-1"></a>  <span class="co"># zero gradients</span></span>
<span id="cb221-22"><a href="#cb221-22" aria-hidden="true" tabindex="-1"></a>  model.weights.grad.zero_()</span>
<span id="cb221-23"><a href="#cb221-23" aria-hidden="true" tabindex="-1"></a>  model.bias.grad.zero_()</span>
<span id="cb221-24"><a href="#cb221-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb221-25"><a href="#cb221-25" aria-hidden="true" tabindex="-1"></a>  <span class="co"># print loss in each epoch</span></span>
<span id="cb221-26"><a href="#cb221-26" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="ss">f'Epoch: </span><span class="sc">{</span>epoch <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">, Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch: 1, Loss: 4.024507996913868
Epoch: 2, Loss: 3.911315255031256
Epoch: 3, Loss: 3.7924208595523616
Epoch: 4, Loss: 3.6684245914797153
Epoch: 5, Loss: 3.5435049128151626
Epoch: 6, Loss: 3.4152885182840507
Epoch: 7, Loss: 3.2828281042647145
Epoch: 8, Loss: 3.1449099669210363
Epoch: 9, Loss: 3.0046272421071833
Epoch: 10, Loss: 2.8546900642566935
Epoch: 11, Loss: 2.702937896741921
Epoch: 12, Loss: 2.544308971894636
Epoch: 13, Loss: 2.3789788753200907
Epoch: 14, Loss: 2.215878705252132
Epoch: 15, Loss: 2.0565452380924527
Epoch: 16, Loss: 1.8981580328601702
Epoch: 17, Loss: 1.7477475634634518
Epoch: 18, Loss: 1.602497545809214
Epoch: 19, Loss: 1.457033089112328
Epoch: 20, Loss: 1.3256694838966872
Epoch: 21, Loss: 1.2100079116915423
Epoch: 22, Loss: 1.1111952324113044
Epoch: 23, Loss: 1.0296470436291785
Epoch: 24, Loss: 0.9647989062014453
Epoch: 25, Loss: 0.9150282523696833</code></pre>
</div>
</div>
<div class="cell" data-execution_count="124">
<div class="sourceCode cell-code" id="cb223"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb223-1"><a href="#cb223-1" aria-hidden="true" tabindex="-1"></a>model.bias</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="124">
<pre><code>tensor([-0.0647], dtype=torch.float64, requires_grad=True)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="125">
<div class="sourceCode cell-code" id="cb225"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb225-1"><a href="#cb225-1" aria-hidden="true" tabindex="-1"></a>model.weights</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="125">
<pre><code>tensor([[ 0.2633],
        [ 0.0192],
        [ 0.4376],
        [ 0.2976],
        [-0.0068],
        [-0.6394],
        [-0.3432],
        [ 0.0566],
        [ 0.0487],
        [ 0.6094],
        [-0.0849],
        [ 0.4802],
        [ 0.1285],
        [ 0.2909],
        [ 0.0829],
        [-0.0656],
        [-0.2591],
        [ 0.3589],
        [ 0.7048],
        [-0.0325],
        [ 0.3722],
        [ 0.2304],
        [-0.5136],
        [ 0.0255],
        [ 0.3085],
        [-0.5099],
        [ 0.2786],
        [-0.0662],
        [ 0.0550],
        [ 0.3601]], dtype=torch.float64, requires_grad=True)</code></pre>
</div>
</div>
</section>
<section id="evaluation" class="level2">
<h2 class="anchored" data-anchor-id="evaluation">Evaluation</h2>
<div class="cell" data-execution_count="126">
<div class="sourceCode cell-code" id="cb227"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb227-1"><a href="#cb227-1" aria-hidden="true" tabindex="-1"></a><span class="co"># model evaluation</span></span>
<span id="cb227-2"><a href="#cb227-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb227-3"><a href="#cb227-3" aria-hidden="true" tabindex="-1"></a>  y_pred <span class="op">=</span> model.forward(X_test_tensor)</span>
<span id="cb227-4"><a href="#cb227-4" aria-hidden="true" tabindex="-1"></a>  y_pred <span class="op">=</span> (y_pred <span class="op">&gt;</span> <span class="fl">0.9</span>).<span class="bu">float</span>()</span>
<span id="cb227-5"><a href="#cb227-5" aria-hidden="true" tabindex="-1"></a>  accuracy <span class="op">=</span> (y_pred <span class="op">==</span> y_test_tensor).<span class="bu">float</span>().mean()</span>
<span id="cb227-6"><a href="#cb227-6" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="ss">f'Accuracy: </span><span class="sc">{</span>accuracy<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.6583564281463623</code></pre>
</div>
</div>
</section>
</section>
<section id="nn-module" class="level1">
<h1>NN module</h1>
</section>
<section id="dataset-and-dataloader" class="level1">
<h1>Dataset and DataLoader</h1>
</section>
<section id="annmlp-in-pytorch" class="level1">
<h1>ANN/MLP in PyTorch</h1>
<p>We will use Fashion MNIST dataset for this purpose. We can find this dataset in Kaggle. It has 70,000 (28*28) fashion images. We will try to classify them using our ANN and improve our model. But we will use less images since we are using less local resource (CPU, not GPU).</p>
<p>Our ANN structure: 1 <code>input layer</code> with <code>28*28 = 784</code> nodes. Then we will have <code>2 hidden layers</code>. The first one will have 128 neurons and the second one will have 64 neurons. Then we will have 1 <code>output layer</code> having 10 neurons. The hidden layers will use ReLU and the last output layer will use softmax since it is a multi-class classification problems. Workflow: - DataLoader object - Training loop - Evaluation</p>
<div class="cell" data-execution_count="127">
<div class="sourceCode cell-code" id="cb229"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb229-1"><a href="#cb229-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb229-2"><a href="#cb229-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb229-3"><a href="#cb229-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb229-4"><a href="#cb229-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset, DataLoader</span>
<span id="cb229-5"><a href="#cb229-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb229-6"><a href="#cb229-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb229-7"><a href="#cb229-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, after loading the packages, we can use them. Let’s make it reproducible using a seed.</p>
<div class="cell" data-execution_count="128">
<div class="sourceCode cell-code" id="cb230"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb230-1"><a href="#cb230-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">30</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="128">
<pre><code>&lt;torch._C.Generator at 0x111c00330&gt;</code></pre>
</div>
</div>
<div class="cell" data-execution_count="129">
<div class="sourceCode cell-code" id="cb232"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb232-1"><a href="#cb232-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use Fashion-MNIST from torchvision and create a small CSV</span></span>
<span id="cb232-2"><a href="#cb232-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb232-3"><a href="#cb232-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</span>
<span id="cb232-4"><a href="#cb232-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb232-5"><a href="#cb232-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb232-6"><a href="#cb232-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Download Fashion-MNIST</span></span>
<span id="cb232-7"><a href="#cb232-7" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([transforms.ToTensor()])</span>
<span id="cb232-8"><a href="#cb232-8" aria-hidden="true" tabindex="-1"></a>fmnist <span class="op">=</span> torchvision.datasets.FashionMNIST(root<span class="op">=</span><span class="st">'./data'</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb232-9"><a href="#cb232-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb232-10"><a href="#cb232-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a small subset (first 1000 samples)</span></span>
<span id="cb232-11"><a href="#cb232-11" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb232-12"><a href="#cb232-12" aria-hidden="true" tabindex="-1"></a>images_list <span class="op">=</span> []</span>
<span id="cb232-13"><a href="#cb232-13" aria-hidden="true" tabindex="-1"></a>labels_list <span class="op">=</span> []</span>
<span id="cb232-14"><a href="#cb232-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb232-15"><a href="#cb232-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">min</span>(n_samples, <span class="bu">len</span>(fmnist))):</span>
<span id="cb232-16"><a href="#cb232-16" aria-hidden="true" tabindex="-1"></a>    image, label <span class="op">=</span> fmnist[i]</span>
<span id="cb232-17"><a href="#cb232-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert tensor to numpy and flatten</span></span>
<span id="cb232-18"><a href="#cb232-18" aria-hidden="true" tabindex="-1"></a>    image_flat <span class="op">=</span> image.numpy().flatten()</span>
<span id="cb232-19"><a href="#cb232-19" aria-hidden="true" tabindex="-1"></a>    images_list.append(image_flat)</span>
<span id="cb232-20"><a href="#cb232-20" aria-hidden="true" tabindex="-1"></a>    labels_list.append(label)</span>
<span id="cb232-21"><a href="#cb232-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb232-22"><a href="#cb232-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Create DataFrame</span></span>
<span id="cb232-23"><a href="#cb232-23" aria-hidden="true" tabindex="-1"></a>images_array <span class="op">=</span> np.array(images_list)</span>
<span id="cb232-24"><a href="#cb232-24" aria-hidden="true" tabindex="-1"></a>labels_array <span class="op">=</span> np.array(labels_list)</span>
<span id="cb232-25"><a href="#cb232-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb232-26"><a href="#cb232-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine labels and images</span></span>
<span id="cb232-27"><a href="#cb232-27" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.column_stack([labels_array, images_array])</span>
<span id="cb232-28"><a href="#cb232-28" aria-hidden="true" tabindex="-1"></a>columns <span class="op">=</span> [<span class="st">'label'</span>] <span class="op">+</span> [<span class="ss">f'pixel</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">784</span>)]</span>
<span id="cb232-29"><a href="#cb232-29" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data, columns<span class="op">=</span>columns)</span>
<span id="cb232-30"><a href="#cb232-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb232-31"><a href="#cb232-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Save to CSV for future use</span></span>
<span id="cb232-32"><a href="#cb232-32" aria-hidden="true" tabindex="-1"></a>df.to_csv(<span class="st">'fmnist_small.csv'</span>, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb232-33"><a href="#cb232-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Created fmnist_small.csv with </span><span class="sc">{</span><span class="bu">len</span>(df)<span class="sc">}</span><span class="ss"> samples"</span>)</span>
<span id="cb232-34"><a href="#cb232-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb232-35"><a href="#cb232-35" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Created fmnist_small.csv with 1000 samples</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="129">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">label</th>
<th data-quarto-table-cell-role="th">pixel0</th>
<th data-quarto-table-cell-role="th">pixel1</th>
<th data-quarto-table-cell-role="th">pixel2</th>
<th data-quarto-table-cell-role="th">pixel3</th>
<th data-quarto-table-cell-role="th">pixel4</th>
<th data-quarto-table-cell-role="th">pixel5</th>
<th data-quarto-table-cell-role="th">pixel6</th>
<th data-quarto-table-cell-role="th">pixel7</th>
<th data-quarto-table-cell-role="th">pixel8</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">pixel774</th>
<th data-quarto-table-cell-role="th">pixel775</th>
<th data-quarto-table-cell-role="th">pixel776</th>
<th data-quarto-table-cell-role="th">pixel777</th>
<th data-quarto-table-cell-role="th">pixel778</th>
<th data-quarto-table-cell-role="th">pixel779</th>
<th data-quarto-table-cell-role="th">pixel780</th>
<th data-quarto-table-cell-role="th">pixel781</th>
<th data-quarto-table-cell-role="th">pixel782</th>
<th data-quarto-table-cell-role="th">pixel783</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>9.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.000000</td>
<td>0.0</td>
<td>0.0</td>
<td>0.000000</td>
<td>...</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.003922</td>
<td>0.0</td>
<td>0.0</td>
<td>0.000000</td>
<td>...</td>
<td>0.466667</td>
<td>0.447059</td>
<td>0.509804</td>
<td>0.298039</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.000000</td>
<td>0.0</td>
<td>0.0</td>
<td>0.000000</td>
<td>...</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.003922</td>
<td>0.000000</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>3.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.000000</td>
<td>0.0</td>
<td>0.0</td>
<td>0.129412</td>
<td>...</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.000000</td>
<td>0.0</td>
<td>0.0</td>
<td>0.000000</td>
<td>...</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
</tbody>
</table>

<p>5 rows × 785 columns</p>
</div>
</div>
</div>
<p>Let’s check some images.</p>
<div class="cell" data-execution_count="130">
<div class="sourceCode cell-code" id="cb234"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb234-1"><a href="#cb234-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a 4x4 grid of images</span></span>
<span id="cb234-2"><a href="#cb234-2" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">4</span>, <span class="dv">4</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb234-3"><a href="#cb234-3" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="st">"First 16 Images"</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb234-4"><a href="#cb234-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb234-5"><a href="#cb234-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the first 16 images from the dataset</span></span>
<span id="cb234-6"><a href="#cb234-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, ax <span class="kw">in</span> <span class="bu">enumerate</span>(axes.flat):</span>
<span id="cb234-7"><a href="#cb234-7" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> df.iloc[i, <span class="dv">1</span>:].values.reshape(<span class="dv">28</span>, <span class="dv">28</span>)  <span class="co"># Reshape to 28x28</span></span>
<span id="cb234-8"><a href="#cb234-8" aria-hidden="true" tabindex="-1"></a>    ax.imshow(img)  <span class="co"># Display in grayscale</span></span>
<span id="cb234-9"><a href="#cb234-9" aria-hidden="true" tabindex="-1"></a>    ax.axis(<span class="st">'off'</span>)  <span class="co"># Remove axis for a cleaner look</span></span>
<span id="cb234-10"><a href="#cb234-10" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f"Label: </span><span class="sc">{</span>df<span class="sc">.</span>iloc[i, <span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)  <span class="co"># Show the label</span></span>
<span id="cb234-11"><a href="#cb234-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb234-12"><a href="#cb234-12" aria-hidden="true" tabindex="-1"></a>plt.tight_layout(rect<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.96</span>])  <span class="co"># Adjust layout to fit the title</span></span>
<span id="cb234-13"><a href="#cb234-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="AI_files/figure-html/cell-131-output-1.png" class="img-fluid"></p>
</div>
</div>


<!-- -->

</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{rasheduzzaman2025,
  author = {Md Rasheduzzaman},
  title = {Artificial {Inteligence}},
  date = {2025-08-03},
  langid = {en},
  abstract = {Tensor, etc.}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-rasheduzzaman2025" class="csl-entry quarto-appendix-citeas" role="listitem">
Md Rasheduzzaman. 2025. <span>“Artificial Inteligence.”</span> August 3,
2025.
</div></div></section></div></main> <!-- /main -->
<hr>

<div style="margin-top: 2em;">
  <p style="font-weight: 500; font-size: 1.1em;">
    💬 Have thoughts or questions? Join the discussion below using your GitHub account!
  </p>
  <p style="font-size: 0.95em; color: #666;">
    You can <strong>edit or delete</strong> your own comments. Reactions like 👍 ❤️ 🚀 are also supported.
  </p>
</div>

<div id="giscus_thread" style="margin-top: 1.5em;"></div>

<script src="https://giscus.app/client.js" data-repo="MdRasheduz-zaman/PythRaSh" data-repo-id="R_kgDOOZN9Xw" data-category-id="DIC_kwDOOZN9X84CpE6N" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="preferred_color_scheme" data-lang="en" data-loading="lazy" crossorigin="anonymous" async="">
</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb235" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb235-1"><a href="#cb235-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb235-2"><a href="#cb235-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Artificial Inteligence"</span></span>
<span id="cb235-3"><a href="#cb235-3" aria-hidden="true" tabindex="-1"></a><span class="an">abstract:</span><span class="co"> "Tensor, etc."</span></span>
<span id="cb235-4"><a href="#cb235-4" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb235-5"><a href="#cb235-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-6"><a href="#cb235-6" aria-hidden="true" tabindex="-1"></a><span class="fu"># Tensor and PyTorch</span></span>
<span id="cb235-7"><a href="#cb235-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-8"><a href="#cb235-8" aria-hidden="true" tabindex="-1"></a>Let's load <span class="in">`pytorch`</span> library and see the version of it.</span>
<span id="cb235-9"><a href="#cb235-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-12"><a href="#cb235-12" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-13"><a href="#cb235-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb235-14"><a href="#cb235-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(torch.__version__)</span>
<span id="cb235-15"><a href="#cb235-15" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-16"><a href="#cb235-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-17"><a href="#cb235-17" aria-hidden="true" tabindex="-1"></a>Use CPU if GPU (CUDA) is not available.</span>
<span id="cb235-18"><a href="#cb235-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-21"><a href="#cb235-21" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-22"><a href="#cb235-22" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb235-23"><a href="#cb235-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"GPU is available!"</span>)</span>
<span id="cb235-24"><a href="#cb235-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Using GPU: </span><span class="sc">{</span>torch<span class="sc">.</span>cuda<span class="sc">.</span>get_device_name(<span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb235-25"><a href="#cb235-25" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb235-26"><a href="#cb235-26" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"GPU not available. Using CPU."</span>)</span>
<span id="cb235-27"><a href="#cb235-27" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-28"><a href="#cb235-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-29"><a href="#cb235-29" aria-hidden="true" tabindex="-1"></a>So, I am using CPU. Let's start making tensors and build from very basics.</span>
<span id="cb235-30"><a href="#cb235-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-31"><a href="#cb235-31" aria-hidden="true" tabindex="-1"></a><span class="fu">## Tensor Creation</span></span>
<span id="cb235-32"><a href="#cb235-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-35"><a href="#cb235-35" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-36"><a href="#cb235-36" aria-hidden="true" tabindex="-1"></a><span class="co"># using empty</span></span>
<span id="cb235-37"><a href="#cb235-37" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.empty(<span class="dv">2</span>,<span class="dv">3</span>)</span>
<span id="cb235-38"><a href="#cb235-38" aria-hidden="true" tabindex="-1"></a>a</span>
<span id="cb235-39"><a href="#cb235-39" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-40"><a href="#cb235-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-41"><a href="#cb235-41" aria-hidden="true" tabindex="-1"></a>Let's check type of pur tensor.</span>
<span id="cb235-42"><a href="#cb235-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-45"><a href="#cb235-45" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-46"><a href="#cb235-46" aria-hidden="true" tabindex="-1"></a><span class="co"># check type</span></span>
<span id="cb235-47"><a href="#cb235-47" aria-hidden="true" tabindex="-1"></a><span class="bu">type</span>(a)</span>
<span id="cb235-48"><a href="#cb235-48" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-49"><a href="#cb235-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-52"><a href="#cb235-52" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-53"><a href="#cb235-53" aria-hidden="true" tabindex="-1"></a><span class="co"># using ones</span></span>
<span id="cb235-54"><a href="#cb235-54" aria-hidden="true" tabindex="-1"></a>torch.ones(<span class="dv">3</span>,<span class="dv">3</span>)</span>
<span id="cb235-55"><a href="#cb235-55" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-56"><a href="#cb235-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-59"><a href="#cb235-59" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-60"><a href="#cb235-60" aria-hidden="true" tabindex="-1"></a><span class="co"># using zeros</span></span>
<span id="cb235-61"><a href="#cb235-61" aria-hidden="true" tabindex="-1"></a>torch.zeros(<span class="dv">3</span>,<span class="dv">3</span>)</span>
<span id="cb235-62"><a href="#cb235-62" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-63"><a href="#cb235-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-66"><a href="#cb235-66" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-67"><a href="#cb235-67" aria-hidden="true" tabindex="-1"></a><span class="co"># using rand</span></span>
<span id="cb235-68"><a href="#cb235-68" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">40</span>)</span>
<span id="cb235-69"><a href="#cb235-69" aria-hidden="true" tabindex="-1"></a>torch.rand(<span class="dv">2</span>,<span class="dv">3</span>)</span>
<span id="cb235-70"><a href="#cb235-70" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-71"><a href="#cb235-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-74"><a href="#cb235-74" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-75"><a href="#cb235-75" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">40</span>)</span>
<span id="cb235-76"><a href="#cb235-76" aria-hidden="true" tabindex="-1"></a>torch.rand(<span class="dv">2</span>,<span class="dv">3</span>)</span>
<span id="cb235-77"><a href="#cb235-77" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-78"><a href="#cb235-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-81"><a href="#cb235-81" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-82"><a href="#cb235-82" aria-hidden="true" tabindex="-1"></a>torch.randint(size<span class="op">=</span>(<span class="dv">2</span>,<span class="dv">3</span>), low<span class="op">=</span><span class="dv">0</span>, high<span class="op">=</span><span class="dv">10</span>, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb235-83"><a href="#cb235-83" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-84"><a href="#cb235-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-87"><a href="#cb235-87" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-88"><a href="#cb235-88" aria-hidden="true" tabindex="-1"></a><span class="co"># using tensor</span></span>
<span id="cb235-89"><a href="#cb235-89" aria-hidden="true" tabindex="-1"></a>torch.tensor([[<span class="dv">3</span>,<span class="dv">2</span>,<span class="dv">1</span>],[<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>]])</span>
<span id="cb235-90"><a href="#cb235-90" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-91"><a href="#cb235-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-94"><a href="#cb235-94" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-95"><a href="#cb235-95" aria-hidden="true" tabindex="-1"></a><span class="co"># other ways</span></span>
<span id="cb235-96"><a href="#cb235-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-97"><a href="#cb235-97" aria-hidden="true" tabindex="-1"></a><span class="co"># arange</span></span>
<span id="cb235-98"><a href="#cb235-98" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.arange(<span class="dv">0</span>,<span class="dv">15</span>,<span class="dv">3</span>)</span>
<span id="cb235-99"><a href="#cb235-99" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"using arange -&gt;"</span>, a)</span>
<span id="cb235-100"><a href="#cb235-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-101"><a href="#cb235-101" aria-hidden="true" tabindex="-1"></a><span class="co"># using linspace</span></span>
<span id="cb235-102"><a href="#cb235-102" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.linspace(<span class="dv">0</span>,<span class="dv">15</span>,<span class="dv">10</span>)</span>
<span id="cb235-103"><a href="#cb235-103" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"using linspace -&gt;"</span>, b)</span>
<span id="cb235-104"><a href="#cb235-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-105"><a href="#cb235-105" aria-hidden="true" tabindex="-1"></a><span class="co"># using eye</span></span>
<span id="cb235-106"><a href="#cb235-106" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> torch.eye(<span class="dv">4</span>)</span>
<span id="cb235-107"><a href="#cb235-107" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"using eye -&gt;"</span>, c)</span>
<span id="cb235-108"><a href="#cb235-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-109"><a href="#cb235-109" aria-hidden="true" tabindex="-1"></a><span class="co"># using full</span></span>
<span id="cb235-110"><a href="#cb235-110" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> torch.full((<span class="dv">3</span>, <span class="dv">3</span>), <span class="dv">5</span>)</span>
<span id="cb235-111"><a href="#cb235-111" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"using full -&gt;"</span>, d)</span>
<span id="cb235-112"><a href="#cb235-112" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-113"><a href="#cb235-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-114"><a href="#cb235-114" aria-hidden="true" tabindex="-1"></a><span class="fu">## Tensor shape</span></span>
<span id="cb235-115"><a href="#cb235-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-116"><a href="#cb235-116" aria-hidden="true" tabindex="-1"></a>We are making a new tensor (<span class="in">`x`</span>) and checking shape of it. We can use the shape of <span class="in">`x`</span> or any other already created tensor to make new tensors of that shape.</span>
<span id="cb235-117"><a href="#cb235-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-120"><a href="#cb235-120" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-121"><a href="#cb235-121" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>],[<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>]])</span>
<span id="cb235-122"><a href="#cb235-122" aria-hidden="true" tabindex="-1"></a>x</span>
<span id="cb235-123"><a href="#cb235-123" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-124"><a href="#cb235-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-127"><a href="#cb235-127" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-128"><a href="#cb235-128" aria-hidden="true" tabindex="-1"></a>x.shape</span>
<span id="cb235-129"><a href="#cb235-129" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-130"><a href="#cb235-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-133"><a href="#cb235-133" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-134"><a href="#cb235-134" aria-hidden="true" tabindex="-1"></a>torch.empty_like(x)</span>
<span id="cb235-135"><a href="#cb235-135" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-136"><a href="#cb235-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-139"><a href="#cb235-139" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-140"><a href="#cb235-140" aria-hidden="true" tabindex="-1"></a>torch.zeros_like(x)</span>
<span id="cb235-141"><a href="#cb235-141" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-142"><a href="#cb235-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-145"><a href="#cb235-145" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-146"><a href="#cb235-146" aria-hidden="true" tabindex="-1"></a><span class="co">#| error: true</span></span>
<span id="cb235-147"><a href="#cb235-147" aria-hidden="true" tabindex="-1"></a>torch.rand_like(x)</span>
<span id="cb235-148"><a href="#cb235-148" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-149"><a href="#cb235-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-150"><a href="#cb235-150" aria-hidden="true" tabindex="-1"></a>It's not working, since <span class="in">`rand`</span> makes float values in the tensor. So, we need to specify data type as float.</span>
<span id="cb235-151"><a href="#cb235-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-154"><a href="#cb235-154" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-155"><a href="#cb235-155" aria-hidden="true" tabindex="-1"></a>torch.rand_like(x, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb235-156"><a href="#cb235-156" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-157"><a href="#cb235-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-158"><a href="#cb235-158" aria-hidden="true" tabindex="-1"></a><span class="fu">## Tensor Data Types</span></span>
<span id="cb235-159"><a href="#cb235-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-162"><a href="#cb235-162" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-163"><a href="#cb235-163" aria-hidden="true" tabindex="-1"></a><span class="co"># find data type</span></span>
<span id="cb235-164"><a href="#cb235-164" aria-hidden="true" tabindex="-1"></a>x.dtype</span>
<span id="cb235-165"><a href="#cb235-165" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-166"><a href="#cb235-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-167"><a href="#cb235-167" aria-hidden="true" tabindex="-1"></a>We are changing data type from float to int using <span class="in">`dtype`</span> here.</span>
<span id="cb235-168"><a href="#cb235-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-171"><a href="#cb235-171" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-172"><a href="#cb235-172" aria-hidden="true" tabindex="-1"></a><span class="co"># assign data type</span></span>
<span id="cb235-173"><a href="#cb235-173" aria-hidden="true" tabindex="-1"></a>torch.tensor([<span class="fl">1.0</span>,<span class="fl">2.0</span>,<span class="fl">3.0</span>], dtype<span class="op">=</span>torch.int32)</span>
<span id="cb235-174"><a href="#cb235-174" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-175"><a href="#cb235-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-176"><a href="#cb235-176" aria-hidden="true" tabindex="-1"></a>Similarly, from int to float using <span class="in">`dtype`</span> here.</span>
<span id="cb235-177"><a href="#cb235-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-180"><a href="#cb235-180" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-181"><a href="#cb235-181" aria-hidden="true" tabindex="-1"></a>torch.tensor([<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>], dtype<span class="op">=</span>torch.float64)</span>
<span id="cb235-182"><a href="#cb235-182" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-183"><a href="#cb235-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-186"><a href="#cb235-186" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-187"><a href="#cb235-187" aria-hidden="true" tabindex="-1"></a><span class="co">#using to()</span></span>
<span id="cb235-188"><a href="#cb235-188" aria-hidden="true" tabindex="-1"></a>x.to(torch.float32)</span>
<span id="cb235-189"><a href="#cb235-189" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-190"><a href="#cb235-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-191"><a href="#cb235-191" aria-hidden="true" tabindex="-1"></a>Some common data types in torch. \| **Data Type** \| **Dtype** \| **Description** \| \|---------------------------\|-------------------\|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\| \| **32-bit Floating Point** \| `torch.float32` \| Standard floating-point type used for most deep learning tasks. Provides a balance between precision and memory usage. \| \| **64-bit Floating Point** \| `torch.float64` \| Double-precision floating point. Useful for high-precision numerical tasks but uses more memory. \| \| **16-bit Floating Point** \| `torch.float16` \| Half-precision floating point. Commonly used in mixed-precision training to reduce memory and computational overhead on modern GPUs. \| \| **BFloat16** \| `torch.bfloat16` \| Brain floating-point format with reduced precision compared to `float16`. Used in mixed-precision training, especially on TPUs. \| \| **8-bit Floating Point** \| `torch.float8` \| Ultra-low-precision floating point. Used for experimental applications and extreme memory-constrained environments (less common). \| \| **8-bit Integer** \| `torch.int8` \| 8-bit signed integer. Used for quantized models to save memory and computation in inference. \| \| **16-bit Integer** \| `torch.int16` \| 16-bit signed integer. Useful for special numerical tasks requiring intermediate precision. \| \| **32-bit Integer** \| `torch.int32` \| Standard signed integer type. Commonly used for indexing and general-purpose numerical tasks. \| \| **64-bit Integer** \| `torch.int64` \| Long integer type. Often used for large indexing arrays or for tasks involving large numbers. \| \| **8-bit Unsigned Integer**\| `torch.uint8` \| 8-bit unsigned integer. Commonly used for image data (e.g., pixel values between 0 and 255). \| \| **Boolean** \| `torch.bool` \| Boolean type, stores `True` or `False` values. Often used for masks in logical operations. \| \| **Complex 64** \| `torch.complex64` \| Complex number type with 32-bit real and 32-bit imaginary parts. Used for scientific and signal processing tasks. \| \| **Complex 128** \| `torch.complex128`\| Complex number type with 64-bit real and 64-bit imaginary parts. Offers higher precision but uses more memory. \| \| **Quantized Integer** \| `torch.qint8` \| Quantized signed 8-bit integer. Used in quantized models for efficient inference. \| \| **Quantized Unsigned Integer** \| <span class="in">`torch.quint8`</span> \| Quantized unsigned 8-bit integer. Often used for quantized tensors in image-related tasks. \|</span>
<span id="cb235-192"><a href="#cb235-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-193"><a href="#cb235-193" aria-hidden="true" tabindex="-1"></a><span class="fu">## Mathematical Operations</span></span>
<span id="cb235-194"><a href="#cb235-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-195"><a href="#cb235-195" aria-hidden="true" tabindex="-1"></a><span class="fu">### Scalar operation</span></span>
<span id="cb235-196"><a href="#cb235-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-197"><a href="#cb235-197" aria-hidden="true" tabindex="-1"></a>Let's define a tensor x first.</span>
<span id="cb235-198"><a href="#cb235-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-201"><a href="#cb235-201" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-202"><a href="#cb235-202" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.rand(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb235-203"><a href="#cb235-203" aria-hidden="true" tabindex="-1"></a>x</span>
<span id="cb235-204"><a href="#cb235-204" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-205"><a href="#cb235-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-206"><a href="#cb235-206" aria-hidden="true" tabindex="-1"></a>Now, let's see some scalar operation on this tensor.</span>
<span id="cb235-207"><a href="#cb235-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-210"><a href="#cb235-210" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-211"><a href="#cb235-211" aria-hidden="true" tabindex="-1"></a><span class="co">#addition</span></span>
<span id="cb235-212"><a href="#cb235-212" aria-hidden="true" tabindex="-1"></a>x <span class="op">+</span> <span class="dv">2</span></span>
<span id="cb235-213"><a href="#cb235-213" aria-hidden="true" tabindex="-1"></a><span class="co">#subtraction</span></span>
<span id="cb235-214"><a href="#cb235-214" aria-hidden="true" tabindex="-1"></a>x <span class="op">-</span> <span class="dv">3</span></span>
<span id="cb235-215"><a href="#cb235-215" aria-hidden="true" tabindex="-1"></a><span class="co">#multiplication</span></span>
<span id="cb235-216"><a href="#cb235-216" aria-hidden="true" tabindex="-1"></a>x<span class="op">*</span><span class="dv">4</span></span>
<span id="cb235-217"><a href="#cb235-217" aria-hidden="true" tabindex="-1"></a><span class="co">#division</span></span>
<span id="cb235-218"><a href="#cb235-218" aria-hidden="true" tabindex="-1"></a>x<span class="op">/</span><span class="dv">2</span></span>
<span id="cb235-219"><a href="#cb235-219" aria-hidden="true" tabindex="-1"></a><span class="co">#integer division</span></span>
<span id="cb235-220"><a href="#cb235-220" aria-hidden="true" tabindex="-1"></a>(x<span class="op">*</span><span class="dv">40</span>)<span class="op">//</span><span class="dv">3</span></span>
<span id="cb235-221"><a href="#cb235-221" aria-hidden="true" tabindex="-1"></a><span class="co">#modulus division</span></span>
<span id="cb235-222"><a href="#cb235-222" aria-hidden="true" tabindex="-1"></a>((x<span class="op">*</span><span class="dv">40</span>)<span class="op">//</span><span class="dv">3</span>)<span class="op">%</span><span class="dv">2</span></span>
<span id="cb235-223"><a href="#cb235-223" aria-hidden="true" tabindex="-1"></a><span class="co">#power</span></span>
<span id="cb235-224"><a href="#cb235-224" aria-hidden="true" tabindex="-1"></a>x<span class="op">**</span><span class="dv">2</span></span>
<span id="cb235-225"><a href="#cb235-225" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-226"><a href="#cb235-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-227"><a href="#cb235-227" aria-hidden="true" tabindex="-1"></a><span class="fu">### Element-wise operation</span></span>
<span id="cb235-228"><a href="#cb235-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-229"><a href="#cb235-229" aria-hidden="true" tabindex="-1"></a>Let's make 2 new tensors first. To do anything element-wise, the shape of the tensors should be the same.</span>
<span id="cb235-230"><a href="#cb235-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-233"><a href="#cb235-233" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-234"><a href="#cb235-234" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.rand(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb235-235"><a href="#cb235-235" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.rand(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb235-236"><a href="#cb235-236" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a)</span>
<span id="cb235-237"><a href="#cb235-237" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(b)</span>
<span id="cb235-238"><a href="#cb235-238" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-239"><a href="#cb235-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-242"><a href="#cb235-242" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-243"><a href="#cb235-243" aria-hidden="true" tabindex="-1"></a><span class="co">#add</span></span>
<span id="cb235-244"><a href="#cb235-244" aria-hidden="true" tabindex="-1"></a>a <span class="op">+</span> b</span>
<span id="cb235-245"><a href="#cb235-245" aria-hidden="true" tabindex="-1"></a><span class="co">#subtract</span></span>
<span id="cb235-246"><a href="#cb235-246" aria-hidden="true" tabindex="-1"></a>a <span class="op">-</span> b</span>
<span id="cb235-247"><a href="#cb235-247" aria-hidden="true" tabindex="-1"></a><span class="co">#multiply</span></span>
<span id="cb235-248"><a href="#cb235-248" aria-hidden="true" tabindex="-1"></a>a<span class="op">*</span>b</span>
<span id="cb235-249"><a href="#cb235-249" aria-hidden="true" tabindex="-1"></a><span class="co">#division</span></span>
<span id="cb235-250"><a href="#cb235-250" aria-hidden="true" tabindex="-1"></a>a<span class="op">/</span>b</span>
<span id="cb235-251"><a href="#cb235-251" aria-hidden="true" tabindex="-1"></a><span class="co">#power</span></span>
<span id="cb235-252"><a href="#cb235-252" aria-hidden="true" tabindex="-1"></a>a<span class="op">**</span>b</span>
<span id="cb235-253"><a href="#cb235-253" aria-hidden="true" tabindex="-1"></a><span class="co">#mod</span></span>
<span id="cb235-254"><a href="#cb235-254" aria-hidden="true" tabindex="-1"></a>a<span class="op">%</span>b</span>
<span id="cb235-255"><a href="#cb235-255" aria-hidden="true" tabindex="-1"></a><span class="co">#int division</span></span>
<span id="cb235-256"><a href="#cb235-256" aria-hidden="true" tabindex="-1"></a>a<span class="op">//</span>b</span>
<span id="cb235-257"><a href="#cb235-257" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-258"><a href="#cb235-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-259"><a href="#cb235-259" aria-hidden="true" tabindex="-1"></a>Let's apply absolute function on a custom tensor.</span>
<span id="cb235-260"><a href="#cb235-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-263"><a href="#cb235-263" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-264"><a href="#cb235-264" aria-hidden="true" tabindex="-1"></a><span class="co">#abs</span></span>
<span id="cb235-265"><a href="#cb235-265" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> torch.tensor([<span class="op">-</span><span class="dv">1</span>, <span class="dv">2</span>, <span class="op">-</span><span class="dv">3</span>, <span class="dv">4</span>, <span class="op">-</span><span class="dv">5</span>, <span class="op">-</span><span class="dv">6</span>, <span class="dv">7</span>, <span class="op">-</span><span class="dv">8</span>])</span>
<span id="cb235-266"><a href="#cb235-266" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">abs</span>(c)</span>
<span id="cb235-267"><a href="#cb235-267" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-268"><a href="#cb235-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-269"><a href="#cb235-269" aria-hidden="true" tabindex="-1"></a>We only have positive values, right? As expected.</span>
<span id="cb235-270"><a href="#cb235-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-271"><a href="#cb235-271" aria-hidden="true" tabindex="-1"></a>Let's apply negative on the tensor.</span>
<span id="cb235-272"><a href="#cb235-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-275"><a href="#cb235-275" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-276"><a href="#cb235-276" aria-hidden="true" tabindex="-1"></a>torch.neg(c)</span>
<span id="cb235-277"><a href="#cb235-277" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-278"><a href="#cb235-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-279"><a href="#cb235-279" aria-hidden="true" tabindex="-1"></a>We have negative signs on the previously positives, and positive signs on the previously negatives, right?</span>
<span id="cb235-280"><a href="#cb235-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-283"><a href="#cb235-283" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-284"><a href="#cb235-284" aria-hidden="true" tabindex="-1"></a><span class="co">#round</span></span>
<span id="cb235-285"><a href="#cb235-285" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> torch.tensor([<span class="fl">1.4</span>, <span class="fl">4.4</span>, <span class="fl">3.6</span>, <span class="fl">3.01</span>, <span class="fl">4.55</span>, <span class="fl">4.9</span>])</span>
<span id="cb235-286"><a href="#cb235-286" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">round</span>(d)</span>
<span id="cb235-287"><a href="#cb235-287" aria-hidden="true" tabindex="-1"></a><span class="co"># ceil</span></span>
<span id="cb235-288"><a href="#cb235-288" aria-hidden="true" tabindex="-1"></a>torch.ceil(d)</span>
<span id="cb235-289"><a href="#cb235-289" aria-hidden="true" tabindex="-1"></a><span class="co"># floor</span></span>
<span id="cb235-290"><a href="#cb235-290" aria-hidden="true" tabindex="-1"></a>torch.floor(d)</span>
<span id="cb235-291"><a href="#cb235-291" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-292"><a href="#cb235-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-293"><a href="#cb235-293" aria-hidden="true" tabindex="-1"></a>Do you see what <span class="in">`round`</span>, <span class="in">`ciel`</span>, <span class="in">`floor`</span> are doing here? It is not that difficult, try to see.</span>
<span id="cb235-294"><a href="#cb235-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-295"><a href="#cb235-295" aria-hidden="true" tabindex="-1"></a>Let's do some <span class="in">`clamp`</span>ing. So, if a value is smaller than the <span class="in">`min`</span> value provided, that value will be equal to the <span class="in">`min`</span> value and values bigger than the <span class="in">`max`</span> value will be made equal to the <span class="in">`max`</span> value. All other values in between the range will be kept as they are.</span>
<span id="cb235-296"><a href="#cb235-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-299"><a href="#cb235-299" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-300"><a href="#cb235-300" aria-hidden="true" tabindex="-1"></a><span class="co"># clamp</span></span>
<span id="cb235-301"><a href="#cb235-301" aria-hidden="true" tabindex="-1"></a>d</span>
<span id="cb235-302"><a href="#cb235-302" aria-hidden="true" tabindex="-1"></a>torch.clamp(d, <span class="bu">min</span><span class="op">=</span><span class="dv">2</span>, <span class="bu">max</span><span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb235-303"><a href="#cb235-303" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-304"><a href="#cb235-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-305"><a href="#cb235-305" aria-hidden="true" tabindex="-1"></a><span class="fu">### Reduction operation</span></span>
<span id="cb235-306"><a href="#cb235-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-309"><a href="#cb235-309" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-310"><a href="#cb235-310" aria-hidden="true" tabindex="-1"></a>e <span class="op">=</span> torch.randint(size<span class="op">=</span>(<span class="dv">2</span>,<span class="dv">3</span>), low<span class="op">=</span><span class="dv">0</span>, high<span class="op">=</span><span class="dv">10</span>, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb235-311"><a href="#cb235-311" aria-hidden="true" tabindex="-1"></a>e</span>
<span id="cb235-312"><a href="#cb235-312" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-313"><a href="#cb235-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-316"><a href="#cb235-316" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-317"><a href="#cb235-317" aria-hidden="true" tabindex="-1"></a><span class="co"># sum</span></span>
<span id="cb235-318"><a href="#cb235-318" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">sum</span>(e)</span>
<span id="cb235-319"><a href="#cb235-319" aria-hidden="true" tabindex="-1"></a><span class="co"># sum along columns</span></span>
<span id="cb235-320"><a href="#cb235-320" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">sum</span>(e, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb235-321"><a href="#cb235-321" aria-hidden="true" tabindex="-1"></a><span class="co"># sum along rows</span></span>
<span id="cb235-322"><a href="#cb235-322" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">sum</span>(e, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb235-323"><a href="#cb235-323" aria-hidden="true" tabindex="-1"></a><span class="co"># mean</span></span>
<span id="cb235-324"><a href="#cb235-324" aria-hidden="true" tabindex="-1"></a>torch.mean(e)</span>
<span id="cb235-325"><a href="#cb235-325" aria-hidden="true" tabindex="-1"></a><span class="co"># mean along col</span></span>
<span id="cb235-326"><a href="#cb235-326" aria-hidden="true" tabindex="-1"></a>torch.mean(e, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb235-327"><a href="#cb235-327" aria-hidden="true" tabindex="-1"></a><span class="co"># mean along row</span></span>
<span id="cb235-328"><a href="#cb235-328" aria-hidden="true" tabindex="-1"></a>torch.mean(e, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb235-329"><a href="#cb235-329" aria-hidden="true" tabindex="-1"></a><span class="co"># median</span></span>
<span id="cb235-330"><a href="#cb235-330" aria-hidden="true" tabindex="-1"></a>torch.median(e)</span>
<span id="cb235-331"><a href="#cb235-331" aria-hidden="true" tabindex="-1"></a>torch.median(e, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb235-332"><a href="#cb235-332" aria-hidden="true" tabindex="-1"></a>torch.median(e, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb235-333"><a href="#cb235-333" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-334"><a href="#cb235-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-337"><a href="#cb235-337" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-338"><a href="#cb235-338" aria-hidden="true" tabindex="-1"></a><span class="co"># max and min</span></span>
<span id="cb235-339"><a href="#cb235-339" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">max</span>(e)</span>
<span id="cb235-340"><a href="#cb235-340" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">max</span>(e, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb235-341"><a href="#cb235-341" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">max</span>(e, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb235-342"><a href="#cb235-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-343"><a href="#cb235-343" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">min</span>(e)</span>
<span id="cb235-344"><a href="#cb235-344" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">min</span>(e, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb235-345"><a href="#cb235-345" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">min</span>(e, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb235-346"><a href="#cb235-346" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-347"><a href="#cb235-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-350"><a href="#cb235-350" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-351"><a href="#cb235-351" aria-hidden="true" tabindex="-1"></a><span class="co"># product</span></span>
<span id="cb235-352"><a href="#cb235-352" aria-hidden="true" tabindex="-1"></a>torch.prod(e)</span>
<span id="cb235-353"><a href="#cb235-353" aria-hidden="true" tabindex="-1"></a><span class="co">#do yourself dimension-wise</span></span>
<span id="cb235-354"><a href="#cb235-354" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-355"><a href="#cb235-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-358"><a href="#cb235-358" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-359"><a href="#cb235-359" aria-hidden="true" tabindex="-1"></a><span class="co"># standard deviation</span></span>
<span id="cb235-360"><a href="#cb235-360" aria-hidden="true" tabindex="-1"></a>torch.std(e)</span>
<span id="cb235-361"><a href="#cb235-361" aria-hidden="true" tabindex="-1"></a><span class="co">#do yourself dimension-wise</span></span>
<span id="cb235-362"><a href="#cb235-362" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-363"><a href="#cb235-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-366"><a href="#cb235-366" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-367"><a href="#cb235-367" aria-hidden="true" tabindex="-1"></a><span class="co"># variance</span></span>
<span id="cb235-368"><a href="#cb235-368" aria-hidden="true" tabindex="-1"></a>torch.var(e)</span>
<span id="cb235-369"><a href="#cb235-369" aria-hidden="true" tabindex="-1"></a><span class="co">#do yourself dimension-wise</span></span>
<span id="cb235-370"><a href="#cb235-370" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-371"><a href="#cb235-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-372"><a href="#cb235-372" aria-hidden="true" tabindex="-1"></a>Which value is the biggest here? How to get its position/index? Use <span class="in">`argmax`</span>.</span>
<span id="cb235-373"><a href="#cb235-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-376"><a href="#cb235-376" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-377"><a href="#cb235-377" aria-hidden="true" tabindex="-1"></a><span class="co"># argmax</span></span>
<span id="cb235-378"><a href="#cb235-378" aria-hidden="true" tabindex="-1"></a>torch.argmax(e)</span>
<span id="cb235-379"><a href="#cb235-379" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-380"><a href="#cb235-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-381"><a href="#cb235-381" aria-hidden="true" tabindex="-1"></a>Which value is the smallest here? How to get its position/index? Use <span class="in">`argmin`</span>.</span>
<span id="cb235-382"><a href="#cb235-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-385"><a href="#cb235-385" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-386"><a href="#cb235-386" aria-hidden="true" tabindex="-1"></a><span class="co"># argmin</span></span>
<span id="cb235-387"><a href="#cb235-387" aria-hidden="true" tabindex="-1"></a>torch.argmin(e)</span>
<span id="cb235-388"><a href="#cb235-388" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-389"><a href="#cb235-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-390"><a href="#cb235-390" aria-hidden="true" tabindex="-1"></a><span class="fu">### Matrix operations</span></span>
<span id="cb235-391"><a href="#cb235-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-394"><a href="#cb235-394" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-395"><a href="#cb235-395" aria-hidden="true" tabindex="-1"></a>m1 <span class="op">=</span> torch.randint(size<span class="op">=</span>(<span class="dv">2</span>,<span class="dv">3</span>), low<span class="op">=</span><span class="dv">0</span>, high<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb235-396"><a href="#cb235-396" aria-hidden="true" tabindex="-1"></a>m2 <span class="op">=</span> torch.randint(size<span class="op">=</span>(<span class="dv">3</span>,<span class="dv">2</span>), low<span class="op">=</span><span class="dv">0</span>, high<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb235-397"><a href="#cb235-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-398"><a href="#cb235-398" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(m1)</span>
<span id="cb235-399"><a href="#cb235-399" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(m2)</span>
<span id="cb235-400"><a href="#cb235-400" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-401"><a href="#cb235-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-404"><a href="#cb235-404" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-405"><a href="#cb235-405" aria-hidden="true" tabindex="-1"></a><span class="co"># matrix multiplcation</span></span>
<span id="cb235-406"><a href="#cb235-406" aria-hidden="true" tabindex="-1"></a>torch.matmul(m1, m2)</span>
<span id="cb235-407"><a href="#cb235-407" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-408"><a href="#cb235-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-409"><a href="#cb235-409" aria-hidden="true" tabindex="-1"></a><span class="fu">### Dot products:</span></span>
<span id="cb235-410"><a href="#cb235-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-413"><a href="#cb235-413" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-414"><a href="#cb235-414" aria-hidden="true" tabindex="-1"></a>vector1 <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">2</span>])</span>
<span id="cb235-415"><a href="#cb235-415" aria-hidden="true" tabindex="-1"></a>vector2 <span class="op">=</span> torch.tensor([<span class="dv">3</span>, <span class="dv">4</span>])</span>
<span id="cb235-416"><a href="#cb235-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-417"><a href="#cb235-417" aria-hidden="true" tabindex="-1"></a><span class="co"># dot product</span></span>
<span id="cb235-418"><a href="#cb235-418" aria-hidden="true" tabindex="-1"></a>torch.dot(vector1, vector2)</span>
<span id="cb235-419"><a href="#cb235-419" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-420"><a href="#cb235-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-423"><a href="#cb235-423" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-424"><a href="#cb235-424" aria-hidden="true" tabindex="-1"></a><span class="co"># transpose</span></span>
<span id="cb235-425"><a href="#cb235-425" aria-hidden="true" tabindex="-1"></a>torch.transpose(m2, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb235-426"><a href="#cb235-426" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-427"><a href="#cb235-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-430"><a href="#cb235-430" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-431"><a href="#cb235-431" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> torch.randint(size<span class="op">=</span>(<span class="dv">3</span>,<span class="dv">3</span>), low<span class="op">=</span><span class="dv">0</span>, high<span class="op">=</span><span class="dv">8</span>, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb235-432"><a href="#cb235-432" aria-hidden="true" tabindex="-1"></a>h</span>
<span id="cb235-433"><a href="#cb235-433" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-434"><a href="#cb235-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-437"><a href="#cb235-437" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-438"><a href="#cb235-438" aria-hidden="true" tabindex="-1"></a><span class="co"># determinant</span></span>
<span id="cb235-439"><a href="#cb235-439" aria-hidden="true" tabindex="-1"></a>torch.det(h)</span>
<span id="cb235-440"><a href="#cb235-440" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-441"><a href="#cb235-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-444"><a href="#cb235-444" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-445"><a href="#cb235-445" aria-hidden="true" tabindex="-1"></a><span class="co"># inverse</span></span>
<span id="cb235-446"><a href="#cb235-446" aria-hidden="true" tabindex="-1"></a>torch.inverse(h)</span>
<span id="cb235-447"><a href="#cb235-447" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-448"><a href="#cb235-448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-449"><a href="#cb235-449" aria-hidden="true" tabindex="-1"></a><span class="fu">### Comparison operations</span></span>
<span id="cb235-450"><a href="#cb235-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-453"><a href="#cb235-453" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-454"><a href="#cb235-454" aria-hidden="true" tabindex="-1"></a>i <span class="op">=</span> torch.randint(size<span class="op">=</span>(<span class="dv">2</span>,<span class="dv">3</span>), low<span class="op">=</span><span class="dv">0</span>, high<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb235-455"><a href="#cb235-455" aria-hidden="true" tabindex="-1"></a>j <span class="op">=</span> torch.randint(size<span class="op">=</span>(<span class="dv">2</span>,<span class="dv">3</span>), low<span class="op">=</span><span class="dv">0</span>, high<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb235-456"><a href="#cb235-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-457"><a href="#cb235-457" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(i)</span>
<span id="cb235-458"><a href="#cb235-458" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(j)</span>
<span id="cb235-459"><a href="#cb235-459" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-460"><a href="#cb235-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-463"><a href="#cb235-463" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-464"><a href="#cb235-464" aria-hidden="true" tabindex="-1"></a><span class="co"># greater than</span></span>
<span id="cb235-465"><a href="#cb235-465" aria-hidden="true" tabindex="-1"></a>i <span class="op">&gt;</span> j</span>
<span id="cb235-466"><a href="#cb235-466" aria-hidden="true" tabindex="-1"></a><span class="co"># less than</span></span>
<span id="cb235-467"><a href="#cb235-467" aria-hidden="true" tabindex="-1"></a>i <span class="op">&lt;</span> j</span>
<span id="cb235-468"><a href="#cb235-468" aria-hidden="true" tabindex="-1"></a><span class="co"># equal to</span></span>
<span id="cb235-469"><a href="#cb235-469" aria-hidden="true" tabindex="-1"></a>i <span class="op">==</span> j</span>
<span id="cb235-470"><a href="#cb235-470" aria-hidden="true" tabindex="-1"></a><span class="co"># not equal to</span></span>
<span id="cb235-471"><a href="#cb235-471" aria-hidden="true" tabindex="-1"></a>i <span class="op">!=</span> j</span>
<span id="cb235-472"><a href="#cb235-472" aria-hidden="true" tabindex="-1"></a><span class="co"># greater than equal to</span></span>
<span id="cb235-473"><a href="#cb235-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-474"><a href="#cb235-474" aria-hidden="true" tabindex="-1"></a><span class="co"># less than equal to</span></span>
<span id="cb235-475"><a href="#cb235-475" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-476"><a href="#cb235-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-477"><a href="#cb235-477" aria-hidden="true" tabindex="-1"></a><span class="fu">### Special functions</span></span>
<span id="cb235-478"><a href="#cb235-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-481"><a href="#cb235-481" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-482"><a href="#cb235-482" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> torch.randint(size<span class="op">=</span>(<span class="dv">2</span>,<span class="dv">3</span>), low<span class="op">=</span><span class="dv">0</span>, high<span class="op">=</span><span class="dv">10</span>, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb235-483"><a href="#cb235-483" aria-hidden="true" tabindex="-1"></a>k</span>
<span id="cb235-484"><a href="#cb235-484" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-485"><a href="#cb235-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-488"><a href="#cb235-488" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-489"><a href="#cb235-489" aria-hidden="true" tabindex="-1"></a><span class="co"># log</span></span>
<span id="cb235-490"><a href="#cb235-490" aria-hidden="true" tabindex="-1"></a>torch.log(k)</span>
<span id="cb235-491"><a href="#cb235-491" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-492"><a href="#cb235-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-495"><a href="#cb235-495" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-496"><a href="#cb235-496" aria-hidden="true" tabindex="-1"></a><span class="co"># exp</span></span>
<span id="cb235-497"><a href="#cb235-497" aria-hidden="true" tabindex="-1"></a>torch.exp(k)</span>
<span id="cb235-498"><a href="#cb235-498" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-499"><a href="#cb235-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-502"><a href="#cb235-502" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-503"><a href="#cb235-503" aria-hidden="true" tabindex="-1"></a><span class="co"># sqrt</span></span>
<span id="cb235-504"><a href="#cb235-504" aria-hidden="true" tabindex="-1"></a>torch.sqrt(k)</span>
<span id="cb235-505"><a href="#cb235-505" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-506"><a href="#cb235-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-509"><a href="#cb235-509" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-510"><a href="#cb235-510" aria-hidden="true" tabindex="-1"></a>k</span>
<span id="cb235-511"><a href="#cb235-511" aria-hidden="true" tabindex="-1"></a><span class="co"># sigmoid</span></span>
<span id="cb235-512"><a href="#cb235-512" aria-hidden="true" tabindex="-1"></a>torch.sigmoid(k)</span>
<span id="cb235-513"><a href="#cb235-513" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-514"><a href="#cb235-514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-517"><a href="#cb235-517" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-518"><a href="#cb235-518" aria-hidden="true" tabindex="-1"></a>k</span>
<span id="cb235-519"><a href="#cb235-519" aria-hidden="true" tabindex="-1"></a><span class="co"># softmax</span></span>
<span id="cb235-520"><a href="#cb235-520" aria-hidden="true" tabindex="-1"></a>torch.softmax(k, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb235-521"><a href="#cb235-521" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-522"><a href="#cb235-522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-525"><a href="#cb235-525" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-526"><a href="#cb235-526" aria-hidden="true" tabindex="-1"></a><span class="co"># relu</span></span>
<span id="cb235-527"><a href="#cb235-527" aria-hidden="true" tabindex="-1"></a>torch.relu(k)</span>
<span id="cb235-528"><a href="#cb235-528" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-529"><a href="#cb235-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-530"><a href="#cb235-530" aria-hidden="true" tabindex="-1"></a><span class="fu">### Inplace Operations</span></span>
<span id="cb235-531"><a href="#cb235-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-534"><a href="#cb235-534" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-535"><a href="#cb235-535" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> torch.rand(<span class="dv">2</span>,<span class="dv">3</span>)</span>
<span id="cb235-536"><a href="#cb235-536" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> torch.rand(<span class="dv">2</span>,<span class="dv">3</span>)</span>
<span id="cb235-537"><a href="#cb235-537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-538"><a href="#cb235-538" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(m)</span>
<span id="cb235-539"><a href="#cb235-539" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(n)</span>
<span id="cb235-540"><a href="#cb235-540" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-541"><a href="#cb235-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-544"><a href="#cb235-544" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-545"><a href="#cb235-545" aria-hidden="true" tabindex="-1"></a>m.add_(n)</span>
<span id="cb235-546"><a href="#cb235-546" aria-hidden="true" tabindex="-1"></a>m</span>
<span id="cb235-547"><a href="#cb235-547" aria-hidden="true" tabindex="-1"></a>n</span>
<span id="cb235-548"><a href="#cb235-548" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-549"><a href="#cb235-549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-552"><a href="#cb235-552" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-553"><a href="#cb235-553" aria-hidden="true" tabindex="-1"></a>torch.relu(m)</span>
<span id="cb235-554"><a href="#cb235-554" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-555"><a href="#cb235-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-558"><a href="#cb235-558" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-559"><a href="#cb235-559" aria-hidden="true" tabindex="-1"></a>m.relu_()</span>
<span id="cb235-560"><a href="#cb235-560" aria-hidden="true" tabindex="-1"></a>m</span>
<span id="cb235-561"><a href="#cb235-561" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-562"><a href="#cb235-562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-563"><a href="#cb235-563" aria-hidden="true" tabindex="-1"></a>Copying a Tensor</span>
<span id="cb235-564"><a href="#cb235-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-567"><a href="#cb235-567" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-568"><a href="#cb235-568" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.rand(<span class="dv">2</span>,<span class="dv">3</span>)</span>
<span id="cb235-569"><a href="#cb235-569" aria-hidden="true" tabindex="-1"></a>a</span>
<span id="cb235-570"><a href="#cb235-570" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-571"><a href="#cb235-571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-574"><a href="#cb235-574" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-575"><a href="#cb235-575" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> a</span>
<span id="cb235-576"><a href="#cb235-576" aria-hidden="true" tabindex="-1"></a>a</span>
<span id="cb235-577"><a href="#cb235-577" aria-hidden="true" tabindex="-1"></a>b</span>
<span id="cb235-578"><a href="#cb235-578" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-579"><a href="#cb235-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-582"><a href="#cb235-582" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-583"><a href="#cb235-583" aria-hidden="true" tabindex="-1"></a>a[<span class="dv">0</span>][<span class="dv">0</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb235-584"><a href="#cb235-584" aria-hidden="true" tabindex="-1"></a>a</span>
<span id="cb235-585"><a href="#cb235-585" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-586"><a href="#cb235-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-589"><a href="#cb235-589" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-590"><a href="#cb235-590" aria-hidden="true" tabindex="-1"></a>b</span>
<span id="cb235-591"><a href="#cb235-591" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-592"><a href="#cb235-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-595"><a href="#cb235-595" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-596"><a href="#cb235-596" aria-hidden="true" tabindex="-1"></a><span class="bu">id</span>(a)</span>
<span id="cb235-597"><a href="#cb235-597" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-598"><a href="#cb235-598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-601"><a href="#cb235-601" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-602"><a href="#cb235-602" aria-hidden="true" tabindex="-1"></a><span class="bu">id</span>(b)</span>
<span id="cb235-603"><a href="#cb235-603" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-604"><a href="#cb235-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-605"><a href="#cb235-605" aria-hidden="true" tabindex="-1"></a>Better way of making a copy</span>
<span id="cb235-606"><a href="#cb235-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-609"><a href="#cb235-609" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-610"><a href="#cb235-610" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> a.clone()</span>
<span id="cb235-611"><a href="#cb235-611" aria-hidden="true" tabindex="-1"></a>a</span>
<span id="cb235-612"><a href="#cb235-612" aria-hidden="true" tabindex="-1"></a>b</span>
<span id="cb235-613"><a href="#cb235-613" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-614"><a href="#cb235-614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-617"><a href="#cb235-617" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-618"><a href="#cb235-618" aria-hidden="true" tabindex="-1"></a>a[<span class="dv">0</span>][<span class="dv">0</span>] <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb235-619"><a href="#cb235-619" aria-hidden="true" tabindex="-1"></a>a</span>
<span id="cb235-620"><a href="#cb235-620" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-621"><a href="#cb235-621" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-624"><a href="#cb235-624" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-625"><a href="#cb235-625" aria-hidden="true" tabindex="-1"></a>b</span>
<span id="cb235-626"><a href="#cb235-626" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-627"><a href="#cb235-627" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-628"><a href="#cb235-628" aria-hidden="true" tabindex="-1"></a>Now, let's check their memory locations. They are at different locations.</span>
<span id="cb235-629"><a href="#cb235-629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-632"><a href="#cb235-632" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-633"><a href="#cb235-633" aria-hidden="true" tabindex="-1"></a><span class="bu">id</span>(a)</span>
<span id="cb235-634"><a href="#cb235-634" aria-hidden="true" tabindex="-1"></a><span class="bu">id</span>(b)</span>
<span id="cb235-635"><a href="#cb235-635" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-636"><a href="#cb235-636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-637"><a href="#cb235-637" aria-hidden="true" tabindex="-1"></a><span class="fu"># Autograd</span></span>
<span id="cb235-638"><a href="#cb235-638" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-639"><a href="#cb235-639" aria-hidden="true" tabindex="-1"></a>Let's go hard way. Let's define our own differentiation formula. Our equation was $y = x^2$. So, the derivative $\frac{dy}{dx}$ will be $2x$.</span>
<span id="cb235-640"><a href="#cb235-640" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-643"><a href="#cb235-643" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-644"><a href="#cb235-644" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> dy_dx(x):</span>
<span id="cb235-645"><a href="#cb235-645" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> <span class="dv">2</span><span class="op">*</span>x</span>
<span id="cb235-646"><a href="#cb235-646" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-647"><a href="#cb235-647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-648"><a href="#cb235-648" aria-hidden="true" tabindex="-1"></a>Let's check for $x = 3$ now.</span>
<span id="cb235-649"><a href="#cb235-649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-652"><a href="#cb235-652" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-653"><a href="#cb235-653" aria-hidden="true" tabindex="-1"></a>dy_dx(<span class="dv">3</span>)</span>
<span id="cb235-654"><a href="#cb235-654" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-655"><a href="#cb235-655" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-656"><a href="#cb235-656" aria-hidden="true" tabindex="-1"></a>But using <span class="in">`PyTorch`</span>, it will be easy.</span>
<span id="cb235-657"><a href="#cb235-657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-660"><a href="#cb235-660" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-661"><a href="#cb235-661" aria-hidden="true" tabindex="-1"></a><span class="co">#import torch</span></span>
<span id="cb235-662"><a href="#cb235-662" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor(<span class="fl">3.0</span>, requires_grad<span class="op">=</span><span class="va">True</span>) <span class="co">#gradient calculation requirement is set as True</span></span>
<span id="cb235-663"><a href="#cb235-663" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x<span class="op">**</span><span class="dv">2</span></span>
<span id="cb235-664"><a href="#cb235-664" aria-hidden="true" tabindex="-1"></a>x</span>
<span id="cb235-665"><a href="#cb235-665" aria-hidden="true" tabindex="-1"></a>y</span>
<span id="cb235-666"><a href="#cb235-666" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-667"><a href="#cb235-667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-668"><a href="#cb235-668" aria-hidden="true" tabindex="-1"></a>We need to use <span class="in">`backward`</span> on the last calculation (or variable) though, to calculate the gradient.</span>
<span id="cb235-669"><a href="#cb235-669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-672"><a href="#cb235-672" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-673"><a href="#cb235-673" aria-hidden="true" tabindex="-1"></a><span class="co">#| error: true</span></span>
<span id="cb235-674"><a href="#cb235-674" aria-hidden="true" tabindex="-1"></a>y.backward()</span>
<span id="cb235-675"><a href="#cb235-675" aria-hidden="true" tabindex="-1"></a>x.grad</span>
<span id="cb235-676"><a href="#cb235-676" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-677"><a href="#cb235-677" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-678"><a href="#cb235-678" aria-hidden="true" tabindex="-1"></a>Now, let's make the situation a bit complex. Let's say we have another equation $z = sin(y)$. So, if we want to calculate $\frac{dz}{dx}$, it requires a chain formula to calculate the derivative. And it will be: $$\frac{dz}{dx} = \frac{dz}{dy}*\frac{dy}{dx}$$. If we solve the formula, the derivative will be: $2*x*cos(x^2)$. And yes, since we have a trigonometric formula, we need to load the math library.</span>
<span id="cb235-679"><a href="#cb235-679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-682"><a href="#cb235-682" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-683"><a href="#cb235-683" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb235-684"><a href="#cb235-684" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-685"><a href="#cb235-685" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> dz_dx(x):</span>
<span id="cb235-686"><a href="#cb235-686" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">2</span> <span class="op">*</span> x <span class="op">*</span> math.cos(x<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb235-687"><a href="#cb235-687" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-688"><a href="#cb235-688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-691"><a href="#cb235-691" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-692"><a href="#cb235-692" aria-hidden="true" tabindex="-1"></a>dz_dx(<span class="dv">2</span>) <span class="co">#you can decide the value of your x here</span></span>
<span id="cb235-693"><a href="#cb235-693" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-694"><a href="#cb235-694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-695"><a href="#cb235-695" aria-hidden="true" tabindex="-1"></a>But let's use our friend <span class="in">`PyTorch`</span> to make our life easier.</span>
<span id="cb235-696"><a href="#cb235-696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-699"><a href="#cb235-699" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-700"><a href="#cb235-700" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor(<span class="fl">2.0</span>, requires_grad<span class="op">=</span><span class="va">True</span>) <span class="co">#you can decide the value of your x here</span></span>
<span id="cb235-701"><a href="#cb235-701" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-702"><a href="#cb235-702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-705"><a href="#cb235-705" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-706"><a href="#cb235-706" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x<span class="op">**</span><span class="dv">2</span></span>
<span id="cb235-707"><a href="#cb235-707" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-708"><a href="#cb235-708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-711"><a href="#cb235-711" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-712"><a href="#cb235-712" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> torch.sin(y)</span>
<span id="cb235-713"><a href="#cb235-713" aria-hidden="true" tabindex="-1"></a>x</span>
<span id="cb235-714"><a href="#cb235-714" aria-hidden="true" tabindex="-1"></a>y</span>
<span id="cb235-715"><a href="#cb235-715" aria-hidden="true" tabindex="-1"></a>z</span>
<span id="cb235-716"><a href="#cb235-716" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-717"><a href="#cb235-717" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-718"><a href="#cb235-718" aria-hidden="true" tabindex="-1"></a>So, let's use <span class="in">`backward`</span> on our <span class="in">`z`</span>.</span>
<span id="cb235-719"><a href="#cb235-719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-722"><a href="#cb235-722" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-723"><a href="#cb235-723" aria-hidden="true" tabindex="-1"></a>z.backward()</span>
<span id="cb235-724"><a href="#cb235-724" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-725"><a href="#cb235-725" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-728"><a href="#cb235-728" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-729"><a href="#cb235-729" aria-hidden="true" tabindex="-1"></a>x.grad</span>
<span id="cb235-730"><a href="#cb235-730" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-731"><a href="#cb235-731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-734"><a href="#cb235-734" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-735"><a href="#cb235-735" aria-hidden="true" tabindex="-1"></a>y.grad</span>
<span id="cb235-736"><a href="#cb235-736" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-737"><a href="#cb235-737" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-738"><a href="#cb235-738" aria-hidden="true" tabindex="-1"></a><span class="in">`y.grad`</span> is not possible, since it is an intermediate leaf.</span>
<span id="cb235-739"><a href="#cb235-739" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-740"><a href="#cb235-740" aria-hidden="true" tabindex="-1"></a><span class="fu">## Real-world example:</span></span>
<span id="cb235-741"><a href="#cb235-741" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-742"><a href="#cb235-742" aria-hidden="true" tabindex="-1"></a>Let's say a student got CGPA 3.10 and did not get a placement in an institute. So, we can try to make a prediction.</span>
<span id="cb235-743"><a href="#cb235-743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-746"><a href="#cb235-746" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-747"><a href="#cb235-747" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb235-748"><a href="#cb235-748" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-749"><a href="#cb235-749" aria-hidden="true" tabindex="-1"></a><span class="co"># Inputs</span></span>
<span id="cb235-750"><a href="#cb235-750" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor(<span class="fl">6.70</span>)  <span class="co"># Input feature</span></span>
<span id="cb235-751"><a href="#cb235-751" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.tensor(<span class="fl">0.0</span>)  <span class="co"># True label (binary)</span></span>
<span id="cb235-752"><a href="#cb235-752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-753"><a href="#cb235-753" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> torch.tensor(<span class="fl">1.0</span>)  <span class="co"># Weight</span></span>
<span id="cb235-754"><a href="#cb235-754" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.tensor(<span class="fl">0.0</span>)  <span class="co"># Bias</span></span>
<span id="cb235-755"><a href="#cb235-755" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-756"><a href="#cb235-756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-759"><a href="#cb235-759" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-760"><a href="#cb235-760" aria-hidden="true" tabindex="-1"></a><span class="co"># Binary Cross-Entropy Loss for scalar</span></span>
<span id="cb235-761"><a href="#cb235-761" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> binary_cross_entropy_loss(prediction, target):</span>
<span id="cb235-762"><a href="#cb235-762" aria-hidden="true" tabindex="-1"></a>    epsilon <span class="op">=</span> <span class="fl">1e-8</span>  <span class="co"># To prevent log(0)</span></span>
<span id="cb235-763"><a href="#cb235-763" aria-hidden="true" tabindex="-1"></a>    prediction <span class="op">=</span> torch.clamp(prediction, epsilon, <span class="dv">1</span> <span class="op">-</span> epsilon)</span>
<span id="cb235-764"><a href="#cb235-764" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span>(target <span class="op">*</span> torch.log(prediction) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> target) <span class="op">*</span> torch.log(<span class="dv">1</span> <span class="op">-</span> prediction))</span>
<span id="cb235-765"><a href="#cb235-765" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-766"><a href="#cb235-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-769"><a href="#cb235-769" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-770"><a href="#cb235-770" aria-hidden="true" tabindex="-1"></a><span class="co"># Forward pass</span></span>
<span id="cb235-771"><a href="#cb235-771" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> w <span class="op">*</span> x <span class="op">+</span> b  <span class="co"># Weighted sum (linear part)</span></span>
<span id="cb235-772"><a href="#cb235-772" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> torch.sigmoid(z)  <span class="co"># Predicted probability</span></span>
<span id="cb235-773"><a href="#cb235-773" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-774"><a href="#cb235-774" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute binary cross-entropy loss</span></span>
<span id="cb235-775"><a href="#cb235-775" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> binary_cross_entropy_loss(y_pred, y)</span>
<span id="cb235-776"><a href="#cb235-776" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-777"><a href="#cb235-777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-780"><a href="#cb235-780" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-781"><a href="#cb235-781" aria-hidden="true" tabindex="-1"></a><span class="co"># Derivatives:</span></span>
<span id="cb235-782"><a href="#cb235-782" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. dL/d(y_pred): Loss with respect to the prediction (y_pred)</span></span>
<span id="cb235-783"><a href="#cb235-783" aria-hidden="true" tabindex="-1"></a>dloss_dy_pred <span class="op">=</span> (y_pred <span class="op">-</span> y)<span class="op">/</span>(y_pred<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>y_pred))</span>
<span id="cb235-784"><a href="#cb235-784" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-785"><a href="#cb235-785" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. dy_pred/dz: Prediction (y_pred) with respect to z (sigmoid derivative)</span></span>
<span id="cb235-786"><a href="#cb235-786" aria-hidden="true" tabindex="-1"></a>dy_pred_dz <span class="op">=</span> y_pred <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> y_pred)</span>
<span id="cb235-787"><a href="#cb235-787" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-788"><a href="#cb235-788" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. dz/dw and dz/db: z with respect to w and b</span></span>
<span id="cb235-789"><a href="#cb235-789" aria-hidden="true" tabindex="-1"></a>dz_dw <span class="op">=</span> x  <span class="co"># dz/dw = x</span></span>
<span id="cb235-790"><a href="#cb235-790" aria-hidden="true" tabindex="-1"></a>dz_db <span class="op">=</span> <span class="dv">1</span>  <span class="co"># dz/db = 1 (bias contributes directly to z)</span></span>
<span id="cb235-791"><a href="#cb235-791" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-792"><a href="#cb235-792" aria-hidden="true" tabindex="-1"></a>dL_dw <span class="op">=</span> dloss_dy_pred <span class="op">*</span> dy_pred_dz <span class="op">*</span> dz_dw</span>
<span id="cb235-793"><a href="#cb235-793" aria-hidden="true" tabindex="-1"></a>dL_db <span class="op">=</span> dloss_dy_pred <span class="op">*</span> dy_pred_dz <span class="op">*</span> dz_db</span>
<span id="cb235-794"><a href="#cb235-794" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-795"><a href="#cb235-795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-798"><a href="#cb235-798" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-799"><a href="#cb235-799" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Manual Gradient of loss w.r.t weight (dw): </span><span class="sc">{</span>dL_dw<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb235-800"><a href="#cb235-800" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Manual Gradient of loss w.r.t bias (db): </span><span class="sc">{</span>dL_db<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb235-801"><a href="#cb235-801" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-802"><a href="#cb235-802" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-803"><a href="#cb235-803" aria-hidden="true" tabindex="-1"></a>But let's use our friend again.</span>
<span id="cb235-804"><a href="#cb235-804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-807"><a href="#cb235-807" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-808"><a href="#cb235-808" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor(<span class="fl">6.7</span>)</span>
<span id="cb235-809"><a href="#cb235-809" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.tensor(<span class="fl">0.0</span>)</span>
<span id="cb235-810"><a href="#cb235-810" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-811"><a href="#cb235-811" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-814"><a href="#cb235-814" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-815"><a href="#cb235-815" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> torch.tensor(<span class="fl">1.0</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb235-816"><a href="#cb235-816" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.tensor(<span class="fl">0.0</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb235-817"><a href="#cb235-817" aria-hidden="true" tabindex="-1"></a>w</span>
<span id="cb235-818"><a href="#cb235-818" aria-hidden="true" tabindex="-1"></a>b</span>
<span id="cb235-819"><a href="#cb235-819" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-820"><a href="#cb235-820" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-823"><a href="#cb235-823" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-824"><a href="#cb235-824" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> w<span class="op">*</span>x <span class="op">+</span> b</span>
<span id="cb235-825"><a href="#cb235-825" aria-hidden="true" tabindex="-1"></a>z</span>
<span id="cb235-826"><a href="#cb235-826" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> torch.sigmoid(z)</span>
<span id="cb235-827"><a href="#cb235-827" aria-hidden="true" tabindex="-1"></a>y_pred</span>
<span id="cb235-828"><a href="#cb235-828" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> binary_cross_entropy_loss(y_pred, y)</span>
<span id="cb235-829"><a href="#cb235-829" aria-hidden="true" tabindex="-1"></a>loss</span>
<span id="cb235-830"><a href="#cb235-830" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-831"><a href="#cb235-831" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-834"><a href="#cb235-834" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-835"><a href="#cb235-835" aria-hidden="true" tabindex="-1"></a>loss.backward()</span>
<span id="cb235-836"><a href="#cb235-836" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-837"><a href="#cb235-837" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-840"><a href="#cb235-840" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-841"><a href="#cb235-841" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(w.grad)</span>
<span id="cb235-842"><a href="#cb235-842" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(b.grad)</span>
<span id="cb235-843"><a href="#cb235-843" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-844"><a href="#cb235-844" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-845"><a href="#cb235-845" aria-hidden="true" tabindex="-1"></a>Let's insert multiple values (or a vector).</span>
<span id="cb235-846"><a href="#cb235-846" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-849"><a href="#cb235-849" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-850"><a href="#cb235-850" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="fl">1.0</span>, <span class="fl">2.0</span>, <span class="fl">3.0</span>], requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb235-851"><a href="#cb235-851" aria-hidden="true" tabindex="-1"></a>x</span>
<span id="cb235-852"><a href="#cb235-852" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-853"><a href="#cb235-853" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-856"><a href="#cb235-856" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-857"><a href="#cb235-857" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> (x<span class="op">**</span><span class="dv">2</span>).mean()</span>
<span id="cb235-858"><a href="#cb235-858" aria-hidden="true" tabindex="-1"></a>y</span>
<span id="cb235-859"><a href="#cb235-859" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-860"><a href="#cb235-860" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-863"><a href="#cb235-863" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-864"><a href="#cb235-864" aria-hidden="true" tabindex="-1"></a>y.backward()</span>
<span id="cb235-865"><a href="#cb235-865" aria-hidden="true" tabindex="-1"></a>x.grad</span>
<span id="cb235-866"><a href="#cb235-866" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-867"><a href="#cb235-867" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-868"><a href="#cb235-868" aria-hidden="true" tabindex="-1"></a>If we rerun all these things, the values get updtaed. So, we need to stop this behavior. How to do it?</span>
<span id="cb235-869"><a href="#cb235-869" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-872"><a href="#cb235-872" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-873"><a href="#cb235-873" aria-hidden="true" tabindex="-1"></a><span class="co"># clearing grad</span></span>
<span id="cb235-874"><a href="#cb235-874" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor(<span class="fl">2.0</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb235-875"><a href="#cb235-875" aria-hidden="true" tabindex="-1"></a>x</span>
<span id="cb235-876"><a href="#cb235-876" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-877"><a href="#cb235-877" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-880"><a href="#cb235-880" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-881"><a href="#cb235-881" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb235-882"><a href="#cb235-882" aria-hidden="true" tabindex="-1"></a>y</span>
<span id="cb235-883"><a href="#cb235-883" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-884"><a href="#cb235-884" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-887"><a href="#cb235-887" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-888"><a href="#cb235-888" aria-hidden="true" tabindex="-1"></a>y.backward()</span>
<span id="cb235-889"><a href="#cb235-889" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-890"><a href="#cb235-890" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-893"><a href="#cb235-893" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-894"><a href="#cb235-894" aria-hidden="true" tabindex="-1"></a>x.grad</span>
<span id="cb235-895"><a href="#cb235-895" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-896"><a href="#cb235-896" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-899"><a href="#cb235-899" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-900"><a href="#cb235-900" aria-hidden="true" tabindex="-1"></a>x.grad.zero_()</span>
<span id="cb235-901"><a href="#cb235-901" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-902"><a href="#cb235-902" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-903"><a href="#cb235-903" aria-hidden="true" tabindex="-1"></a>Now, we don't see <span class="in">`requires_grad=True`</span> part here. So, it is off. Another way:</span>
<span id="cb235-904"><a href="#cb235-904" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-907"><a href="#cb235-907" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-908"><a href="#cb235-908" aria-hidden="true" tabindex="-1"></a><span class="co"># option 1 - requires_grad_(False)</span></span>
<span id="cb235-909"><a href="#cb235-909" aria-hidden="true" tabindex="-1"></a><span class="co"># option 2 - detach()</span></span>
<span id="cb235-910"><a href="#cb235-910" aria-hidden="true" tabindex="-1"></a><span class="co"># option 3 - torch.no_grad()</span></span>
<span id="cb235-911"><a href="#cb235-911" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-912"><a href="#cb235-912" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-915"><a href="#cb235-915" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-916"><a href="#cb235-916" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor(<span class="fl">2.0</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb235-917"><a href="#cb235-917" aria-hidden="true" tabindex="-1"></a>x</span>
<span id="cb235-918"><a href="#cb235-918" aria-hidden="true" tabindex="-1"></a>x.requires_grad_(<span class="va">False</span>)</span>
<span id="cb235-919"><a href="#cb235-919" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-920"><a href="#cb235-920" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-923"><a href="#cb235-923" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-924"><a href="#cb235-924" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb235-925"><a href="#cb235-925" aria-hidden="true" tabindex="-1"></a>y</span>
<span id="cb235-926"><a href="#cb235-926" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-927"><a href="#cb235-927" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-930"><a href="#cb235-930" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-931"><a href="#cb235-931" aria-hidden="true" tabindex="-1"></a><span class="co">#| error: true</span></span>
<span id="cb235-932"><a href="#cb235-932" aria-hidden="true" tabindex="-1"></a><span class="co">#not possible now</span></span>
<span id="cb235-933"><a href="#cb235-933" aria-hidden="true" tabindex="-1"></a>y.backward()</span>
<span id="cb235-934"><a href="#cb235-934" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-935"><a href="#cb235-935" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-938"><a href="#cb235-938" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-939"><a href="#cb235-939" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor(<span class="fl">2.0</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb235-940"><a href="#cb235-940" aria-hidden="true" tabindex="-1"></a>x</span>
<span id="cb235-941"><a href="#cb235-941" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-942"><a href="#cb235-942" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-945"><a href="#cb235-945" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-946"><a href="#cb235-946" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> x.detach()</span>
<span id="cb235-947"><a href="#cb235-947" aria-hidden="true" tabindex="-1"></a>z</span>
<span id="cb235-948"><a href="#cb235-948" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-949"><a href="#cb235-949" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-952"><a href="#cb235-952" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-953"><a href="#cb235-953" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb235-954"><a href="#cb235-954" aria-hidden="true" tabindex="-1"></a>y</span>
<span id="cb235-955"><a href="#cb235-955" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-956"><a href="#cb235-956" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-959"><a href="#cb235-959" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-960"><a href="#cb235-960" aria-hidden="true" tabindex="-1"></a>y1 <span class="op">=</span> z <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb235-961"><a href="#cb235-961" aria-hidden="true" tabindex="-1"></a>y1</span>
<span id="cb235-962"><a href="#cb235-962" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-963"><a href="#cb235-963" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-966"><a href="#cb235-966" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-967"><a href="#cb235-967" aria-hidden="true" tabindex="-1"></a>y.backward() <span class="co">#possible</span></span>
<span id="cb235-968"><a href="#cb235-968" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-969"><a href="#cb235-969" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-972"><a href="#cb235-972" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-973"><a href="#cb235-973" aria-hidden="true" tabindex="-1"></a><span class="co">#| error: true</span></span>
<span id="cb235-974"><a href="#cb235-974" aria-hidden="true" tabindex="-1"></a>y1.backward() <span class="co">#not possible</span></span>
<span id="cb235-975"><a href="#cb235-975" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-976"><a href="#cb235-976" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-977"><a href="#cb235-977" aria-hidden="true" tabindex="-1"></a><span class="fu"># PyTorch Trining Pipeline</span></span>
<span id="cb235-978"><a href="#cb235-978" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-981"><a href="#cb235-981" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-982"><a href="#cb235-982" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb235-983"><a href="#cb235-983" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb235-984"><a href="#cb235-984" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb235-985"><a href="#cb235-985" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb235-986"><a href="#cb235-986" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb235-987"><a href="#cb235-987" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder</span>
<span id="cb235-988"><a href="#cb235-988" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-989"><a href="#cb235-989" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-990"><a href="#cb235-990" aria-hidden="true" tabindex="-1"></a>Load an example dataset</span>
<span id="cb235-991"><a href="#cb235-991" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-994"><a href="#cb235-994" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-995"><a href="#cb235-995" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv'</span>)</span>
<span id="cb235-996"><a href="#cb235-996" aria-hidden="true" tabindex="-1"></a>df.head()</span>
<span id="cb235-997"><a href="#cb235-997" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-998"><a href="#cb235-998" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1001"><a href="#cb235-1001" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1002"><a href="#cb235-1002" aria-hidden="true" tabindex="-1"></a>df.shape</span>
<span id="cb235-1003"><a href="#cb235-1003" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1004"><a href="#cb235-1004" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1007"><a href="#cb235-1007" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1008"><a href="#cb235-1008" aria-hidden="true" tabindex="-1"></a>df.drop(columns<span class="op">=</span>[<span class="st">'id'</span>, <span class="st">'Unnamed: 32'</span>], inplace<span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb235-1009"><a href="#cb235-1009" aria-hidden="true" tabindex="-1"></a>df.head()</span>
<span id="cb235-1010"><a href="#cb235-1010" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1011"><a href="#cb235-1011" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1012"><a href="#cb235-1012" aria-hidden="true" tabindex="-1"></a><span class="fu">## Train test split</span></span>
<span id="cb235-1013"><a href="#cb235-1013" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1016"><a href="#cb235-1016" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1017"><a href="#cb235-1017" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(df.iloc[:, <span class="dv">1</span>:], df.iloc[:, <span class="dv">0</span>], test_size<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb235-1018"><a href="#cb235-1018" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1019"><a href="#cb235-1019" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1020"><a href="#cb235-1020" aria-hidden="true" tabindex="-1"></a><span class="fu">## Scaling</span></span>
<span id="cb235-1021"><a href="#cb235-1021" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1024"><a href="#cb235-1024" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1025"><a href="#cb235-1025" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb235-1026"><a href="#cb235-1026" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb235-1027"><a href="#cb235-1027" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> scaler.transform(X_test)</span>
<span id="cb235-1028"><a href="#cb235-1028" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1029"><a href="#cb235-1029" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1032"><a href="#cb235-1032" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1033"><a href="#cb235-1033" aria-hidden="true" tabindex="-1"></a>X_train</span>
<span id="cb235-1034"><a href="#cb235-1034" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1035"><a href="#cb235-1035" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1038"><a href="#cb235-1038" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1039"><a href="#cb235-1039" aria-hidden="true" tabindex="-1"></a>y_train</span>
<span id="cb235-1040"><a href="#cb235-1040" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1041"><a href="#cb235-1041" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1042"><a href="#cb235-1042" aria-hidden="true" tabindex="-1"></a><span class="fu">## Label Encoding</span></span>
<span id="cb235-1043"><a href="#cb235-1043" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1046"><a href="#cb235-1046" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1047"><a href="#cb235-1047" aria-hidden="true" tabindex="-1"></a>encoder <span class="op">=</span> LabelEncoder()</span>
<span id="cb235-1048"><a href="#cb235-1048" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> encoder.fit_transform(y_train)</span>
<span id="cb235-1049"><a href="#cb235-1049" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> encoder.transform(y_test)</span>
<span id="cb235-1050"><a href="#cb235-1050" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1051"><a href="#cb235-1051" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1054"><a href="#cb235-1054" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1055"><a href="#cb235-1055" aria-hidden="true" tabindex="-1"></a>y_train</span>
<span id="cb235-1056"><a href="#cb235-1056" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1057"><a href="#cb235-1057" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1058"><a href="#cb235-1058" aria-hidden="true" tabindex="-1"></a><span class="fu">## Numpy arrays to PyTorch tensors</span></span>
<span id="cb235-1059"><a href="#cb235-1059" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1062"><a href="#cb235-1062" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1063"><a href="#cb235-1063" aria-hidden="true" tabindex="-1"></a>X_train_tensor <span class="op">=</span> torch.from_numpy(X_train)</span>
<span id="cb235-1064"><a href="#cb235-1064" aria-hidden="true" tabindex="-1"></a>X_test_tensor <span class="op">=</span> torch.from_numpy(X_test)</span>
<span id="cb235-1065"><a href="#cb235-1065" aria-hidden="true" tabindex="-1"></a>y_train_tensor <span class="op">=</span> torch.from_numpy(y_train)</span>
<span id="cb235-1066"><a href="#cb235-1066" aria-hidden="true" tabindex="-1"></a>y_test_tensor <span class="op">=</span> torch.from_numpy(y_test)</span>
<span id="cb235-1067"><a href="#cb235-1067" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1068"><a href="#cb235-1068" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1071"><a href="#cb235-1071" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1072"><a href="#cb235-1072" aria-hidden="true" tabindex="-1"></a>X_train_tensor.shape</span>
<span id="cb235-1073"><a href="#cb235-1073" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1074"><a href="#cb235-1074" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1077"><a href="#cb235-1077" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1078"><a href="#cb235-1078" aria-hidden="true" tabindex="-1"></a>y_train_tensor.shape</span>
<span id="cb235-1079"><a href="#cb235-1079" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1080"><a href="#cb235-1080" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1081"><a href="#cb235-1081" aria-hidden="true" tabindex="-1"></a><span class="fu">## Defining the model</span></span>
<span id="cb235-1082"><a href="#cb235-1082" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1085"><a href="#cb235-1085" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1086"><a href="#cb235-1086" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MySimpleNN():</span>
<span id="cb235-1087"><a href="#cb235-1087" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1088"><a href="#cb235-1088" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, X):</span>
<span id="cb235-1089"><a href="#cb235-1089" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1090"><a href="#cb235-1090" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.weights <span class="op">=</span> torch.rand(X.shape[<span class="dv">1</span>], <span class="dv">1</span>, dtype<span class="op">=</span>torch.float64, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb235-1091"><a href="#cb235-1091" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.bias <span class="op">=</span> torch.zeros(<span class="dv">1</span>, dtype<span class="op">=</span>torch.float64, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb235-1092"><a href="#cb235-1092" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1093"><a href="#cb235-1093" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> forward(<span class="va">self</span>, X):</span>
<span id="cb235-1094"><a href="#cb235-1094" aria-hidden="true" tabindex="-1"></a>    z <span class="op">=</span> torch.matmul(X, <span class="va">self</span>.weights) <span class="op">+</span> <span class="va">self</span>.bias</span>
<span id="cb235-1095"><a href="#cb235-1095" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> torch.sigmoid(z)</span>
<span id="cb235-1096"><a href="#cb235-1096" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> y_pred</span>
<span id="cb235-1097"><a href="#cb235-1097" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1098"><a href="#cb235-1098" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> loss_function(<span class="va">self</span>, y_pred, y):</span>
<span id="cb235-1099"><a href="#cb235-1099" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Clamp predictions to avoid log(0)</span></span>
<span id="cb235-1100"><a href="#cb235-1100" aria-hidden="true" tabindex="-1"></a>    epsilon <span class="op">=</span> <span class="fl">1e-7</span></span>
<span id="cb235-1101"><a href="#cb235-1101" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> torch.clamp(y_pred, epsilon, <span class="dv">1</span> <span class="op">-</span> epsilon)</span>
<span id="cb235-1102"><a href="#cb235-1102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1103"><a href="#cb235-1103" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate loss</span></span>
<span id="cb235-1104"><a href="#cb235-1104" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> <span class="op">-</span>(y_train_tensor <span class="op">*</span> torch.log(y_pred) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> y_train_tensor) <span class="op">*</span> torch.log(<span class="dv">1</span> <span class="op">-</span> y_pred)).mean()</span>
<span id="cb235-1105"><a href="#cb235-1105" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> loss</span>
<span id="cb235-1106"><a href="#cb235-1106" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1107"><a href="#cb235-1107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1108"><a href="#cb235-1108" aria-hidden="true" tabindex="-1"></a><span class="fu">## Important Parameters</span></span>
<span id="cb235-1109"><a href="#cb235-1109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1112"><a href="#cb235-1112" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1113"><a href="#cb235-1113" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb235-1114"><a href="#cb235-1114" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">25</span></span>
<span id="cb235-1115"><a href="#cb235-1115" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1116"><a href="#cb235-1116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1117"><a href="#cb235-1117" aria-hidden="true" tabindex="-1"></a><span class="fu">## Training Pipeline</span></span>
<span id="cb235-1118"><a href="#cb235-1118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1121"><a href="#cb235-1121" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1122"><a href="#cb235-1122" aria-hidden="true" tabindex="-1"></a><span class="co"># create model</span></span>
<span id="cb235-1123"><a href="#cb235-1123" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> MySimpleNN(X_train_tensor)</span>
<span id="cb235-1124"><a href="#cb235-1124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1125"><a href="#cb235-1125" aria-hidden="true" tabindex="-1"></a><span class="co"># define loop</span></span>
<span id="cb235-1126"><a href="#cb235-1126" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb235-1127"><a href="#cb235-1127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1128"><a href="#cb235-1128" aria-hidden="true" tabindex="-1"></a>  <span class="co"># forward pass</span></span>
<span id="cb235-1129"><a href="#cb235-1129" aria-hidden="true" tabindex="-1"></a>  y_pred <span class="op">=</span> model.forward(X_train_tensor)</span>
<span id="cb235-1130"><a href="#cb235-1130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1131"><a href="#cb235-1131" aria-hidden="true" tabindex="-1"></a>  <span class="co"># loss calculate</span></span>
<span id="cb235-1132"><a href="#cb235-1132" aria-hidden="true" tabindex="-1"></a>  loss <span class="op">=</span> model.loss_function(y_pred, y_train_tensor)</span>
<span id="cb235-1133"><a href="#cb235-1133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1134"><a href="#cb235-1134" aria-hidden="true" tabindex="-1"></a>  <span class="co"># backward pass</span></span>
<span id="cb235-1135"><a href="#cb235-1135" aria-hidden="true" tabindex="-1"></a>  loss.backward()</span>
<span id="cb235-1136"><a href="#cb235-1136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1137"><a href="#cb235-1137" aria-hidden="true" tabindex="-1"></a>  <span class="co"># parameters update</span></span>
<span id="cb235-1138"><a href="#cb235-1138" aria-hidden="true" tabindex="-1"></a>  <span class="cf">with</span> torch.no_grad():</span>
<span id="cb235-1139"><a href="#cb235-1139" aria-hidden="true" tabindex="-1"></a>    model.weights <span class="op">-=</span> learning_rate <span class="op">*</span> model.weights.grad</span>
<span id="cb235-1140"><a href="#cb235-1140" aria-hidden="true" tabindex="-1"></a>    model.bias <span class="op">-=</span> learning_rate <span class="op">*</span> model.bias.grad</span>
<span id="cb235-1141"><a href="#cb235-1141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1142"><a href="#cb235-1142" aria-hidden="true" tabindex="-1"></a>  <span class="co"># zero gradients</span></span>
<span id="cb235-1143"><a href="#cb235-1143" aria-hidden="true" tabindex="-1"></a>  model.weights.grad.zero_()</span>
<span id="cb235-1144"><a href="#cb235-1144" aria-hidden="true" tabindex="-1"></a>  model.bias.grad.zero_()</span>
<span id="cb235-1145"><a href="#cb235-1145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1146"><a href="#cb235-1146" aria-hidden="true" tabindex="-1"></a>  <span class="co"># print loss in each epoch</span></span>
<span id="cb235-1147"><a href="#cb235-1147" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="ss">f'Epoch: </span><span class="sc">{</span>epoch <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">, Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb235-1148"><a href="#cb235-1148" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1149"><a href="#cb235-1149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1152"><a href="#cb235-1152" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1153"><a href="#cb235-1153" aria-hidden="true" tabindex="-1"></a>model.bias</span>
<span id="cb235-1154"><a href="#cb235-1154" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1155"><a href="#cb235-1155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1158"><a href="#cb235-1158" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1159"><a href="#cb235-1159" aria-hidden="true" tabindex="-1"></a>model.weights</span>
<span id="cb235-1160"><a href="#cb235-1160" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1161"><a href="#cb235-1161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1162"><a href="#cb235-1162" aria-hidden="true" tabindex="-1"></a><span class="fu">## Evaluation</span></span>
<span id="cb235-1163"><a href="#cb235-1163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1166"><a href="#cb235-1166" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1167"><a href="#cb235-1167" aria-hidden="true" tabindex="-1"></a><span class="co"># model evaluation</span></span>
<span id="cb235-1168"><a href="#cb235-1168" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb235-1169"><a href="#cb235-1169" aria-hidden="true" tabindex="-1"></a>  y_pred <span class="op">=</span> model.forward(X_test_tensor)</span>
<span id="cb235-1170"><a href="#cb235-1170" aria-hidden="true" tabindex="-1"></a>  y_pred <span class="op">=</span> (y_pred <span class="op">&gt;</span> <span class="fl">0.9</span>).<span class="bu">float</span>()</span>
<span id="cb235-1171"><a href="#cb235-1171" aria-hidden="true" tabindex="-1"></a>  accuracy <span class="op">=</span> (y_pred <span class="op">==</span> y_test_tensor).<span class="bu">float</span>().mean()</span>
<span id="cb235-1172"><a href="#cb235-1172" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="ss">f'Accuracy: </span><span class="sc">{</span>accuracy<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb235-1173"><a href="#cb235-1173" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1174"><a href="#cb235-1174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1177"><a href="#cb235-1177" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1178"><a href="#cb235-1178" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1179"><a href="#cb235-1179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1182"><a href="#cb235-1182" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1183"><a href="#cb235-1183" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1184"><a href="#cb235-1184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1187"><a href="#cb235-1187" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1188"><a href="#cb235-1188" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1189"><a href="#cb235-1189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1192"><a href="#cb235-1192" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1193"><a href="#cb235-1193" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1194"><a href="#cb235-1194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1197"><a href="#cb235-1197" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1198"><a href="#cb235-1198" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1199"><a href="#cb235-1199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1200"><a href="#cb235-1200" aria-hidden="true" tabindex="-1"></a><span class="fu"># NN module</span></span>
<span id="cb235-1201"><a href="#cb235-1201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1202"><a href="#cb235-1202" aria-hidden="true" tabindex="-1"></a><span class="fu"># Dataset and DataLoader</span></span>
<span id="cb235-1203"><a href="#cb235-1203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1204"><a href="#cb235-1204" aria-hidden="true" tabindex="-1"></a><span class="fu"># ANN/MLP in PyTorch</span></span>
<span id="cb235-1205"><a href="#cb235-1205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1206"><a href="#cb235-1206" aria-hidden="true" tabindex="-1"></a>We will use Fashion MNIST dataset for this purpose. We can find this dataset in Kaggle. It has 70,000 (28<span class="sc">\*</span>28) fashion images. We will try to classify them using our ANN and improve our model. But we will use less images since we are using less local resource (CPU, not GPU).</span>
<span id="cb235-1207"><a href="#cb235-1207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1208"><a href="#cb235-1208" aria-hidden="true" tabindex="-1"></a>Our ANN structure: 1 <span class="in">`input layer`</span> with <span class="in">`28*28 = 784`</span> nodes. Then we will have <span class="in">`2 hidden layers`</span>. The first one will have 128 neurons and the second one will have 64 neurons. Then we will have 1 <span class="in">`output layer`</span> having 10 neurons. The hidden layers will use ReLU and the last output layer will use softmax since it is a multi-class classification problems. Workflow: - DataLoader object - Training loop - Evaluation</span>
<span id="cb235-1209"><a href="#cb235-1209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1212"><a href="#cb235-1212" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1213"><a href="#cb235-1213" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb235-1214"><a href="#cb235-1214" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb235-1215"><a href="#cb235-1215" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb235-1216"><a href="#cb235-1216" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset, DataLoader</span>
<span id="cb235-1217"><a href="#cb235-1217" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb235-1218"><a href="#cb235-1218" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb235-1219"><a href="#cb235-1219" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb235-1220"><a href="#cb235-1220" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1221"><a href="#cb235-1221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1222"><a href="#cb235-1222" aria-hidden="true" tabindex="-1"></a>Now, after loading the packages, we can use them. Let's make it reproducible using a seed.</span>
<span id="cb235-1223"><a href="#cb235-1223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1226"><a href="#cb235-1226" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1227"><a href="#cb235-1227" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">30</span>)</span>
<span id="cb235-1228"><a href="#cb235-1228" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1229"><a href="#cb235-1229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1232"><a href="#cb235-1232" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1233"><a href="#cb235-1233" aria-hidden="true" tabindex="-1"></a><span class="co"># Use Fashion-MNIST from torchvision and create a small CSV</span></span>
<span id="cb235-1234"><a href="#cb235-1234" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb235-1235"><a href="#cb235-1235" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</span>
<span id="cb235-1236"><a href="#cb235-1236" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb235-1237"><a href="#cb235-1237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1238"><a href="#cb235-1238" aria-hidden="true" tabindex="-1"></a><span class="co"># Download Fashion-MNIST</span></span>
<span id="cb235-1239"><a href="#cb235-1239" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([transforms.ToTensor()])</span>
<span id="cb235-1240"><a href="#cb235-1240" aria-hidden="true" tabindex="-1"></a>fmnist <span class="op">=</span> torchvision.datasets.FashionMNIST(root<span class="op">=</span><span class="st">'./data'</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb235-1241"><a href="#cb235-1241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1242"><a href="#cb235-1242" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a small subset (first 1000 samples)</span></span>
<span id="cb235-1243"><a href="#cb235-1243" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb235-1244"><a href="#cb235-1244" aria-hidden="true" tabindex="-1"></a>images_list <span class="op">=</span> []</span>
<span id="cb235-1245"><a href="#cb235-1245" aria-hidden="true" tabindex="-1"></a>labels_list <span class="op">=</span> []</span>
<span id="cb235-1246"><a href="#cb235-1246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1247"><a href="#cb235-1247" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">min</span>(n_samples, <span class="bu">len</span>(fmnist))):</span>
<span id="cb235-1248"><a href="#cb235-1248" aria-hidden="true" tabindex="-1"></a>    image, label <span class="op">=</span> fmnist[i]</span>
<span id="cb235-1249"><a href="#cb235-1249" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert tensor to numpy and flatten</span></span>
<span id="cb235-1250"><a href="#cb235-1250" aria-hidden="true" tabindex="-1"></a>    image_flat <span class="op">=</span> image.numpy().flatten()</span>
<span id="cb235-1251"><a href="#cb235-1251" aria-hidden="true" tabindex="-1"></a>    images_list.append(image_flat)</span>
<span id="cb235-1252"><a href="#cb235-1252" aria-hidden="true" tabindex="-1"></a>    labels_list.append(label)</span>
<span id="cb235-1253"><a href="#cb235-1253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1254"><a href="#cb235-1254" aria-hidden="true" tabindex="-1"></a><span class="co"># Create DataFrame</span></span>
<span id="cb235-1255"><a href="#cb235-1255" aria-hidden="true" tabindex="-1"></a>images_array <span class="op">=</span> np.array(images_list)</span>
<span id="cb235-1256"><a href="#cb235-1256" aria-hidden="true" tabindex="-1"></a>labels_array <span class="op">=</span> np.array(labels_list)</span>
<span id="cb235-1257"><a href="#cb235-1257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1258"><a href="#cb235-1258" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine labels and images</span></span>
<span id="cb235-1259"><a href="#cb235-1259" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.column_stack([labels_array, images_array])</span>
<span id="cb235-1260"><a href="#cb235-1260" aria-hidden="true" tabindex="-1"></a>columns <span class="op">=</span> [<span class="st">'label'</span>] <span class="op">+</span> [<span class="ss">f'pixel</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">784</span>)]</span>
<span id="cb235-1261"><a href="#cb235-1261" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data, columns<span class="op">=</span>columns)</span>
<span id="cb235-1262"><a href="#cb235-1262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1263"><a href="#cb235-1263" aria-hidden="true" tabindex="-1"></a><span class="co"># Save to CSV for future use</span></span>
<span id="cb235-1264"><a href="#cb235-1264" aria-hidden="true" tabindex="-1"></a>df.to_csv(<span class="st">'fmnist_small.csv'</span>, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb235-1265"><a href="#cb235-1265" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Created fmnist_small.csv with </span><span class="sc">{</span><span class="bu">len</span>(df)<span class="sc">}</span><span class="ss"> samples"</span>)</span>
<span id="cb235-1266"><a href="#cb235-1266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1267"><a href="#cb235-1267" aria-hidden="true" tabindex="-1"></a>df.head()</span>
<span id="cb235-1268"><a href="#cb235-1268" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1269"><a href="#cb235-1269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1270"><a href="#cb235-1270" aria-hidden="true" tabindex="-1"></a>Let's check some images.</span>
<span id="cb235-1271"><a href="#cb235-1271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1274"><a href="#cb235-1274" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1275"><a href="#cb235-1275" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a 4x4 grid of images</span></span>
<span id="cb235-1276"><a href="#cb235-1276" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">4</span>, <span class="dv">4</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb235-1277"><a href="#cb235-1277" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="st">"First 16 Images"</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb235-1278"><a href="#cb235-1278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1279"><a href="#cb235-1279" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the first 16 images from the dataset</span></span>
<span id="cb235-1280"><a href="#cb235-1280" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, ax <span class="kw">in</span> <span class="bu">enumerate</span>(axes.flat):</span>
<span id="cb235-1281"><a href="#cb235-1281" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> df.iloc[i, <span class="dv">1</span>:].values.reshape(<span class="dv">28</span>, <span class="dv">28</span>)  <span class="co"># Reshape to 28x28</span></span>
<span id="cb235-1282"><a href="#cb235-1282" aria-hidden="true" tabindex="-1"></a>    ax.imshow(img)  <span class="co"># Display in grayscale</span></span>
<span id="cb235-1283"><a href="#cb235-1283" aria-hidden="true" tabindex="-1"></a>    ax.axis(<span class="st">'off'</span>)  <span class="co"># Remove axis for a cleaner look</span></span>
<span id="cb235-1284"><a href="#cb235-1284" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f"Label: </span><span class="sc">{</span>df<span class="sc">.</span>iloc[i, <span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)  <span class="co"># Show the label</span></span>
<span id="cb235-1285"><a href="#cb235-1285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1286"><a href="#cb235-1286" aria-hidden="true" tabindex="-1"></a>plt.tight_layout(rect<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.96</span>])  <span class="co"># Adjust layout to fit the title</span></span>
<span id="cb235-1287"><a href="#cb235-1287" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb235-1288"><a href="#cb235-1288" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1289"><a href="#cb235-1289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1292"><a href="#cb235-1292" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1293"><a href="#cb235-1293" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1294"><a href="#cb235-1294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1297"><a href="#cb235-1297" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1298"><a href="#cb235-1298" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1299"><a href="#cb235-1299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1302"><a href="#cb235-1302" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1303"><a href="#cb235-1303" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1304"><a href="#cb235-1304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1307"><a href="#cb235-1307" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1308"><a href="#cb235-1308" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1309"><a href="#cb235-1309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1312"><a href="#cb235-1312" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1313"><a href="#cb235-1313" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1314"><a href="#cb235-1314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1317"><a href="#cb235-1317" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1318"><a href="#cb235-1318" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1319"><a href="#cb235-1319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1322"><a href="#cb235-1322" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1323"><a href="#cb235-1323" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1324"><a href="#cb235-1324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1327"><a href="#cb235-1327" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1328"><a href="#cb235-1328" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1329"><a href="#cb235-1329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1332"><a href="#cb235-1332" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1333"><a href="#cb235-1333" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1334"><a href="#cb235-1334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1337"><a href="#cb235-1337" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1338"><a href="#cb235-1338" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1339"><a href="#cb235-1339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1342"><a href="#cb235-1342" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1343"><a href="#cb235-1343" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1344"><a href="#cb235-1344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1347"><a href="#cb235-1347" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1348"><a href="#cb235-1348" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1349"><a href="#cb235-1349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1352"><a href="#cb235-1352" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1353"><a href="#cb235-1353" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1354"><a href="#cb235-1354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1357"><a href="#cb235-1357" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1358"><a href="#cb235-1358" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1359"><a href="#cb235-1359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1362"><a href="#cb235-1362" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1363"><a href="#cb235-1363" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1364"><a href="#cb235-1364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1367"><a href="#cb235-1367" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1368"><a href="#cb235-1368" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1369"><a href="#cb235-1369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1372"><a href="#cb235-1372" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1373"><a href="#cb235-1373" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1374"><a href="#cb235-1374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1377"><a href="#cb235-1377" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1378"><a href="#cb235-1378" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1379"><a href="#cb235-1379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1382"><a href="#cb235-1382" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1383"><a href="#cb235-1383" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1384"><a href="#cb235-1384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1387"><a href="#cb235-1387" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1388"><a href="#cb235-1388" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1389"><a href="#cb235-1389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1392"><a href="#cb235-1392" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1393"><a href="#cb235-1393" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb235-1394"><a href="#cb235-1394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-1397"><a href="#cb235-1397" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb235-1398"><a href="#cb235-1398" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>