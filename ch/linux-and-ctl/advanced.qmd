---
title: "Advanced Linux and CTL"
abstract: "awk, grep, cut, etc."
---

```{r}
#| include: false
source(here::here("src/helpersrc.R"))
```

# Q1

I have many files inside a folder. I want to move them into to sub-folders named `f1` and `f2` (I made them using `mkdir -p f1 f2`). How to do that?\
This is the way:

```{bash, eval=FALSE}
i=0
for file in $(ls *.fastq.gz | sort -V); do
  if [ $i -le 400 ]; then
    mv "$file" f1/
  else
    mv "$file" f2/
  fi
  i=$((i + 1))
done
```

Here, I am sending files having 0-400 in there name to `f1` folder and remaining ones to `f2`. You just need to use your file naming pattern, and you are all set.

**How to execute/run this file now?**\
Run these:

```{bash, eval=FALSE}
chmod +x move_files.sh
./move_files.sh
```

`chmod +x` is making the file executable. Then we are running it using `./move_files.sh`.




## HPC Cluster connection
I am going to connect to Uni-Greifswald's Brain cluster. 
```{bash, eval=FALSE}
ssh username@brain.uni-greifswald.de
```
You need to give your real username and password. 
Now, let's get an interactive session to the gpu compute node (it is named "vision" for uni-greifswald's gpu node). 
```{bash, eval=FALSE}
srun --pty --gres=gpu:1 --partition=vision --mem=16g -t 12:00:00 bash -i
```
Let's install conda for our environment management. 
```{bash, eval=FALSE}
# Download the Miniconda installer for Linux
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh

# Run the installer, specifying the installation path
bash Miniconda3-latest-Linux-x86_64.sh -b -p ~/miniconda_install/
```
Now, let's initialize conda:
```{bash, eval=FALSE}
# Source the conda shell script to make the 'conda' command available
source ~/miniconda_install/bin/activate

# Initialize conda for the current shell session.
conda init bash
```
Since we're using an interactive session, we won't need to manually source anything after this. The `conda init` command makes it so we can use `conda` and `conda activate` as we normally would.

**N.B. We could make some aliases for conda commands to write conda codes in shorter format, but we can do/see it later.**

Let's make an environment and install our required tools there. Well, our goal is to make a system where we will use some images/characters and make short videos using them to teach Italian. We need to process photos, images, text, and sync lips (video) with audio/speech. We need MuseTalk for this. Let's configure our environment accordingly.  

**Step 1 -- Create conda environment**
```{bash, eval=FALSE}
# Create new environment for MuseTalk
conda create -n musetalk python=3.10
conda activate musetalk
```
**Step 2 -- Install Dependencies**
```{bash, eval=FALSE}
# Create new environment for MuseTalk
# Install PyTorch (adapt cuda version to your cluster, here CUDA 11.8 example)
pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --extra-index-url https://download.pytorch.org/whl/cu118

# HuggingFace core libs
pip install transformers accelerate diffusers safetensors

# MuseTalk repo (clone)
git clone https://github.com/TMElyralab/MuseTalk.git
cd MuseTalk

# Install requirements
pip install -r requirements.txt

# Install whisper encoder
pip install --editable ./musetalk/whisper

# Extra: ffmpeg for video processing
conda install -c conda-forge ffmpeg -y
```
**Step 3 -- Download MuseTalk Models**
MuseTalk Hugging Face repo: https://huggingface.co/TMElyralab/MuseTalk  
We need:  
- musetalk.pth (main model)
- gfpgan (optional face enhancer)

Run inside MuseTalk:
```{bash, eval=FALSE}
mkdir checkpoints
cd checkpoints

# Download core model
wget https://huggingface.co/TMElyralab/MuseTalk/resolve/main/musetalk.pth

# Optional face enhancer
git clone https://github.com/TencentARC/GFPGAN.git
cd ..

```

## Better way:
```{bash, eval=FALSE}
export CUDA_HOME=/usr/local/cuda-11.7
export PATH=$CUDA_HOME/bin:$PATH
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH
```
In my HPC Cluster, it is cuda 11.7. I am configuring for that. We could add these lines in my ~/.bashrc file as well. We might see it later.  

Let's load our cuda module first to get things done smoothly.
```{bash, eval=FALSE}
module load cuda/12.0.0
```
Now, make the `yml` file to make the environment with all the tools required.
```{bash, eval=FALSE}
name: musetalk3
channels:
  - pytorch
  - nvidia
  - defaults
dependencies:
  - python=3.10
  - pip
  - ffmpeg
  - pip:
      # PyTorch + CUDA 11.8 compatible with 11.7 system
      - torch==2.1.0+cu118
      - torchvision==0.16.0+cu118
      - torchaudio==2.1.0+cu118
      - --extra-index-url https://download.pytorch.org/whl/cu118

      # OpenMMLab dependencies
      - mmcv==2.0.1 -f https://download.openmmlab.com/mmcv/dist/cu118/torch2.1.0/index.html
      - mmdet==3.1.0
      - gradio
      - opencv-python
      - numpy
      - scipy
      - matplotlib
      - tqdm
      - pyyaml
      - pillow
      - soundfile
      - librosa
      - moviepy
      - imageio
```
Save this as `musetalk3.yml` and run:
```{bash, eval=FALSE}
conda env create -f musetalk3.yml
conda activate musetalk3
```
Now, we have our environment ready to use. Let's use it.
```{bash, eval=FALSE}
conda activate musetalk3
```
Now, install museetalk repo dependencies. 
```{bash, eval=FALSE}
git clone https://github.com/TMElyralab/MuseTalk.git
cd MuseTalk
pip install -r requirements.txt
```
Let's get the faces I want to use. I uploaded them to my GDrive.
```{bash, eval=FALSE}
pip install gdown

# Get shareable link from Google Drive and copy file id
gdown https://drive.google.com/uc?id=FILE_ID -O data/faces/alice.jpg
gdown https://drive.google.com/uc?id=FILE_ID -O data/faces/bob.jpg
```
modify the google drive links for the images and their destination name as you like it.

# Real work
Now, let's follow the author's guideline.
```{bash, eval=FALSE}
pip install --no-cache-dir -U openmim
mim install mmengine
mim install "mmcv==2.0.1"
mim install "mmdet==3.1.0"
mim install "mmpose==1.1.0"
```
Let's download the model's weight.
```{bash, eval=FALSE}
sh ./download_weights.sh
```
```{bash, eval=FALSE}
# Check ffmpeg installation
ffmpeg -version
```
The conversation
```{bash, eval=FALSE}
pip install TTS

# Example: Alice speaking Italian
tts --text "Buon giorno, Bob! Come stai?" \
    --model_name tts_models/it/mai_female/vits \
    --out_path alice_buongiorno.wav

# Example: Bob replying
tts --text "Buon giorno, Alice! Va bene, grazie mille! Chi Ã¨ questo?" \
    --model_name tts_models/it/mai_male/vits \
    --out_path bob_risposta.wav

```



