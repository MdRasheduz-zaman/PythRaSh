{
  "hash": "2759d2b3f6ee44a3c3a843a885c9a126",
  "result": {
    "markdown": "---\ntitle: \"Artificial Inteligence\"\nabstract: \"Tensor, etc.\"\n---\n\n# Tensor and PyTorch\n\nLet's load `pytorch` library and see the version of it.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport torch\nprint(torch.__version__)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n2.7.0\n```\n:::\n:::\n\n\nUse CPU if GPU (CUDA) is not available.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nif torch.cuda.is_available():\n    print(\"GPU is available!\")\n    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\nelse:\n    print(\"GPU not available. Using CPU.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGPU not available. Using CPU.\n```\n:::\n:::\n\n\nSo, I am using CPU. Let's start making tensors and build from very basics.\n\n## Tensor Creation\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n# using empty\na = torch.empty(2,3)\na\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\ntensor([[0., 0., 0.],\n        [0., 0., 0.]])\n```\n:::\n:::\n\n\nLet's check type of pur tensor.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n# check type\ntype(a)\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\ntorch.Tensor\n```\n:::\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n# using ones\ntorch.ones(3,3)\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\ntensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n# using zeros\ntorch.zeros(3,3)\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\ntensor([[0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n# using rand\ntorch.manual_seed(40)\ntorch.rand(2,3)\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\ntensor([[0.3679, 0.8661, 0.1737],\n        [0.7157, 0.8649, 0.4878]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\ntorch.manual_seed(40)\ntorch.rand(2,3)\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\ntensor([[0.3679, 0.8661, 0.1737],\n        [0.7157, 0.8649, 0.4878]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\ntorch.randint(size=(2,3), low=0, high=10, dtype=torch.float32)\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\ntensor([[6., 3., 6.],\n        [7., 6., 5.]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\n# using tensor\ntorch.tensor([[3,2,1],[4,5,6]])\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\ntensor([[3, 2, 1],\n        [4, 5, 6]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\n# other ways\n\n# arange\na = torch.arange(0,15,3)\nprint(\"using arange ->\", a)\n\n# using linspace\nb = torch.linspace(0,15,10)\nprint(\"using linspace ->\", b)\n\n# using eye\nc = torch.eye(4)\nprint(\"using eye ->\", c)\n\n# using full\nd = torch.full((3, 3), 5)\nprint(\"using full ->\", d)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nusing arange -> tensor([ 0,  3,  6,  9, 12])\nusing linspace -> tensor([ 0.0000,  1.6667,  3.3333,  5.0000,  6.6667,  8.3333, 10.0000, 11.6667,\n        13.3333, 15.0000])\nusing eye -> tensor([[1., 0., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 0., 1., 0.],\n        [0., 0., 0., 1.]])\nusing full -> tensor([[5, 5, 5],\n        [5, 5, 5],\n        [5, 5, 5]])\n```\n:::\n:::\n\n\n## Tensor shape\n\nWe are making a new tensor (`x`) and checking shape of it. We can use the shape of `x` or any other already created tensor to make new tensors of that shape.\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nx = torch.tensor([[1,2,3],[5,6,7]])\nx\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\ntensor([[1, 2, 3],\n        [5, 6, 7]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nx.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\ntorch.Size([2, 3])\n```\n:::\n:::\n\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\ntorch.empty_like(x)\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\ntensor([[0, 0, 0],\n        [0, 0, 0]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\ntorch.zeros_like(x)\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```\ntensor([[0, 0, 0],\n        [0, 0, 0]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\ntorch.rand_like(x)\n```\n\n::: {.cell-output .cell-output-error}\n```\nRuntimeError: \"check_uniform_bounds\" not implemented for 'Long'\n```\n:::\n:::\n\n\nIt's not working, since `rand` makes float values in the tensor. So, we need to specify data type as float.\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\ntorch.rand_like(x, dtype=torch.float32)\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```\ntensor([[0.7583, 0.8896, 0.6959],\n        [0.4810, 0.8545, 0.1130]])\n```\n:::\n:::\n\n\n## Tensor Data Types\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\n# find data type\nx.dtype\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```\ntorch.int64\n```\n:::\n:::\n\n\nWe are changing data type from float to int using `dtype` here.\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\n# assign data type\ntorch.tensor([1.0,2.0,3.0], dtype=torch.int32)\n```\n\n::: {.cell-output .cell-output-display execution_count=19}\n```\ntensor([1, 2, 3], dtype=torch.int32)\n```\n:::\n:::\n\n\nSimilarly, from int to float using `dtype` here.\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\ntorch.tensor([1,2,3], dtype=torch.float64)\n```\n\n::: {.cell-output .cell-output-display execution_count=20}\n```\ntensor([1., 2., 3.], dtype=torch.float64)\n```\n:::\n:::\n\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\n#using to()\nx.to(torch.float32)\n```\n\n::: {.cell-output .cell-output-display execution_count=21}\n```\ntensor([[1., 2., 3.],\n        [5., 6., 7.]])\n```\n:::\n:::\n\n\nSome common data types in torch. \\| **Data Type** \\| **Dtype** \\| **Description** \\| \\|---------------------------\\|-------------------\\|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\| \\| **32-bit Floating Point** \\| `torch.float32` \\| Standard floating-point type used for most deep learning tasks. Provides a balance between precision and memory usage. \\| \\| **64-bit Floating Point** \\| `torch.float64` \\| Double-precision floating point. Useful for high-precision numerical tasks but uses more memory. \\| \\| **16-bit Floating Point** \\| `torch.float16` \\| Half-precision floating point. Commonly used in mixed-precision training to reduce memory and computational overhead on modern GPUs. \\| \\| **BFloat16** \\| `torch.bfloat16` \\| Brain floating-point format with reduced precision compared to `float16`. Used in mixed-precision training, especially on TPUs. \\| \\| **8-bit Floating Point** \\| `torch.float8` \\| Ultra-low-precision floating point. Used for experimental applications and extreme memory-constrained environments (less common). \\| \\| **8-bit Integer** \\| `torch.int8` \\| 8-bit signed integer. Used for quantized models to save memory and computation in inference. \\| \\| **16-bit Integer** \\| `torch.int16` \\| 16-bit signed integer. Useful for special numerical tasks requiring intermediate precision. \\| \\| **32-bit Integer** \\| `torch.int32` \\| Standard signed integer type. Commonly used for indexing and general-purpose numerical tasks. \\| \\| **64-bit Integer** \\| `torch.int64` \\| Long integer type. Often used for large indexing arrays or for tasks involving large numbers. \\| \\| **8-bit Unsigned Integer**\\| `torch.uint8` \\| 8-bit unsigned integer. Commonly used for image data (e.g., pixel values between 0 and 255). \\| \\| **Boolean** \\| `torch.bool` \\| Boolean type, stores `True` or `False` values. Often used for masks in logical operations. \\| \\| **Complex 64** \\| `torch.complex64` \\| Complex number type with 32-bit real and 32-bit imaginary parts. Used for scientific and signal processing tasks. \\| \\| **Complex 128** \\| `torch.complex128`\\| Complex number type with 64-bit real and 64-bit imaginary parts. Offers higher precision but uses more memory. \\| \\| **Quantized Integer** \\| `torch.qint8` \\| Quantized signed 8-bit integer. Used in quantized models for efficient inference. \\| \\| **Quantized Unsigned Integer** \\| `torch.quint8` \\| Quantized unsigned 8-bit integer. Often used for quantized tensors in image-related tasks. \\|\n\n## Mathematical Operations\n\n### Scalar operation\n\nLet's define a tensor x first.\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\nx = torch.rand(2, 3)\nx\n```\n\n::: {.cell-output .cell-output-display execution_count=22}\n```\ntensor([[0.6779, 0.0173, 0.1203],\n        [0.1363, 0.8089, 0.8229]])\n```\n:::\n:::\n\n\nNow, let's see some scalar operation on this tensor.\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\n#addition\nx + 2\n#subtraction\nx - 3\n#multiplication\nx*4\n#division\nx/2\n#integer division\n(x*40)//3\n#modulus division\n((x*40)//3)%2\n#power\nx**2\n```\n\n::: {.cell-output .cell-output-display execution_count=23}\n```\ntensor([[4.5950e-01, 2.9987e-04, 1.4484e-02],\n        [1.8587e-02, 6.5435e-01, 6.7723e-01]])\n```\n:::\n:::\n\n\n### Element-wise operation\n\nLet's make 2 new tensors first. To do anything element-wise, the shape of the tensors should be the same.\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\na = torch.rand(2, 3)\nb = torch.rand(2, 3)\nprint(a)\nprint(b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntensor([[0.3759, 0.0295, 0.4132],\n        [0.0791, 0.0489, 0.9287]])\ntensor([[0.4924, 0.8416, 0.1756],\n        [0.5687, 0.4447, 0.0310]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\n#add\na + b\n#subtract\na - b\n#multiply\na*b\n#division\na/b\n#power\na**b\n#mod\na%b\n#int division\na//b\n```\n\n::: {.cell-output .cell-output-display execution_count=25}\n```\ntensor([[ 0.,  0.,  2.],\n        [ 0.,  0., 29.]])\n```\n:::\n:::\n\n\nLet's apply absolute function on a custom tensor.\n\n::: {.cell execution_count=26}\n``` {.python .cell-code}\n#abs\nc = torch.tensor([-1, 2, -3, 4, -5, -6, 7, -8])\ntorch.abs(c)\n```\n\n::: {.cell-output .cell-output-display execution_count=26}\n```\ntensor([1, 2, 3, 4, 5, 6, 7, 8])\n```\n:::\n:::\n\n\nWe only have positive values, right? As expected.\n\nLet's apply negative on the tensor.\n\n::: {.cell execution_count=27}\n``` {.python .cell-code}\ntorch.neg(c)\n```\n\n::: {.cell-output .cell-output-display execution_count=27}\n```\ntensor([ 1, -2,  3, -4,  5,  6, -7,  8])\n```\n:::\n:::\n\n\nWe have negative signs on the previously positives, and positive signs on the previously negatives, right?\n\n::: {.cell execution_count=28}\n``` {.python .cell-code}\n#round\nd = torch.tensor([1.4, 4.4, 3.6, 3.01, 4.55, 4.9])\ntorch.round(d)\n# ceil\ntorch.ceil(d)\n# floor\ntorch.floor(d)\n```\n\n::: {.cell-output .cell-output-display execution_count=28}\n```\ntensor([1., 4., 3., 3., 4., 4.])\n```\n:::\n:::\n\n\nDo you see what `round`, `ciel`, `floor` are doing here? It is not that difficult, try to see.\n\nLet's do some `clamp`ing. So, if a value is smaller than the `min` value provided, that value will be equal to the `min` value and values bigger than the `max` value will be made equal to the `max` value. All other values in between the range will be kept as they are.\n\n::: {.cell execution_count=29}\n``` {.python .cell-code}\n# clamp\nd\ntorch.clamp(d, min=2, max=4)\n```\n\n::: {.cell-output .cell-output-display execution_count=29}\n```\ntensor([2.0000, 4.0000, 3.6000, 3.0100, 4.0000, 4.0000])\n```\n:::\n:::\n\n\n### Reduction operation\n\n::: {.cell execution_count=30}\n``` {.python .cell-code}\ne = torch.randint(size=(2,3), low=0, high=10, dtype=torch.float32)\ne\n```\n\n::: {.cell-output .cell-output-display execution_count=30}\n```\ntensor([[5., 1., 7.],\n        [7., 1., 5.]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=31}\n``` {.python .cell-code}\n# sum\ntorch.sum(e)\n# sum along columns\ntorch.sum(e, dim=0)\n# sum along rows\ntorch.sum(e, dim=1)\n# mean\ntorch.mean(e)\n# mean along col\ntorch.mean(e, dim=0)\n# mean along row\ntorch.mean(e, dim=1)\n# median\ntorch.median(e)\ntorch.median(e, dim=0)\ntorch.median(e, dim=1)\n```\n\n::: {.cell-output .cell-output-display execution_count=31}\n```\ntorch.return_types.median(\nvalues=tensor([5., 5.]),\nindices=tensor([0, 2]))\n```\n:::\n:::\n\n\n::: {.cell execution_count=32}\n``` {.python .cell-code}\n# max and min\ntorch.max(e)\ntorch.max(e, dim=0)\ntorch.max(e, dim=1)\n\ntorch.min(e)\ntorch.min(e, dim=0)\ntorch.min(e, dim=1)\n```\n\n::: {.cell-output .cell-output-display execution_count=32}\n```\ntorch.return_types.min(\nvalues=tensor([1., 1.]),\nindices=tensor([1, 1]))\n```\n:::\n:::\n\n\n::: {.cell execution_count=33}\n``` {.python .cell-code}\n# product\ntorch.prod(e)\n#do yourself dimension-wise\n```\n\n::: {.cell-output .cell-output-display execution_count=33}\n```\ntensor(1225.)\n```\n:::\n:::\n\n\n::: {.cell execution_count=34}\n``` {.python .cell-code}\n# standard deviation\ntorch.std(e)\n#do yourself dimension-wise\n```\n\n::: {.cell-output .cell-output-display execution_count=34}\n```\ntensor(2.7325)\n```\n:::\n:::\n\n\n::: {.cell execution_count=35}\n``` {.python .cell-code}\n# variance\ntorch.var(e)\n#do yourself dimension-wise\n```\n\n::: {.cell-output .cell-output-display execution_count=35}\n```\ntensor(7.4667)\n```\n:::\n:::\n\n\nWhich value is the biggest here? How to get its position/index? Use `argmax`.\n\n::: {.cell execution_count=36}\n``` {.python .cell-code}\n# argmax\ntorch.argmax(e)\n```\n\n::: {.cell-output .cell-output-display execution_count=36}\n```\ntensor(2)\n```\n:::\n:::\n\n\nWhich value is the smallest here? How to get its position/index? Use `argmin`.\n\n::: {.cell execution_count=37}\n``` {.python .cell-code}\n# argmin\ntorch.argmin(e)\n```\n\n::: {.cell-output .cell-output-display execution_count=37}\n```\ntensor(1)\n```\n:::\n:::\n\n\n### Matrix operations\n\n::: {.cell execution_count=38}\n``` {.python .cell-code}\nm1 = torch.randint(size=(2,3), low=0, high=10)\nm2 = torch.randint(size=(3,2), low=0, high=10)\n\nprint(m1)\nprint(m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntensor([[8, 9, 1],\n        [2, 4, 5]])\ntensor([[6, 5],\n        [6, 2],\n        [0, 6]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=39}\n``` {.python .cell-code}\n# matrix multiplcation\ntorch.matmul(m1, m2)\n```\n\n::: {.cell-output .cell-output-display execution_count=39}\n```\ntensor([[102,  64],\n        [ 36,  48]])\n```\n:::\n:::\n\n\n### Dot products:\n\n::: {.cell execution_count=40}\n``` {.python .cell-code}\nvector1 = torch.tensor([1, 2])\nvector2 = torch.tensor([3, 4])\n\n# dot product\ntorch.dot(vector1, vector2)\n```\n\n::: {.cell-output .cell-output-display execution_count=40}\n```\ntensor(11)\n```\n:::\n:::\n\n\n::: {.cell execution_count=41}\n``` {.python .cell-code}\n# transpose\ntorch.transpose(m2, 0, 1)\n```\n\n::: {.cell-output .cell-output-display execution_count=41}\n```\ntensor([[6, 6, 0],\n        [5, 2, 6]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=42}\n``` {.python .cell-code}\nh = torch.randint(size=(3,3), low=0, high=8, dtype=torch.float32)\nh\n```\n\n::: {.cell-output .cell-output-display execution_count=42}\n```\ntensor([[7., 1., 3.],\n        [3., 2., 2.],\n        [7., 2., 4.]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=43}\n``` {.python .cell-code}\n# determinant\ntorch.det(h)\n```\n\n::: {.cell-output .cell-output-display execution_count=43}\n```\ntensor(6.0000)\n```\n:::\n:::\n\n\n::: {.cell execution_count=44}\n``` {.python .cell-code}\n# inverse\ntorch.inverse(h)\n```\n\n::: {.cell-output .cell-output-display execution_count=44}\n```\ntensor([[ 0.6667,  0.3333, -0.6667],\n        [ 0.3333,  1.1667, -0.8333],\n        [-1.3333, -1.1667,  1.8333]])\n```\n:::\n:::\n\n\n### Comparison operations\n\n::: {.cell execution_count=45}\n``` {.python .cell-code}\ni = torch.randint(size=(2,3), low=0, high=10)\nj = torch.randint(size=(2,3), low=0, high=10)\n\nprint(i)\nprint(j)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntensor([[1, 0, 1],\n        [7, 8, 9]])\ntensor([[1, 9, 7],\n        [4, 5, 9]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=46}\n``` {.python .cell-code}\n# greater than\ni > j\n# less than\ni < j\n# equal to\ni == j\n# not equal to\ni != j\n# greater than equal to\n\n# less than equal to\n```\n\n::: {.cell-output .cell-output-display execution_count=46}\n```\ntensor([[False,  True,  True],\n        [ True,  True, False]])\n```\n:::\n:::\n\n\n### Special functions\n\n::: {.cell execution_count=47}\n``` {.python .cell-code}\nk = torch.randint(size=(2,3), low=0, high=10, dtype=torch.float32)\nk\n```\n\n::: {.cell-output .cell-output-display execution_count=47}\n```\ntensor([[5., 8., 1.],\n        [3., 4., 4.]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=48}\n``` {.python .cell-code}\n# log\ntorch.log(k)\n```\n\n::: {.cell-output .cell-output-display execution_count=48}\n```\ntensor([[1.6094, 2.0794, 0.0000],\n        [1.0986, 1.3863, 1.3863]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=49}\n``` {.python .cell-code}\n# exp\ntorch.exp(k)\n```\n\n::: {.cell-output .cell-output-display execution_count=49}\n```\ntensor([[1.4841e+02, 2.9810e+03, 2.7183e+00],\n        [2.0086e+01, 5.4598e+01, 5.4598e+01]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=50}\n``` {.python .cell-code}\n# sqrt\ntorch.sqrt(k)\n```\n\n::: {.cell-output .cell-output-display execution_count=50}\n```\ntensor([[2.2361, 2.8284, 1.0000],\n        [1.7321, 2.0000, 2.0000]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=51}\n``` {.python .cell-code}\nk\n# sigmoid\ntorch.sigmoid(k)\n```\n\n::: {.cell-output .cell-output-display execution_count=51}\n```\ntensor([[0.9933, 0.9997, 0.7311],\n        [0.9526, 0.9820, 0.9820]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=52}\n``` {.python .cell-code}\nk\n# softmax\ntorch.softmax(k, dim=0)\n```\n\n::: {.cell-output .cell-output-display execution_count=52}\n```\ntensor([[0.8808, 0.9820, 0.0474],\n        [0.1192, 0.0180, 0.9526]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=53}\n``` {.python .cell-code}\n# relu\ntorch.relu(k)\n```\n\n::: {.cell-output .cell-output-display execution_count=53}\n```\ntensor([[5., 8., 1.],\n        [3., 4., 4.]])\n```\n:::\n:::\n\n\n### Inplace Operations\n\n::: {.cell execution_count=54}\n``` {.python .cell-code}\nm = torch.rand(2,3)\nn = torch.rand(2,3)\n\nprint(m)\nprint(n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntensor([[0.2179, 0.5475, 0.4801],\n        [0.2278, 0.7175, 0.8381]])\ntensor([[0.2569, 0.9879, 0.0779],\n        [0.3233, 0.7714, 0.9524]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=55}\n``` {.python .cell-code}\nm.add_(n)\nm\nn\n```\n\n::: {.cell-output .cell-output-display execution_count=55}\n```\ntensor([[0.2569, 0.9879, 0.0779],\n        [0.3233, 0.7714, 0.9524]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=56}\n``` {.python .cell-code}\ntorch.relu(m)\n```\n\n::: {.cell-output .cell-output-display execution_count=56}\n```\ntensor([[0.4748, 1.5353, 0.5580],\n        [0.5511, 1.4889, 1.7905]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=57}\n``` {.python .cell-code}\nm.relu_()\nm\n```\n\n::: {.cell-output .cell-output-display execution_count=57}\n```\ntensor([[0.4748, 1.5353, 0.5580],\n        [0.5511, 1.4889, 1.7905]])\n```\n:::\n:::\n\n\nCopying a Tensor\n\n::: {.cell execution_count=58}\n``` {.python .cell-code}\na = torch.rand(2,3)\na\n```\n\n::: {.cell-output .cell-output-display execution_count=58}\n```\ntensor([[0.1013, 0.2033, 0.2292],\n        [0.6055, 0.3249, 0.9225]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=59}\n``` {.python .cell-code}\nb = a\na\nb\n```\n\n::: {.cell-output .cell-output-display execution_count=59}\n```\ntensor([[0.1013, 0.2033, 0.2292],\n        [0.6055, 0.3249, 0.9225]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=60}\n``` {.python .cell-code}\na[0][0] = 0\na\n```\n\n::: {.cell-output .cell-output-display execution_count=60}\n```\ntensor([[0.0000, 0.2033, 0.2292],\n        [0.6055, 0.3249, 0.9225]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=61}\n``` {.python .cell-code}\nb\n```\n\n::: {.cell-output .cell-output-display execution_count=61}\n```\ntensor([[0.0000, 0.2033, 0.2292],\n        [0.6055, 0.3249, 0.9225]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=62}\n``` {.python .cell-code}\nid(a)\n```\n\n::: {.cell-output .cell-output-display execution_count=62}\n```\n4843282960\n```\n:::\n:::\n\n\n::: {.cell execution_count=63}\n``` {.python .cell-code}\nid(b)\n```\n\n::: {.cell-output .cell-output-display execution_count=63}\n```\n4843282960\n```\n:::\n:::\n\n\nBetter way of making a copy\n\n::: {.cell execution_count=64}\n``` {.python .cell-code}\nb = a.clone()\na\nb\n```\n\n::: {.cell-output .cell-output-display execution_count=64}\n```\ntensor([[0.0000, 0.2033, 0.2292],\n        [0.6055, 0.3249, 0.9225]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=65}\n``` {.python .cell-code}\na[0][0] = 10\na\n```\n\n::: {.cell-output .cell-output-display execution_count=65}\n```\ntensor([[10.0000,  0.2033,  0.2292],\n        [ 0.6055,  0.3249,  0.9225]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=66}\n``` {.python .cell-code}\nb\n```\n\n::: {.cell-output .cell-output-display execution_count=66}\n```\ntensor([[0.0000, 0.2033, 0.2292],\n        [0.6055, 0.3249, 0.9225]])\n```\n:::\n:::\n\n\nNow, let's check their memory locations. They are at different locations.\n\n::: {.cell execution_count=67}\n``` {.python .cell-code}\nid(a)\nid(b)\n```\n\n::: {.cell-output .cell-output-display execution_count=67}\n```\n4843283344\n```\n:::\n:::\n\n\n# Autograd\n\nLet's go hard way. Let's define our own differentiation formula. Our equation was $y = x^2$. So, the derivative $\\frac{dy}{dx}$ will be $2x$.\n\n::: {.cell execution_count=68}\n``` {.python .cell-code}\ndef dy_dx(x):\n  return 2*x\n```\n:::\n\n\nLet's check for $x = 3$ now.\n\n::: {.cell execution_count=69}\n``` {.python .cell-code}\ndy_dx(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=69}\n```\n6\n```\n:::\n:::\n\n\nBut using `PyTorch`, it will be easy.\n\n::: {.cell execution_count=70}\n``` {.python .cell-code}\n#import torch\nx = torch.tensor(3.0, requires_grad=True) #gradient calculation requirement is set as True\ny = x**2\nx\ny\n```\n\n::: {.cell-output .cell-output-display execution_count=70}\n```\ntensor(9., grad_fn=<PowBackward0>)\n```\n:::\n:::\n\n\nWe need to use `backward` on the last calculation (or variable) though, to calculate the gradient.\n\n::: {.cell execution_count=71}\n``` {.python .cell-code}\ny.backward()\nx.grad\n```\n\n::: {.cell-output .cell-output-display execution_count=71}\n```\ntensor(6.)\n```\n:::\n:::\n\n\nNow, let's make the situation a bit complex. Let's say we have another equation $z = sin(y)$. So, if we want to calculate $\\frac{dz}{dx}$, it requires a chain formula to calculate the derivative. And it will be: $$\\frac{dz}{dx} = \\frac{dz}{dy}*\\frac{dy}{dx}$$. If we solve the formula, the derivative will be: $2*x*cos(x^2)$. And yes, since we have a trigonometric formula, we need to load the math library.\n\n::: {.cell execution_count=72}\n``` {.python .cell-code}\nimport math\n\ndef dz_dx(x):\n    return 2 * x * math.cos(x**2)\n```\n:::\n\n\n::: {.cell execution_count=73}\n``` {.python .cell-code}\ndz_dx(2) #you can decide the value of your x here\n```\n\n::: {.cell-output .cell-output-display execution_count=73}\n```\n-2.6145744834544478\n```\n:::\n:::\n\n\nBut let's use our friend `PyTorch` to make our life easier.\n\n::: {.cell execution_count=74}\n``` {.python .cell-code}\nx = torch.tensor(2.0, requires_grad=True) #you can decide the value of your x here\n```\n:::\n\n\n::: {.cell execution_count=75}\n``` {.python .cell-code}\ny = x**2\n```\n:::\n\n\n::: {.cell execution_count=76}\n``` {.python .cell-code}\nz = torch.sin(y)\nx\ny\nz\n```\n\n::: {.cell-output .cell-output-display execution_count=76}\n```\ntensor(-0.7568, grad_fn=<SinBackward0>)\n```\n:::\n:::\n\n\nSo, let's use `backward` on our `z`.\n\n::: {.cell execution_count=77}\n``` {.python .cell-code}\nz.backward()\n```\n:::\n\n\n::: {.cell execution_count=78}\n``` {.python .cell-code}\nx.grad\n```\n\n::: {.cell-output .cell-output-display execution_count=78}\n```\ntensor(-2.6146)\n```\n:::\n:::\n\n\n::: {.cell execution_count=79}\n``` {.python .cell-code}\ny.grad\n```\n:::\n\n\n`y.grad` is not possible, since it is an intermediate leaf.\n\n## Real-world example:\n\nLet's say a student got CGPA 3.10 and did not get a placement in an institute. So, we can try to make a prediction.\n\n::: {.cell execution_count=80}\n``` {.python .cell-code}\nimport torch\n\n# Inputs\nx = torch.tensor(6.70)  # Input feature\ny = torch.tensor(0.0)  # True label (binary)\n\nw = torch.tensor(1.0)  # Weight\nb = torch.tensor(0.0)  # Bias\n```\n:::\n\n\n::: {.cell execution_count=81}\n``` {.python .cell-code}\n# Binary Cross-Entropy Loss for scalar\ndef binary_cross_entropy_loss(prediction, target):\n    epsilon = 1e-8  # To prevent log(0)\n    prediction = torch.clamp(prediction, epsilon, 1 - epsilon)\n    return -(target * torch.log(prediction) + (1 - target) * torch.log(1 - prediction))\n```\n:::\n\n\n::: {.cell execution_count=82}\n``` {.python .cell-code}\n# Forward pass\nz = w * x + b  # Weighted sum (linear part)\ny_pred = torch.sigmoid(z)  # Predicted probability\n\n# Compute binary cross-entropy loss\nloss = binary_cross_entropy_loss(y_pred, y)\n```\n:::\n\n\n::: {.cell execution_count=83}\n``` {.python .cell-code}\n# Derivatives:\n# 1. dL/d(y_pred): Loss with respect to the prediction (y_pred)\ndloss_dy_pred = (y_pred - y)/(y_pred*(1-y_pred))\n\n# 2. dy_pred/dz: Prediction (y_pred) with respect to z (sigmoid derivative)\ndy_pred_dz = y_pred * (1 - y_pred)\n\n# 3. dz/dw and dz/db: z with respect to w and b\ndz_dw = x  # dz/dw = x\ndz_db = 1  # dz/db = 1 (bias contributes directly to z)\n\ndL_dw = dloss_dy_pred * dy_pred_dz * dz_dw\ndL_db = dloss_dy_pred * dy_pred_dz * dz_db\n```\n:::\n\n\n::: {.cell execution_count=84}\n``` {.python .cell-code}\nprint(f\"Manual Gradient of loss w.r.t weight (dw): {dL_dw}\")\nprint(f\"Manual Gradient of loss w.r.t bias (db): {dL_db}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nManual Gradient of loss w.r.t weight (dw): 6.691762447357178\nManual Gradient of loss w.r.t bias (db): 0.998770534992218\n```\n:::\n:::\n\n\nBut let's use our friend again.\n\n::: {.cell execution_count=85}\n``` {.python .cell-code}\nx = torch.tensor(6.7)\ny = torch.tensor(0.0)\n```\n:::\n\n\n::: {.cell execution_count=86}\n``` {.python .cell-code}\nw = torch.tensor(1.0, requires_grad=True)\nb = torch.tensor(0.0, requires_grad=True)\nw\nb\n```\n\n::: {.cell-output .cell-output-display execution_count=86}\n```\ntensor(0., requires_grad=True)\n```\n:::\n:::\n\n\n::: {.cell execution_count=87}\n``` {.python .cell-code}\nz = w*x + b\nz\ny_pred = torch.sigmoid(z)\ny_pred\nloss = binary_cross_entropy_loss(y_pred, y)\nloss\n```\n\n::: {.cell-output .cell-output-display execution_count=87}\n```\ntensor(6.7012, grad_fn=<NegBackward0>)\n```\n:::\n:::\n\n\n::: {.cell execution_count=88}\n``` {.python .cell-code}\nloss.backward()\n```\n:::\n\n\n::: {.cell execution_count=89}\n``` {.python .cell-code}\nprint(w.grad)\nprint(b.grad)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntensor(6.6918)\ntensor(0.9988)\n```\n:::\n:::\n\n\nLet's insert multiple values (or a vector).\n\n::: {.cell execution_count=90}\n``` {.python .cell-code}\nx = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\nx\n```\n\n::: {.cell-output .cell-output-display execution_count=90}\n```\ntensor([1., 2., 3.], requires_grad=True)\n```\n:::\n:::\n\n\n::: {.cell execution_count=91}\n``` {.python .cell-code}\ny = (x**2).mean()\ny\n```\n\n::: {.cell-output .cell-output-display execution_count=91}\n```\ntensor(4.6667, grad_fn=<MeanBackward0>)\n```\n:::\n:::\n\n\n::: {.cell execution_count=92}\n``` {.python .cell-code}\ny.backward()\nx.grad\n```\n\n::: {.cell-output .cell-output-display execution_count=92}\n```\ntensor([0.6667, 1.3333, 2.0000])\n```\n:::\n:::\n\n\nIf we rerun all these things, the values get updtaed. So, we need to stop this behavior. How to do it?\n\n::: {.cell execution_count=93}\n``` {.python .cell-code}\n# clearing grad\nx = torch.tensor(2.0, requires_grad=True)\nx\n```\n\n::: {.cell-output .cell-output-display execution_count=93}\n```\ntensor(2., requires_grad=True)\n```\n:::\n:::\n\n\n::: {.cell execution_count=94}\n``` {.python .cell-code}\ny = x ** 2\ny\n```\n\n::: {.cell-output .cell-output-display execution_count=94}\n```\ntensor(4., grad_fn=<PowBackward0>)\n```\n:::\n:::\n\n\n::: {.cell execution_count=95}\n``` {.python .cell-code}\ny.backward()\n```\n:::\n\n\n::: {.cell execution_count=96}\n``` {.python .cell-code}\nx.grad\n```\n\n::: {.cell-output .cell-output-display execution_count=96}\n```\ntensor(4.)\n```\n:::\n:::\n\n\n::: {.cell execution_count=97}\n``` {.python .cell-code}\nx.grad.zero_()\n```\n\n::: {.cell-output .cell-output-display execution_count=97}\n```\ntensor(0.)\n```\n:::\n:::\n\n\nNow, we don't see `requires_grad=True` part here. So, it is off. Another way:\n\n::: {.cell execution_count=98}\n``` {.python .cell-code}\n# option 1 - requires_grad_(False)\n# option 2 - detach()\n# option 3 - torch.no_grad()\n```\n:::\n\n\n::: {.cell execution_count=99}\n``` {.python .cell-code}\nx = torch.tensor(2.0, requires_grad=True)\nx\nx.requires_grad_(False)\n```\n\n::: {.cell-output .cell-output-display execution_count=99}\n```\ntensor(2.)\n```\n:::\n:::\n\n\n::: {.cell execution_count=100}\n``` {.python .cell-code}\ny = x ** 2\ny\n```\n\n::: {.cell-output .cell-output-display execution_count=100}\n```\ntensor(4.)\n```\n:::\n:::\n\n\n::: {.cell execution_count=101}\n``` {.python .cell-code}\n#not possible now\ny.backward()\n```\n\n::: {.cell-output .cell-output-error}\n```\nRuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n```\n:::\n:::\n\n\n::: {.cell execution_count=102}\n``` {.python .cell-code}\nx = torch.tensor(2.0, requires_grad=True)\nx\n```\n\n::: {.cell-output .cell-output-display execution_count=102}\n```\ntensor(2., requires_grad=True)\n```\n:::\n:::\n\n\n::: {.cell execution_count=103}\n``` {.python .cell-code}\nz = x.detach()\nz\n```\n\n::: {.cell-output .cell-output-display execution_count=103}\n```\ntensor(2.)\n```\n:::\n:::\n\n\n::: {.cell execution_count=104}\n``` {.python .cell-code}\ny = x ** 2\ny\n```\n\n::: {.cell-output .cell-output-display execution_count=104}\n```\ntensor(4., grad_fn=<PowBackward0>)\n```\n:::\n:::\n\n\n::: {.cell execution_count=105}\n``` {.python .cell-code}\ny1 = z ** 2\ny1\n```\n\n::: {.cell-output .cell-output-display execution_count=105}\n```\ntensor(4.)\n```\n:::\n:::\n\n\n::: {.cell execution_count=106}\n``` {.python .cell-code}\ny.backward() #possible\n```\n:::\n\n\n::: {.cell execution_count=107}\n``` {.python .cell-code}\ny1.backward() #not possible\n```\n\n::: {.cell-output .cell-output-error}\n```\nRuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n```\n:::\n:::\n\n\n# PyTorch Trining Pipeline\n\n::: {.cell execution_count=108}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\n```\n:::\n\n\nLoad an example dataset\n\n::: {.cell execution_count=109}\n``` {.python .cell-code}\ndf = pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=109}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>...</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n      <th>Unnamed: 32</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842302</td>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>...</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>842517</td>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>...</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84300903</td>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>...</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84348301</td>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>...</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84358402</td>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>...</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 33 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=110}\n``` {.python .cell-code}\ndf.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=110}\n```\n(569, 33)\n```\n:::\n:::\n\n\n::: {.cell execution_count=111}\n``` {.python .cell-code}\ndf.drop(columns=['id', 'Unnamed: 32'], inplace= True)\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=111}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>symmetry_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>0.2419</td>\n      <td>...</td>\n      <td>25.38</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>0.1812</td>\n      <td>...</td>\n      <td>24.99</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>0.2069</td>\n      <td>...</td>\n      <td>23.57</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>0.2597</td>\n      <td>...</td>\n      <td>14.91</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>0.1809</td>\n      <td>...</td>\n      <td>22.54</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>\n```\n:::\n:::\n\n\n## Train test split\n\n::: {.cell execution_count=112}\n``` {.python .cell-code}\nX_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 1:], df.iloc[:, 0], test_size=0.2)\n```\n:::\n\n\n## Scaling\n\n::: {.cell execution_count=113}\n``` {.python .cell-code}\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n```\n:::\n\n\n::: {.cell execution_count=114}\n``` {.python .cell-code}\nX_train\n```\n\n::: {.cell-output .cell-output-display execution_count=114}\n```\narray([[-0.30279106, -0.87388841, -0.21264979, ...,  1.24614994,\n         0.37827849,  3.01811359],\n       [ 1.13805311,  0.18496661,  1.10187355, ...,  1.1649544 ,\n         0.24425606, -0.02325634],\n       [ 1.80801761, -0.44507608,  1.71875391, ...,  1.43560621,\n        -0.35246286, -0.72605794],\n       ...,\n       [-0.8774468 , -1.04876718, -0.89852335, ..., -0.90462979,\n        -0.51041787,  0.39960221],\n       [-0.4233286 ,  1.10966806, -0.39609053, ...,  0.84017222,\n         0.7548177 ,  1.01622631],\n       [-0.08133835, -0.61995485, -0.14122154, ..., -0.80448862,\n        -0.36841791, -0.3818832 ]], shape=(455, 30))\n```\n:::\n:::\n\n\n::: {.cell execution_count=115}\n``` {.python .cell-code}\ny_train\n```\n\n::: {.cell-output .cell-output-display execution_count=115}\n```\n105    M\n6      M\n373    M\n295    B\n157    B\n      ..\n276    B\n113    B\n398    B\n64     M\n477    B\nName: diagnosis, Length: 455, dtype: object\n```\n:::\n:::\n\n\n## Label Encoding\n\n::: {.cell execution_count=116}\n``` {.python .cell-code}\nencoder = LabelEncoder()\ny_train = encoder.fit_transform(y_train)\ny_test = encoder.transform(y_test)\n```\n:::\n\n\n::: {.cell execution_count=117}\n``` {.python .cell-code}\ny_train\n```\n\n::: {.cell-output .cell-output-display execution_count=117}\n```\narray([1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n       1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n       1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n       1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n       1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n       0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n       0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n       0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n       0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n       1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n       0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n       1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0])\n```\n:::\n:::\n\n\n## Numpy arrays to PyTorch tensors\n\n::: {.cell execution_count=118}\n``` {.python .cell-code}\nX_train_tensor = torch.from_numpy(X_train)\nX_test_tensor = torch.from_numpy(X_test)\ny_train_tensor = torch.from_numpy(y_train)\ny_test_tensor = torch.from_numpy(y_test)\n```\n:::\n\n\n::: {.cell execution_count=119}\n``` {.python .cell-code}\nX_train_tensor.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=119}\n```\ntorch.Size([455, 30])\n```\n:::\n:::\n\n\n::: {.cell execution_count=120}\n``` {.python .cell-code}\ny_train_tensor.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=120}\n```\ntorch.Size([455])\n```\n:::\n:::\n\n\n## Defining the model\n\n::: {.cell execution_count=121}\n``` {.python .cell-code}\nclass MySimpleNN():\n\n  def __init__(self, X):\n\n    self.weights = torch.rand(X.shape[1], 1, dtype=torch.float64, requires_grad=True)\n    self.bias = torch.zeros(1, dtype=torch.float64, requires_grad=True)\n\n  def forward(self, X):\n    z = torch.matmul(X, self.weights) + self.bias\n    y_pred = torch.sigmoid(z)\n    return y_pred\n\n  def loss_function(self, y_pred, y):\n    # Clamp predictions to avoid log(0)\n    epsilon = 1e-7\n    y_pred = torch.clamp(y_pred, epsilon, 1 - epsilon)\n\n    # Calculate loss\n    loss = -(y_train_tensor * torch.log(y_pred) + (1 - y_train_tensor) * torch.log(1 - y_pred)).mean()\n    return loss\n```\n:::\n\n\n## Important Parameters\n\n::: {.cell execution_count=122}\n``` {.python .cell-code}\nlearning_rate = 0.1\nepochs = 25\n```\n:::\n\n\n## Training Pipeline\n\n::: {.cell execution_count=123}\n``` {.python .cell-code}\n# create model\nmodel = MySimpleNN(X_train_tensor)\n\n# define loop\nfor epoch in range(epochs):\n\n  # forward pass\n  y_pred = model.forward(X_train_tensor)\n\n  # loss calculate\n  loss = model.loss_function(y_pred, y_train_tensor)\n\n  # backward pass\n  loss.backward()\n\n  # parameters update\n  with torch.no_grad():\n    model.weights -= learning_rate * model.weights.grad\n    model.bias -= learning_rate * model.bias.grad\n\n  # zero gradients\n  model.weights.grad.zero_()\n  model.bias.grad.zero_()\n\n  # print loss in each epoch\n  print(f'Epoch: {epoch + 1}, Loss: {loss.item()}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch: 1, Loss: 4.024507996913868\nEpoch: 2, Loss: 3.911315255031256\nEpoch: 3, Loss: 3.7924208595523616\nEpoch: 4, Loss: 3.6684245914797153\nEpoch: 5, Loss: 3.5435049128151626\nEpoch: 6, Loss: 3.4152885182840507\nEpoch: 7, Loss: 3.2828281042647145\nEpoch: 8, Loss: 3.1449099669210363\nEpoch: 9, Loss: 3.0046272421071833\nEpoch: 10, Loss: 2.8546900642566935\nEpoch: 11, Loss: 2.702937896741921\nEpoch: 12, Loss: 2.544308971894636\nEpoch: 13, Loss: 2.3789788753200907\nEpoch: 14, Loss: 2.215878705252132\nEpoch: 15, Loss: 2.0565452380924527\nEpoch: 16, Loss: 1.8981580328601702\nEpoch: 17, Loss: 1.7477475634634518\nEpoch: 18, Loss: 1.602497545809214\nEpoch: 19, Loss: 1.457033089112328\nEpoch: 20, Loss: 1.3256694838966872\nEpoch: 21, Loss: 1.2100079116915423\nEpoch: 22, Loss: 1.1111952324113044\nEpoch: 23, Loss: 1.0296470436291785\nEpoch: 24, Loss: 0.9647989062014453\nEpoch: 25, Loss: 0.9150282523696833\n```\n:::\n:::\n\n\n::: {.cell execution_count=124}\n``` {.python .cell-code}\nmodel.bias\n```\n\n::: {.cell-output .cell-output-display execution_count=124}\n```\ntensor([-0.0647], dtype=torch.float64, requires_grad=True)\n```\n:::\n:::\n\n\n::: {.cell execution_count=125}\n``` {.python .cell-code}\nmodel.weights\n```\n\n::: {.cell-output .cell-output-display execution_count=125}\n```\ntensor([[ 0.2633],\n        [ 0.0192],\n        [ 0.4376],\n        [ 0.2976],\n        [-0.0068],\n        [-0.6394],\n        [-0.3432],\n        [ 0.0566],\n        [ 0.0487],\n        [ 0.6094],\n        [-0.0849],\n        [ 0.4802],\n        [ 0.1285],\n        [ 0.2909],\n        [ 0.0829],\n        [-0.0656],\n        [-0.2591],\n        [ 0.3589],\n        [ 0.7048],\n        [-0.0325],\n        [ 0.3722],\n        [ 0.2304],\n        [-0.5136],\n        [ 0.0255],\n        [ 0.3085],\n        [-0.5099],\n        [ 0.2786],\n        [-0.0662],\n        [ 0.0550],\n        [ 0.3601]], dtype=torch.float64, requires_grad=True)\n```\n:::\n:::\n\n\n## Evaluation\n\n::: {.cell execution_count=126}\n``` {.python .cell-code}\n# model evaluation\nwith torch.no_grad():\n  y_pred = model.forward(X_test_tensor)\n  y_pred = (y_pred > 0.9).float()\n  accuracy = (y_pred == y_test_tensor).float().mean()\n  print(f'Accuracy: {accuracy.item()}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy: 0.6583564281463623\n```\n:::\n:::\n\n\n# NN module\n\n# Dataset and DataLoader\n\n# ANN/MLP in PyTorch\n\nWe will use Fashion MNIST dataset for this purpose. We can find this dataset in Kaggle. It has 70,000 (28\\*28) fashion images. We will try to classify them using our ANN and improve our model. But we will use less images since we are using less local resource (CPU, not GPU).\n\nOur ANN structure: 1 `input layer` with `28*28 = 784` nodes. Then we will have `2 hidden layers`. The first one will have 128 neurons and the second one will have 64 neurons. Then we will have 1 `output layer` having 10 neurons. The hidden layers will use ReLU and the last output layer will use softmax since it is a multi-class classification problems. Workflow: - DataLoader object - Training loop - Evaluation\n\n::: {.cell execution_count=127}\n``` {.python .cell-code}\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\n```\n:::\n\n\nNow, after loading the packages, we can use them. Let's make it reproducible using a seed.\n\n::: {.cell execution_count=128}\n``` {.python .cell-code}\ntorch.manual_seed(30)\n```\n\n::: {.cell-output .cell-output-display execution_count=128}\n```\n<torch._C.Generator at 0x111c00330>\n```\n:::\n:::\n\n\n::: {.cell execution_count=129}\n``` {.python .cell-code}\n# Use Fashion-MNIST from torchvision and create a small CSV\nimport torchvision\nimport torchvision.transforms as transforms\nimport numpy as np\n\n# Download Fashion-MNIST\ntransform = transforms.Compose([transforms.ToTensor()])\nfmnist = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n\n# Create a small subset (first 1000 samples)\nn_samples = 1000\nimages_list = []\nlabels_list = []\n\nfor i in range(min(n_samples, len(fmnist))):\n    image, label = fmnist[i]\n    # Convert tensor to numpy and flatten\n    image_flat = image.numpy().flatten()\n    images_list.append(image_flat)\n    labels_list.append(label)\n\n# Create DataFrame\nimages_array = np.array(images_list)\nlabels_array = np.array(labels_list)\n\n# Combine labels and images\ndata = np.column_stack([labels_array, images_array])\ncolumns = ['label'] + [f'pixel{i}' for i in range(784)]\ndf = pd.DataFrame(data, columns=columns)\n\n# Save to CSV for future use\ndf.to_csv('fmnist_small.csv', index=False)\nprint(f\"Created fmnist_small.csv with {len(df)} samples\")\n\ndf.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCreated fmnist_small.csv with 1000 samples\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=129}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.003922</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.466667</td>\n      <td>0.447059</td>\n      <td>0.509804</td>\n      <td>0.298039</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.003922</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.129412</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 785 columns</p>\n</div>\n```\n:::\n:::\n\n\nLet's check some images.\n\n::: {.cell execution_count=130}\n``` {.python .cell-code}\n# Create a 4x4 grid of images\nfig, axes = plt.subplots(4, 4, figsize=(10, 10))\nfig.suptitle(\"First 16 Images\", fontsize=16)\n\n# Plot the first 16 images from the dataset\nfor i, ax in enumerate(axes.flat):\n    img = df.iloc[i, 1:].values.reshape(28, 28)  # Reshape to 28x28\n    ax.imshow(img)  # Display in grayscale\n    ax.axis('off')  # Remove axis for a cleaner look\n    ax.set_title(f\"Label: {df.iloc[i, 0]}\")  # Show the label\n\nplt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust layout to fit the title\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](AI_files/figure-html/cell-131-output-1.png){}\n:::\n:::\n\n\n",
    "supporting": [
      "AI_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}